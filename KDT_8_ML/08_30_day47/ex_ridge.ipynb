{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보스턴 집값 예측 모델 \n",
    "- 데이터셋 : boston.csv\n",
    "- 학습방법 : 지도학습 -> 회귀\n",
    "- 피쳐/독립 : 13개 \n",
    "- 타겟/종속 : 1개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩 \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "DATA_FILE = '../DATA/boston.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.9</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.9</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "\n",
       "   PTRATIO      B  LSTAT  MEDV  \n",
       "0     15.3  396.9   4.98  24.0  \n",
       "1     17.8  396.9   9.14  21.6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(DATA_FILE)\n",
    "data_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    int64  \n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] 전처리\n",
    "### [2-1] 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치, 중복값, 이상치, 컬럼별 고유값 추출로 이상 데이터 체크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2-2] 표준화 & 정규화 \n",
    "-> 진행 여부에 따라 성능의 변화는 경우에 따라 다름\n",
    "- 정규분포 데이터셋을 기반으로 한 모델 -> StandardScaler, MinMaxScaler, Log 변환 \n",
    "- 피쳐의 값의 범위 차이를 줄이기 -> 피쳐 스케일링, MinMaxScaler, RobustScaler....\n",
    "- 범주형 피쳐 -> 수치화 인코딩 : OneHotEncoder, OrdinalEncoder\n",
    "- 문자열 타겟 -> 정수 라벨 인코딩 : LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2-3] 피쳐와 타겟 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = data_df.iloc[:,:-1]\n",
    "target_sr = data_df['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_df : (506, 13) target_sr : (506,)\n"
     ]
    }
   ],
   "source": [
    "print(f'feature_df : {feature_df.shape} target_sr : {target_sr.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] 학습 준비\n",
    "### [3-1] 학습용 데이터셋과 테스트용 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(feature_df, target_sr, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train : (379, 13), y_train : (379,)\n",
      "x_test : (127, 13), y_test : (127,)\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train : {x_train.shape}, y_train : {y_train.shape}')\n",
    "print(f'x_test : {x_test.shape}, y_test : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3-2] 학습용 데이터셋으로 스케일러 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### - 수치 피쳐 값의 범위 차가 큼 -> scaling 진행 \n",
    "ss_scaler = StandardScaler()\n",
    "ss_scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = ss_scaler.transform(x_train)\n",
    "x_test_scaled = ss_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] 학습 진행 -> 교차검증으로 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성 \n",
    "ridge_model = Ridge(alpha=1.0) # 기본값 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.        , 0.00074434, 0.0004921 ]),\n",
       " 'score_time': array([0.0092628, 0.       , 0.       ]),\n",
       " 'test_neg_mean_squared_error': array([-17.32029712, -22.58256569, -22.65758521]),\n",
       " 'train_neg_mean_squared_error': array([-20.14363572, -18.21077226, -17.29366176]),\n",
       " 'test_r2': array([0.74828253, 0.75629228, 0.68099104]),\n",
       " 'train_r2': array([0.75566257, 0.74003888, 0.78609709])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 진행 \n",
    "# - cv : 3개\n",
    "# - scoring : 'mean_squared_error','r2'ArithmeticError\n",
    "# - return_train_score\n",
    "\n",
    "result = cross_validate(ridge_model, x_train_scaled, y_train, cv=3, scoring=['neg_mean_squared_error','r2'], return_train_score=True)\n",
    "# neg : \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ridge(alpha=0.0)]\n",
      "   fit_time  score_time  test_neg_mean_squared_error  \\\n",
      "0  0.000996    0.000998                   -17.320297   \n",
      "1  0.000998    0.000997                   -22.582566   \n",
      "2  0.001081    0.000921                   -22.657585   \n",
      "\n",
      "   train_neg_mean_squared_error   test_r2  train_r2  \n",
      "0                    -20.143636  0.748283  0.755663  \n",
      "1                    -18.210772  0.756292  0.740039  \n",
      "2                    -17.293662  0.680991  0.786097  \n",
      "\n",
      "[Ridge(alpha=1.0)]\n",
      "   fit_time  score_time  test_neg_mean_squared_error  \\\n",
      "0  0.000777         0.0                   -17.320297   \n",
      "1  0.000000         0.0                   -22.582566   \n",
      "2  0.000000         0.0                   -22.657585   \n",
      "\n",
      "   train_neg_mean_squared_error   test_r2  train_r2  \n",
      "0                    -20.143636  0.748283  0.755663  \n",
      "1                    -18.210772  0.756292  0.740039  \n",
      "2                    -17.293662  0.680991  0.786097  \n",
      "\n",
      "[Ridge(alpha=10)]\n",
      "   fit_time  score_time  test_neg_mean_squared_error  \\\n",
      "0  0.009900    0.000000                   -17.320297   \n",
      "1  0.001264    0.000891                   -22.582566   \n",
      "2  0.001010    0.001137                   -22.657585   \n",
      "\n",
      "   train_neg_mean_squared_error   test_r2  train_r2  \n",
      "0                    -20.143636  0.748283  0.755663  \n",
      "1                    -18.210772  0.756292  0.740039  \n",
      "2                    -17.293662  0.680991  0.786097  \n",
      "\n",
      "[Ridge(alpha=100)]\n",
      "   fit_time  score_time  test_neg_mean_squared_error  \\\n",
      "0       0.0         0.0                   -17.320297   \n",
      "1       0.0         0.0                   -22.582566   \n",
      "2       0.0         0.0                   -22.657585   \n",
      "\n",
      "   train_neg_mean_squared_error   test_r2  train_r2  \n",
      "0                    -20.143636  0.748283  0.755663  \n",
      "1                    -18.210772  0.756292  0.740039  \n",
      "2                    -17.293662  0.680991  0.786097  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 모델 성능을 좌우하는 Hyper-parameter 제어 즉, 튜닝\n",
    "alpha_values = [0.,1.0,10,100]\n",
    "\n",
    "for value in alpha_values:\n",
    "    ridge_model = Ridge(alpha=value)\n",
    "    # 모델 인스턴스 생성\n",
    "    ridge_model = Ridge(alpha=1.0) # 기본값 1.0\n",
    "\n",
    "    # 학습 진행\n",
    "    # - cv : 3개\n",
    "    # - scoring : 'mean_squared_error', 'r2'\n",
    "    # return_train_score\n",
    "    result = cross_validate(ridge_model, x_train_scaled, y_train, cv = 3, scoring=['neg_mean_squared_error','r2'], return_train_score=True)\n",
    "    \n",
    "    result_df = pd.DataFrame(result)\n",
    "    print(f'[Ridge(alpha={value})]')\n",
    "    print(result_df, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ridge(alpha=0.0)]\n",
      "    test_r2  train_r2\n",
      "0  0.748283  0.755663\n",
      "1  0.756292  0.740039\n",
      "2  0.680991  0.786097\n",
      "\n",
      "[Ridge(alpha=1.0)]\n",
      "    test_r2  train_r2\n",
      "0  0.748283  0.755663\n",
      "1  0.756292  0.740039\n",
      "2  0.680991  0.786097\n",
      "\n",
      "[Ridge(alpha=10)]\n",
      "    test_r2  train_r2\n",
      "0  0.748283  0.755663\n",
      "1  0.756292  0.740039\n",
      "2  0.680991  0.786097\n",
      "\n",
      "[Ridge(alpha=100)]\n",
      "    test_r2  train_r2\n",
      "0  0.748283  0.755663\n",
      "1  0.756292  0.740039\n",
      "2  0.680991  0.786097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 모델 성능을 좌우하는 Hyper-parameter 제어 즉, 튜닝\n",
    "alpha_values = [0.,1.0,10,100]\n",
    "\n",
    "for value in alpha_values:\n",
    "    ridge_model = Ridge(alpha=value)\n",
    "# 모델 인스턴스 생성\n",
    "    ridge_model = Ridge(alpha=1.0) # 기본값 1.0\n",
    "\n",
    "# 학습 진행\n",
    "# - cv : 3개\n",
    "# - scoring : 'mean_squared_error', 'r2'\n",
    "# return_train_score\n",
    "    result = cross_validate(ridge_model, x_train_scaled, y_train, cv = 3, scoring=['neg_mean_squared_error','r2'],\n",
    "                            return_train_score=True, return_estimator= True)\n",
    "    \n",
    "    result_df = pd.DataFrame(result)[['test_r2','train_r2']]\n",
    "    print(f'[Ridge(alpha={value})]')\n",
    "    print(result_df, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007380040333377247\n",
      "[Ridge(alpha=0.0)]\n",
      "    test_r2  train_r2      diff\n",
      "0  0.748283  0.755663  0.007380\n",
      "1  0.756292  0.740039  0.016253\n",
      "2  0.680991  0.786097  0.105106\n",
      "\n",
      "0.007380040333377247\n",
      "[Ridge(alpha=1.0)]\n",
      "    test_r2  train_r2      diff\n",
      "0  0.748283  0.755663  0.007380\n",
      "1  0.756292  0.740039  0.016253\n",
      "2  0.680991  0.786097  0.105106\n",
      "\n",
      "0.007380040333377247\n",
      "[Ridge(alpha=10)]\n",
      "    test_r2  train_r2      diff\n",
      "0  0.748283  0.755663  0.007380\n",
      "1  0.756292  0.740039  0.016253\n",
      "2  0.680991  0.786097  0.105106\n",
      "\n",
      "0.007380040333377247\n",
      "[Ridge(alpha=100)]\n",
      "    test_r2  train_r2      diff\n",
      "0  0.748283  0.755663  0.007380\n",
      "1  0.756292  0.740039  0.016253\n",
      "2  0.680991  0.786097  0.105106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 둘의 차이가 작은 것이 좋으므로 차이 구함 \n",
    "\n",
    "alpha_values = [0.,1.0,10,100]\n",
    "\n",
    "for value in alpha_values:\n",
    "    ridge_model = Ridge(alpha=value)\n",
    "    ridge_model = Ridge(alpha=1.0) # 기본값 1.0\n",
    "\n",
    "    result = cross_validate(ridge_model, x_train_scaled, y_train, cv = 3, scoring=['neg_mean_squared_error','r2'],\n",
    "                            return_train_score=True, return_estimator= True)\n",
    "    \n",
    "    result_df = pd.DataFrame(result)[['test_r2','train_r2']]\n",
    "\n",
    "    result_df['diff'] = abs(result_df['test_r2']- result_df['train_r2']) # 차이만 보면 되므로 절대값 사용 \n",
    "    best_idx = result_df['diff'].sort_values()[0] # 정렬했으므로 가장 작은 값 출력 - 정렬했으므로 0번이 가장 작음 \n",
    "    print(best_idx)\n",
    "    print(f'[Ridge(alpha={value})]')\n",
    "    print(result_df, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.39035961  1.53043843  0.11109741  0.6621853  -2.29024619  2.34249774\n",
      "  0.10030677 -3.52062389  2.57481444 -2.20749462 -1.86406784  1.03607796\n",
      " -3.48102887]\n",
      "[-1.39035961  1.53043843  0.11109741  0.6621853  -2.29024619  2.34249774\n",
      "  0.10030677 -3.52062389  2.57481444 -2.20749462 -1.86406784  1.03607796\n",
      " -3.48102887]\n",
      "[-1.39035961  1.53043843  0.11109741  0.6621853  -2.29024619  2.34249774\n",
      "  0.10030677 -3.52062389  2.57481444 -2.20749462 -1.86406784  1.03607796\n",
      " -3.48102887]\n",
      "[-1.39035961  1.53043843  0.11109741  0.6621853  -2.29024619  2.34249774\n",
      "  0.10030677 -3.52062389  2.57481444 -2.20749462 -1.86406784  1.03607796\n",
      " -3.48102887]\n"
     ]
    }
   ],
   "source": [
    "# 둘의 차이가 작은 것이 좋으므로 차이 구함 \n",
    "\n",
    "alpha_values = [0.,1.0,10,100]\n",
    "\n",
    "for value in alpha_values:\n",
    "    ridge_model = Ridge(alpha=value)\n",
    "    ridge_model = Ridge(alpha=1.0) # 기본값 1.0\n",
    "\n",
    "    result = cross_validate(ridge_model, x_train_scaled, y_train, cv = 3, scoring=['neg_mean_squared_error','r2'],\n",
    "                            return_train_score=True, return_estimator= True)\n",
    "    \n",
    "    result_df = pd.DataFrame(result)[['test_r2','train_r2']]\n",
    "\n",
    "    result_df['diff'] = abs(result_df['test_r2']- result_df['train_r2']) # 차이만 보면 되므로 절대값 사용 \n",
    "\n",
    "    print(result['estimator'][0].coef_) # 그냥 확인용\n",
    "\n",
    "    # print(f'[Ridge(alpha={value})]')\n",
    "    # print(result_df, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.41407793  1.56590993  0.15536906  0.65522098 -2.36200159  2.31948624\n",
      "  0.1173831  -3.59071105  2.71475429 -2.33252925 -1.88390034  1.04036915\n",
      " -3.50250877]\n",
      "[-1.39035961  1.53043843  0.11109741  0.6621853  -2.29024619  2.34249774\n",
      "  0.10030677 -3.52062389  2.57481444 -2.20749462 -1.86406784  1.03607796\n",
      " -3.48102887]\n",
      "[-1.23221033  1.29302258 -0.12737786  0.70280521 -1.80949922  2.48028701\n",
      " -0.00860666 -2.99831755  1.75466332 -1.51704375 -1.73434856  1.00368486\n",
      " -3.30809117]\n",
      "[-0.78141029  0.70910255 -0.46407849  0.72503917 -0.69294458  2.41757287\n",
      " -0.24148703 -1.21831206  0.28616643 -0.63423538 -1.31602563  0.78528977\n",
      " -2.39571659]\n"
     ]
    }
   ],
   "source": [
    "# 둘의 차이가 작은 것이 좋으므로 차이 구함 \n",
    "\n",
    "alpha_values = [0.,1.0,10,100]\n",
    "\n",
    "for value in alpha_values:\n",
    "    ridge_model = Ridge(alpha=value)\n",
    "\n",
    "    result = cross_validate(ridge_model, x_train_scaled, y_train, cv = 3, scoring=['neg_mean_squared_error','r2'],\n",
    "                            return_train_score=True, return_estimator= True)\n",
    "    \n",
    "    result_df = pd.DataFrame(result)[['test_r2','train_r2']]\n",
    "\n",
    "    result_df['diff'] = abs(result_df['test_r2']- result_df['train_r2']) # 차이만 보면 되므로 절대값 사용 \n",
    "\n",
    "    print(result['estimator'][0].coef_)\n",
    "\n",
    "    # print(f'[Ridge(alpha={value})]')\n",
    "    # print(result_df, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1*w1 + f2+w2 + ........ + fnwn + b 로 식이 만들어질 때 alpha를 통해 가중치를 조절하여 나온 계수값들이 위의 출력값 (?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.41407793  1.56590993  0.15536906  0.65522098 -2.36200159  2.31948624\n",
      "  0.1173831  -3.59071105  2.71475429 -2.33252925 -1.88390034  1.04036915\n",
      " -3.50250877]\n",
      "[-0.18119516  0.         -0.          0.         -0.          2.6706524\n",
      " -0.         -0.         -0.         -0.1542158  -1.17708874  0.36943757\n",
      " -3.33718723]\n",
      "[-0.  0. -0.  0. -0.  0. -0.  0. -0. -0. -0.  0. -0.]\n",
      "[-0.  0. -0.  0. -0.  0. -0.  0. -0. -0. -0.  0. -0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.537e+03, tolerance: 2.078e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.303e+03, tolerance: 1.772e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+03, tolerance: 2.045e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# 둘의 차이가 작은 것이 좋으므로 차이 구함 \n",
    "\n",
    "alpha_values = [0.,1.0,10,100]\n",
    "\n",
    "for value in alpha_values:\n",
    "    ridge_model = Lasso(alpha=value)\n",
    "    # ridge_model = Lasso(alpha=1.0) # 기본값 1.0\n",
    "\n",
    "    result = cross_validate(ridge_model, x_train_scaled, y_train, cv = 3, scoring=['neg_mean_squared_error','r2'],\n",
    "                            return_train_score=True, return_estimator= True)\n",
    "    \n",
    "    result_df = pd.DataFrame(result)[['test_r2','train_r2']]\n",
    "\n",
    "    result_df['diff'] = abs(result_df['test_r2']- result_df['train_r2']) # 차이만 보면 되므로 절대값 사용 \n",
    "\n",
    "    print(result['estimator'][0].coef_)\n",
    "\n",
    "    # print(f'[Ridge(alpha={value})]')\n",
    "    # print(result_df, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.76918209  1.30798802 -1.3660128   0.70871821 -1.12810945  3.13078874\n",
      "  0.20140226 -3.18951128  0.40006951 -1.02796444 -1.33246342  1.05170534\n",
      " -2.85931196]\n",
      "[-0.12685525  0.         -0.68948499  0.         -0.35867851  3.50097227\n",
      " -0.         -0.         -0.02775436 -0.34045443 -1.07046702  0.47097032\n",
      " -2.11146537]\n",
      "[-0.  0. -0.  0. -0.  0. -0.  0. -0. -0. -0.  0. -0.]\n",
      "[-0.  0. -0.  0. -0.  0. -0.  0. -0. -0. -0.  0. -0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.779e+03, tolerance: 2.078e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.500e+03, tolerance: 1.772e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+03, tolerance: 2.045e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.691e+02, tolerance: 2.078e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.640e+02, tolerance: 1.772e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\KDP-35\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+03, tolerance: 2.045e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# 둘의 차이가 작은 것이 좋으므로 차이 구함 \n",
    "\n",
    "alpha_values = [0.,1.0,10,100]\n",
    "\n",
    "for value in alpha_values:\n",
    "    ridge_model = Lasso(alpha=value, max_iter=3)\n",
    "\n",
    "    result = cross_validate(ridge_model, x_train_scaled, y_train, cv = 3, scoring=['neg_mean_squared_error','r2'],\n",
    "                            return_train_score=True, return_estimator= True)\n",
    "    \n",
    "    result_df = pd.DataFrame(result)[['test_r2','train_r2']]\n",
    "\n",
    "    result_df['diff'] = abs(result_df['test_r2']- result_df['train_r2']) # 차이만 보면 되므로 절대값 사용 \n",
    "\n",
    "    print(result['estimator'][0].coef_)\n",
    "\n",
    "    # print(f'[Ridge(alpha={value})]')\n",
    "    # print(result_df, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 데이터가 부족"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameter 튜닝과 교차 검증을 동시에 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge의 Hyper-parameter 값 설정 \n",
    "params = {'alpha' : [0,0.1,0.5,1.0], 'max_iter' : [3,5]}\n",
    "\n",
    "# -> 0., 3 => model\n",
    "# -> 0., 5 => model \n",
    "# --> 총 조합하면 8개 Ridge 모델 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인스턴스 생성 \n",
    "r_model = Ridge()\n",
    "\n",
    "search_cv = GridSearchCV(r_model, params, cv = 3, verbose= True, return_train_score=True) # default cv : 5\n",
    "\n",
    "# verbose = True : 진행상황 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0, 0.1, 0.5, 1.0], &#x27;max_iter&#x27;: [3, 5]},\n",
       "             return_train_score=True, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0, 0.1, 0.5, 1.0], &#x27;max_iter&#x27;: [3, 5]},\n",
       "             return_train_score=True, verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Ridge(),\n",
       "             param_grid={'alpha': [0, 0.1, 0.5, 1.0], 'max_iter': [3, 5]},\n",
       "             return_train_score=True, verbose=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 진행 \n",
    "search_cv.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fitting 3 folds for each of 8 candidates : 8개의 후보 모델 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'max_iter': 3}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit() 진행 후 모델 파라미터 확인 \n",
    "search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(max_iter=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(max_iter=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(max_iter=3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_cv.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00130113, 0.00096281, 0.00135573, 0.00066257, 0.00099723,\n",
       "        0.        , 0.00353797, 0.00066312]),\n",
       " 'std_fit_time': array([5.75806959e-04, 7.81058303e-04, 4.52098223e-04, 4.68523063e-04,\n",
       "        1.23630756e-06, 0.00000000e+00, 4.31193712e-03, 4.68899719e-04]),\n",
       " 'mean_score_time': array([0.00042311, 0.00127999, 0.00066336, 0.00090289, 0.00013622,\n",
       "        0.        , 0.00066463, 0.00033228]),\n",
       " 'std_score_time': array([0.00030149, 0.00116807, 0.00046907, 0.00013794, 0.00019264,\n",
       "        0.        , 0.00046999, 0.00046991]),\n",
       " 'param_alpha': masked_array(data=[0, 0, 0.1, 0.1, 0.5, 0.5, 1.0, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[3, 5, 3, 5, 3, 5, 3, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0, 'max_iter': 3},\n",
       "  {'alpha': 0, 'max_iter': 5},\n",
       "  {'alpha': 0.1, 'max_iter': 3},\n",
       "  {'alpha': 0.1, 'max_iter': 5},\n",
       "  {'alpha': 0.5, 'max_iter': 3},\n",
       "  {'alpha': 0.5, 'max_iter': 5},\n",
       "  {'alpha': 1.0, 'max_iter': 3},\n",
       "  {'alpha': 1.0, 'max_iter': 5}],\n",
       " 'split0_test_score': array([0.74702159, 0.74702159, 0.74715858, 0.74715858, 0.74768153,\n",
       "        0.74768153, 0.74828253, 0.74828253]),\n",
       " 'split1_test_score': array([0.75648166, 0.75648166, 0.75646183, 0.75646183, 0.75638454,\n",
       "        0.75638454, 0.75629228, 0.75629228]),\n",
       " 'split2_test_score': array([0.68080096, 0.68080096, 0.6808315 , 0.6808315 , 0.6809267 ,\n",
       "        0.6809267 , 0.68099104, 0.68099104]),\n",
       " 'mean_test_score': array([0.7281014 , 0.7281014 , 0.72815064, 0.72815064, 0.72833092,\n",
       "        0.72833092, 0.72852195, 0.72852195]),\n",
       " 'std_test_score': array([0.0336687 , 0.0336687 , 0.03367455, 0.03367455, 0.03370762,\n",
       "        0.03370762, 0.03376813, 0.03376813]),\n",
       " 'rank_test_score': array([7, 7, 5, 5, 3, 3, 1, 1]),\n",
       " 'split0_train_score': array([0.75572028, 0.75572028, 0.75571966, 0.75571966, 0.75570525,\n",
       "        0.75570525, 0.75566257, 0.75566257]),\n",
       " 'split1_train_score': array([0.74008153, 0.74008153, 0.74008107, 0.74008107, 0.74007048,\n",
       "        0.74007048, 0.74003888, 0.74003888]),\n",
       " 'split2_train_score': array([0.78615638, 0.78615638, 0.78615572, 0.78615572, 0.78614075,\n",
       "        0.78614075, 0.78609709, 0.78609709]),\n",
       " 'mean_train_score': array([0.76065273, 0.76065273, 0.76065215, 0.76065215, 0.76063883,\n",
       "        0.76063883, 0.76059951, 0.76059951]),\n",
       " 'std_train_score': array([0.0191306 , 0.0191306 , 0.01913052, 0.01913052, 0.01912891,\n",
       "        0.01912891, 0.0191245 , 0.0191245 ])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>{'alpha': 0, 'max_iter': 3}</td>\n",
       "      <td>0.747022</td>\n",
       "      <td>0.756482</td>\n",
       "      <td>0.680801</td>\n",
       "      <td>0.728101</td>\n",
       "      <td>0.033669</td>\n",
       "      <td>7</td>\n",
       "      <td>0.755720</td>\n",
       "      <td>0.740082</td>\n",
       "      <td>0.786156</td>\n",
       "      <td>0.760653</td>\n",
       "      <td>0.019131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 0, 'max_iter': 5}</td>\n",
       "      <td>0.747022</td>\n",
       "      <td>0.756482</td>\n",
       "      <td>0.680801</td>\n",
       "      <td>0.728101</td>\n",
       "      <td>0.033669</td>\n",
       "      <td>7</td>\n",
       "      <td>0.755720</td>\n",
       "      <td>0.740082</td>\n",
       "      <td>0.786156</td>\n",
       "      <td>0.760653</td>\n",
       "      <td>0.019131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'alpha': 0.1, 'max_iter': 3}</td>\n",
       "      <td>0.747159</td>\n",
       "      <td>0.756462</td>\n",
       "      <td>0.680831</td>\n",
       "      <td>0.728151</td>\n",
       "      <td>0.033675</td>\n",
       "      <td>5</td>\n",
       "      <td>0.755720</td>\n",
       "      <td>0.740081</td>\n",
       "      <td>0.786156</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.019131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 0.1, 'max_iter': 5}</td>\n",
       "      <td>0.747159</td>\n",
       "      <td>0.756462</td>\n",
       "      <td>0.680831</td>\n",
       "      <td>0.728151</td>\n",
       "      <td>0.033675</td>\n",
       "      <td>5</td>\n",
       "      <td>0.755720</td>\n",
       "      <td>0.740081</td>\n",
       "      <td>0.786156</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.019131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'alpha': 0.5, 'max_iter': 3}</td>\n",
       "      <td>0.747682</td>\n",
       "      <td>0.756385</td>\n",
       "      <td>0.680927</td>\n",
       "      <td>0.728331</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>3</td>\n",
       "      <td>0.755705</td>\n",
       "      <td>0.740070</td>\n",
       "      <td>0.786141</td>\n",
       "      <td>0.760639</td>\n",
       "      <td>0.019129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 0.5, 'max_iter': 5}</td>\n",
       "      <td>0.747682</td>\n",
       "      <td>0.756385</td>\n",
       "      <td>0.680927</td>\n",
       "      <td>0.728331</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>3</td>\n",
       "      <td>0.755705</td>\n",
       "      <td>0.740070</td>\n",
       "      <td>0.786141</td>\n",
       "      <td>0.760639</td>\n",
       "      <td>0.019129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>{'alpha': 1.0, 'max_iter': 3}</td>\n",
       "      <td>0.748283</td>\n",
       "      <td>0.756292</td>\n",
       "      <td>0.680991</td>\n",
       "      <td>0.728522</td>\n",
       "      <td>0.033768</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755663</td>\n",
       "      <td>0.740039</td>\n",
       "      <td>0.786097</td>\n",
       "      <td>0.760600</td>\n",
       "      <td>0.019124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 1.0, 'max_iter': 5}</td>\n",
       "      <td>0.748283</td>\n",
       "      <td>0.756292</td>\n",
       "      <td>0.680991</td>\n",
       "      <td>0.728522</td>\n",
       "      <td>0.033768</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755663</td>\n",
       "      <td>0.740039</td>\n",
       "      <td>0.786097</td>\n",
       "      <td>0.760600</td>\n",
       "      <td>0.019124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.001301      0.000576         0.000423        0.000301           0   \n",
       "1       0.000963      0.000781         0.001280        0.001168           0   \n",
       "2       0.001356      0.000452         0.000663        0.000469         0.1   \n",
       "3       0.000663      0.000469         0.000903        0.000138         0.1   \n",
       "4       0.000997      0.000001         0.000136        0.000193         0.5   \n",
       "5       0.000000      0.000000         0.000000        0.000000         0.5   \n",
       "6       0.003538      0.004312         0.000665        0.000470         1.0   \n",
       "7       0.000663      0.000469         0.000332        0.000470         1.0   \n",
       "\n",
       "  param_max_iter                         params  split0_test_score  \\\n",
       "0              3    {'alpha': 0, 'max_iter': 3}           0.747022   \n",
       "1              5    {'alpha': 0, 'max_iter': 5}           0.747022   \n",
       "2              3  {'alpha': 0.1, 'max_iter': 3}           0.747159   \n",
       "3              5  {'alpha': 0.1, 'max_iter': 5}           0.747159   \n",
       "4              3  {'alpha': 0.5, 'max_iter': 3}           0.747682   \n",
       "5              5  {'alpha': 0.5, 'max_iter': 5}           0.747682   \n",
       "6              3  {'alpha': 1.0, 'max_iter': 3}           0.748283   \n",
       "7              5  {'alpha': 1.0, 'max_iter': 5}           0.748283   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.756482           0.680801         0.728101        0.033669   \n",
       "1           0.756482           0.680801         0.728101        0.033669   \n",
       "2           0.756462           0.680831         0.728151        0.033675   \n",
       "3           0.756462           0.680831         0.728151        0.033675   \n",
       "4           0.756385           0.680927         0.728331        0.033708   \n",
       "5           0.756385           0.680927         0.728331        0.033708   \n",
       "6           0.756292           0.680991         0.728522        0.033768   \n",
       "7           0.756292           0.680991         0.728522        0.033768   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                7            0.755720            0.740082   \n",
       "1                7            0.755720            0.740082   \n",
       "2                5            0.755720            0.740081   \n",
       "3                5            0.755720            0.740081   \n",
       "4                3            0.755705            0.740070   \n",
       "5                3            0.755705            0.740070   \n",
       "6                1            0.755663            0.740039   \n",
       "7                1            0.755663            0.740039   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.786156          0.760653         0.019131  \n",
       "1            0.786156          0.760653         0.019131  \n",
       "2            0.786156          0.760652         0.019131  \n",
       "3            0.786156          0.760652         0.019131  \n",
       "4            0.786141          0.760639         0.019129  \n",
       "5            0.786141          0.760639         0.019129  \n",
       "6            0.786097          0.760600         0.019124  \n",
       "7            0.786097          0.760600         0.019124  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 내용이 dict 라서 dict 에 넣음 \n",
    "\n",
    "result_df = pd.DataFrame(search_cv.cv_results_)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
