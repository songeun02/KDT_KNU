{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결정 트리 알고리즘 기반 모델\n",
    "- 데이터셋의 피쳐(특성)을 기준으로 데이터를 분류하는 알고리즘 \n",
    "- 질문방식으로 Yes/No 결과에 따라 데이터셋 분리\n",
    "- 장점 : 스케일링이나 정규화 불필요 (성능에 영향 x), 쉬운 알고리즘 \n",
    "- 단점 : 과대적합 --> 해결을 위한 많은 Hyper Parameter 존재\n",
    "- 다른 ML 알고리즘에 비해 성능 x --> 단, 여러개의 decision tree가 모이면 성능이 강해짐 \n",
    "    - 앙상블에 주로 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] 모듈 로딩 및 데이터 준비\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as npp\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_df : (150, 4), 2D\n",
      "target_sr : (150,), 1D\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로딩 \n",
    "feature_df, target_sr = load_iris(as_frame=True, return_X_y=True) # return_X_y : 리턴 값으로 feature X와 target y가 리턴\n",
    "\n",
    "print(f'feature_df : {feature_df.shape}, {feature_df.ndim}D')\n",
    "print(f'target_sr : {target_sr.shape}, {target_sr.ndim}D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] 학습용 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(feature_df, target_sr, random_state=10, stratify=target_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train : (112, 4), 2D\n",
      "x_test : (38, 4), 2D\n",
      "y_train : (112,), 1D\n",
      "y_test : (38,), 1D\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train : {x_train.shape}, {x_train.ndim}D')\n",
    "print(f'x_test : {x_test.shape}, {x_test.ndim}D')\n",
    "\n",
    "print(f'y_train : {y_train.shape}, {y_train.ndim}D')\n",
    "print(f'y_test : {y_test.shape}, {y_test.ndim}D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] 학습 - 기본학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 인스턴스 생성 \n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=10)\n",
    "dt_model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dt_model.classes_] [0 1 2]\n",
      "[dt_model.n_classes_] 3개\n",
      "[dt_model.max_features_] 4개\n",
      "[dt_model.feature_names_in_] ['sepal length (cm)' 'sepal width (cm)' 'petal length (cm)'\n",
      " 'petal width (cm)']개\n",
      "[dt_model.feature_importances_] [0.03125249 0.         0.06844775 0.90029976]\n"
     ]
    }
   ],
   "source": [
    "# 모델 파라미터 : 학습 fit() 후에 학습용 데이터셋을 기반으로 설정된 값들 \n",
    "\n",
    "print(f'[dt_model.classes_] {dt_model.classes_}')\n",
    "print(f'[dt_model.n_classes_] {dt_model.n_classes_}개')\n",
    "print(f'[dt_model.max_features_] {dt_model.max_features_}개') # 모든 feature 사용 -> 개수 반환 \n",
    "print(f'[dt_model.feature_names_in_] {dt_model.feature_names_in_}개') # feature 이름 반환 -> 주요 feature 파악 ㅇ \n",
    "print(f'[dt_model.feature_importances_] {dt_model.feature_importances_}') # feature 중요도 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] 성능 체크 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score : 1.0, test_score : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 학습용 데이터셋에 대한 성능 \n",
    "train_score = dt_model.score(x_train, y_train)\n",
    "\n",
    "# 테스트용 데이터셋에 대한 성능\n",
    "test_score = dt_model.score(x_test, y_test)\n",
    "\n",
    "print(f'train_score : {train_score}, test_score : {test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 과대적합 (데이터셋이 너무 작아서)\n",
    "\n",
    "=> cross_validate 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [5] 교차검증 \n",
    "\n",
    "=> 데이터셋 부족 해결 및 과대적합 회피"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 데이터는 분류\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.        , 0.01584554, 0.        , 0.        , 0.        ]),\n",
       " 'score_time': array([0., 0., 0., 0., 0.]),\n",
       " 'estimator': [DecisionTreeClassifier(random_state=1),\n",
       "  DecisionTreeClassifier(random_state=1),\n",
       "  DecisionTreeClassifier(random_state=1),\n",
       "  DecisionTreeClassifier(random_state=1),\n",
       "  DecisionTreeClassifier(random_state=1)],\n",
       " 'test_score': array([0.95652174, 0.95652174, 0.95454545, 0.86363636, 0.90909091]),\n",
       " 'train_score': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교차검증 준비 => 모델 인스턴스, trainDS, cv = 5(default)\n",
    "\n",
    "# 새로운 모델 필요 -> 위에서는 Decision Tree 사용\n",
    "dt_model2 = DecisionTreeClassifier(random_state=1)\n",
    "cross_validate(dt_model2, x_train, y_train, return_train_score=True, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cross_validate(dt_model2, x_train, y_train, return_train_score=True, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>estimator</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>DecisionTreeClassifier(random_state=1)</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>DecisionTreeClassifier(random_state=1)</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>DecisionTreeClassifier(random_state=1)</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>DecisionTreeClassifier(random_state=1)</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>DecisionTreeClassifier(random_state=1)</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time                               estimator  test_score  \\\n",
       "0  0.000000    0.000000  DecisionTreeClassifier(random_state=1)    0.956522   \n",
       "1  0.002887    0.000000  DecisionTreeClassifier(random_state=1)    0.956522   \n",
       "2  0.000000    0.000000  DecisionTreeClassifier(random_state=1)    0.954545   \n",
       "3  0.000000    0.000000  DecisionTreeClassifier(random_state=1)    0.863636   \n",
       "4  0.012593    0.001205  DecisionTreeClassifier(random_state=1)    0.909091   \n",
       "\n",
       "   train_score  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "3          1.0  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict => DataFrame\n",
    "result_df = pd.DataFrame(result)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능향상 판단 \n",
    " -> train_score보다 test_score가 낮아서 과대적합이라 판단하고 train_score와 test_score가 비슷한게 가장 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [6] 성능 향상을 위한 튜닝 => 하이퍼 파라미터 설정\n",
    "- 단점 : 과대적합\n",
    "    - max_depth, min_samples_leaf, ..... \n",
    "    - Decision Tree는 하이퍼 파라미터 많음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 dict 생성 \n",
    "params = {'max_depth' : [4,3,2,1], \n",
    "          'min_samples_leaf' : [5,3,2]} # 리프 노드에 있어야 할 최소 샘플 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [4, 3, 2, 1],\n",
       "                         &#x27;min_samples_leaf&#x27;: [5, 3, 2]},\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [4, 3, 2, 1],\n",
       "                         &#x27;min_samples_leaf&#x27;: [5, 3, 2]},\n",
       "             return_train_score=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [4, 3, 2, 1],\n",
       "                         'min_samples_leaf': [5, 3, 2]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv= GridSearchCV(DecisionTreeClassifier(), param_grid=params, refit = True, return_train_score=True)\n",
    "# refit : 가장 좋은 esimator로 자동 학습 - GridSearchCV에만 존재\n",
    "gs_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gs_cv.best_params_] {'max_depth': 4, 'min_samples_leaf': 2}\n",
      "[gs_cv.best_score_] 0.9371541501976285\n",
      "[gs_cv.best_estimator_] DecisionTreeClassifier(max_depth=4, min_samples_leaf=2)\n",
      "[gs_cv.cv_results_]\n",
      " {'mean_fit_time': array([0.00385799, 0.00230212, 0.00025177, 0.0014153 , 0.00159931,\n",
      "       0.        , 0.00314298, 0.00312519, 0.        , 0.00312285,\n",
      "       0.        , 0.        ]), 'std_fit_time': array([0.00605542, 0.00250122, 0.00050354, 0.0028306 , 0.00319862,\n",
      "       0.        , 0.00628595, 0.00625038, 0.        , 0.00624571,\n",
      "       0.        , 0.        ]), 'mean_score_time': array([0.00133686, 0.00242872, 0.        , 0.00321589, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.00312409, 0.        ,\n",
      "       0.        , 0.        ]), 'std_score_time': array([0.00179643, 0.00344845, 0.        , 0.00393872, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.00624819, 0.        ,\n",
      "       0.        , 0.        ]), 'param_max_depth': masked_array(data=[4, 4, 4, 3, 3, 3, 2, 2, 2, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_leaf': masked_array(data=[5, 3, 2, 5, 3, 2, 5, 3, 2, 5, 3, 2],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 4, 'min_samples_leaf': 5}, {'max_depth': 4, 'min_samples_leaf': 3}, {'max_depth': 4, 'min_samples_leaf': 2}, {'max_depth': 3, 'min_samples_leaf': 5}, {'max_depth': 3, 'min_samples_leaf': 3}, {'max_depth': 3, 'min_samples_leaf': 2}, {'max_depth': 2, 'min_samples_leaf': 5}, {'max_depth': 2, 'min_samples_leaf': 3}, {'max_depth': 2, 'min_samples_leaf': 2}, {'max_depth': 1, 'min_samples_leaf': 5}, {'max_depth': 1, 'min_samples_leaf': 3}, {'max_depth': 1, 'min_samples_leaf': 2}], 'split0_test_score': array([0.91304348, 0.91304348, 0.95652174, 0.91304348, 0.91304348,\n",
      "       0.91304348, 0.91304348, 0.91304348, 0.91304348, 0.65217391,\n",
      "       0.65217391, 0.65217391]), 'split1_test_score': array([0.95652174, 0.95652174, 0.95652174, 0.95652174, 0.95652174,\n",
      "       0.95652174, 0.95652174, 0.95652174, 0.95652174, 0.65217391,\n",
      "       0.65217391, 0.65217391]), 'split2_test_score': array([0.95454545, 0.95454545, 0.95454545, 0.95454545, 0.95454545,\n",
      "       0.95454545, 0.95454545, 0.95454545, 0.95454545, 0.68181818,\n",
      "       0.68181818, 0.68181818]), 'split3_test_score': array([0.86363636, 0.86363636, 0.90909091, 0.86363636, 0.86363636,\n",
      "       0.86363636, 0.90909091, 0.90909091, 0.90909091, 0.63636364,\n",
      "       0.63636364, 0.63636364]), 'split4_test_score': array([0.95454545, 0.90909091, 0.90909091, 0.95454545, 0.90909091,\n",
      "       0.90909091, 0.90909091, 0.90909091, 0.90909091, 0.63636364,\n",
      "       0.63636364, 0.63636364]), 'mean_test_score': array([0.9284585 , 0.91936759, 0.93715415, 0.9284585 , 0.91936759,\n",
      "       0.91936759, 0.9284585 , 0.9284585 , 0.9284585 , 0.65177866,\n",
      "       0.65177866, 0.65177866]), 'std_test_score': array([0.03629914, 0.03426219, 0.0229249 , 0.03629914, 0.03426219,\n",
      "       0.03426219, 0.0221626 , 0.0221626 , 0.0221626 , 0.01660079,\n",
      "       0.01660079, 0.01660079]), 'rank_test_score': array([ 2,  7,  1,  2,  7,  7,  2,  2,  2, 10, 10, 10]), 'split0_train_score': array([0.95505618, 0.95505618, 0.97752809, 0.95505618, 0.95505618,\n",
      "       0.95505618, 0.95505618, 0.95505618, 0.95505618, 0.6741573 ,\n",
      "       0.6741573 , 0.6741573 ]), 'split1_train_score': array([0.94382022, 0.97752809, 0.97752809, 0.94382022, 0.95505618,\n",
      "       0.95505618, 0.94382022, 0.94382022, 0.94382022, 0.6741573 ,\n",
      "       0.6741573 , 0.6741573 ]), 'split2_train_score': array([0.96666667, 0.96666667, 0.96666667, 0.94444444, 0.96666667,\n",
      "       0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.66666667,\n",
      "       0.66666667, 0.66666667]), 'split3_train_score': array([0.95555556, 0.96666667, 0.97777778, 0.95555556, 0.95555556,\n",
      "       0.95555556, 0.95555556, 0.95555556, 0.95555556, 0.67777778,\n",
      "       0.67777778, 0.67777778]), 'split4_train_score': array([0.96666667, 0.97777778, 0.97777778, 0.96666667, 0.97777778,\n",
      "       0.97777778, 0.95555556, 0.95555556, 0.95555556, 0.67777778,\n",
      "       0.67777778, 0.67777778]), 'mean_train_score': array([0.95755306, 0.96873908, 0.97545568, 0.95310861, 0.96202247,\n",
      "       0.95757803, 0.95088639, 0.95088639, 0.95088639, 0.67410737,\n",
      "       0.67410737, 0.67410737]), 'std_train_score': array([0.00854319, 0.00842326, 0.00439593, 0.00842548, 0.00904077,\n",
      "       0.01093006, 0.00552121, 0.00552121, 0.00552121, 0.00405741,\n",
      "       0.00405741, 0.00405741])}\n"
     ]
    }
   ],
   "source": [
    "# 모델 파라미터 확인 \n",
    "print(f'[gs_cv.best_params_] {gs_cv.best_params_}')\n",
    "print(f'[gs_cv.best_score_] {gs_cv.best_score_}')\n",
    "print(f'[gs_cv.best_estimator_] {gs_cv.best_estimator_}')\n",
    "print(f'[gs_cv.cv_results_]\\n {gs_cv.cv_results_}')\n",
    "\n",
    "cv_result_df= pd.DataFrame(gs_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003858</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928458</td>\n",
       "      <td>0.036299</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.957553</td>\n",
       "      <td>0.008543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919368</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>7</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.968739</td>\n",
       "      <td>0.008423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937154</td>\n",
       "      <td>0.022925</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.975456</td>\n",
       "      <td>0.004396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.003939</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928458</td>\n",
       "      <td>0.036299</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.953109</td>\n",
       "      <td>0.008425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919368</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>7</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.962022</td>\n",
       "      <td>0.009041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919368</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>7</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.957578</td>\n",
       "      <td>0.010930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928458</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.950886</td>\n",
       "      <td>0.005521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928458</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.950886</td>\n",
       "      <td>0.005521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928458</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.950886</td>\n",
       "      <td>0.005521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651779</td>\n",
       "      <td>0.016601</td>\n",
       "      <td>10</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.674107</td>\n",
       "      <td>0.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651779</td>\n",
       "      <td>0.016601</td>\n",
       "      <td>10</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.674107</td>\n",
       "      <td>0.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651779</td>\n",
       "      <td>0.016601</td>\n",
       "      <td>10</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.674107</td>\n",
       "      <td>0.004057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.003858      0.006055         0.001337        0.001796   \n",
       "1        0.002302      0.002501         0.002429        0.003448   \n",
       "2        0.000252      0.000504         0.000000        0.000000   \n",
       "3        0.001415      0.002831         0.003216        0.003939   \n",
       "4        0.001599      0.003199         0.000000        0.000000   \n",
       "5        0.000000      0.000000         0.000000        0.000000   \n",
       "6        0.003143      0.006286         0.000000        0.000000   \n",
       "7        0.003125      0.006250         0.000000        0.000000   \n",
       "8        0.000000      0.000000         0.003124        0.006248   \n",
       "9        0.003123      0.006246         0.000000        0.000000   \n",
       "10       0.000000      0.000000         0.000000        0.000000   \n",
       "11       0.000000      0.000000         0.000000        0.000000   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf  \\\n",
       "0                4                      5   \n",
       "1                4                      3   \n",
       "2                4                      2   \n",
       "3                3                      5   \n",
       "4                3                      3   \n",
       "5                3                      2   \n",
       "6                2                      5   \n",
       "7                2                      3   \n",
       "8                2                      2   \n",
       "9                1                      5   \n",
       "10               1                      3   \n",
       "11               1                      2   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0   {'max_depth': 4, 'min_samples_leaf': 5}           0.913043   \n",
       "1   {'max_depth': 4, 'min_samples_leaf': 3}           0.913043   \n",
       "2   {'max_depth': 4, 'min_samples_leaf': 2}           0.956522   \n",
       "3   {'max_depth': 3, 'min_samples_leaf': 5}           0.913043   \n",
       "4   {'max_depth': 3, 'min_samples_leaf': 3}           0.913043   \n",
       "5   {'max_depth': 3, 'min_samples_leaf': 2}           0.913043   \n",
       "6   {'max_depth': 2, 'min_samples_leaf': 5}           0.913043   \n",
       "7   {'max_depth': 2, 'min_samples_leaf': 3}           0.913043   \n",
       "8   {'max_depth': 2, 'min_samples_leaf': 2}           0.913043   \n",
       "9   {'max_depth': 1, 'min_samples_leaf': 5}           0.652174   \n",
       "10  {'max_depth': 1, 'min_samples_leaf': 3}           0.652174   \n",
       "11  {'max_depth': 1, 'min_samples_leaf': 2}           0.652174   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "0            0.956522           0.954545  ...         0.928458   \n",
       "1            0.956522           0.954545  ...         0.919368   \n",
       "2            0.956522           0.954545  ...         0.937154   \n",
       "3            0.956522           0.954545  ...         0.928458   \n",
       "4            0.956522           0.954545  ...         0.919368   \n",
       "5            0.956522           0.954545  ...         0.919368   \n",
       "6            0.956522           0.954545  ...         0.928458   \n",
       "7            0.956522           0.954545  ...         0.928458   \n",
       "8            0.956522           0.954545  ...         0.928458   \n",
       "9            0.652174           0.681818  ...         0.651779   \n",
       "10           0.652174           0.681818  ...         0.651779   \n",
       "11           0.652174           0.681818  ...         0.651779   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.036299                2            0.955056            0.943820   \n",
       "1         0.034262                7            0.955056            0.977528   \n",
       "2         0.022925                1            0.977528            0.977528   \n",
       "3         0.036299                2            0.955056            0.943820   \n",
       "4         0.034262                7            0.955056            0.955056   \n",
       "5         0.034262                7            0.955056            0.955056   \n",
       "6         0.022163                2            0.955056            0.943820   \n",
       "7         0.022163                2            0.955056            0.943820   \n",
       "8         0.022163                2            0.955056            0.943820   \n",
       "9         0.016601               10            0.674157            0.674157   \n",
       "10        0.016601               10            0.674157            0.674157   \n",
       "11        0.016601               10            0.674157            0.674157   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.966667            0.955556            0.966667   \n",
       "1             0.966667            0.966667            0.977778   \n",
       "2             0.966667            0.977778            0.977778   \n",
       "3             0.944444            0.955556            0.966667   \n",
       "4             0.966667            0.955556            0.977778   \n",
       "5             0.944444            0.955556            0.977778   \n",
       "6             0.944444            0.955556            0.955556   \n",
       "7             0.944444            0.955556            0.955556   \n",
       "8             0.944444            0.955556            0.955556   \n",
       "9             0.666667            0.677778            0.677778   \n",
       "10            0.666667            0.677778            0.677778   \n",
       "11            0.666667            0.677778            0.677778   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.957553         0.008543  \n",
       "1           0.968739         0.008423  \n",
       "2           0.975456         0.004396  \n",
       "3           0.953109         0.008425  \n",
       "4           0.962022         0.009041  \n",
       "5           0.957578         0.010930  \n",
       "6           0.950886         0.005521  \n",
       "7           0.950886         0.005521  \n",
       "8           0.950886         0.005521  \n",
       "9           0.674107         0.004057  \n",
       "10          0.674107         0.004057  \n",
       "11          0.674107         0.004057  \n",
       "\n",
       "[12 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_max_depth', 'param_min_samples_leaf', 'params',\n",
       "       'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
       "       'split3_test_score', 'split4_test_score', 'mean_test_score',\n",
       "       'std_test_score', 'rank_test_score', 'split0_train_score',\n",
       "       'split1_train_score', 'split2_train_score', 'split3_train_score',\n",
       "       'split4_train_score', 'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003858</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928458</td>\n",
       "      <td>0.036299</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.957553</td>\n",
       "      <td>0.008543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919368</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>7</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.968739</td>\n",
       "      <td>0.008423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937154</td>\n",
       "      <td>0.022925</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.975456</td>\n",
       "      <td>0.004396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.003939</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928458</td>\n",
       "      <td>0.036299</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.953109</td>\n",
       "      <td>0.008425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919368</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>7</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.962022</td>\n",
       "      <td>0.009041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919368</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>7</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.957578</td>\n",
       "      <td>0.010930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928458</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.950886</td>\n",
       "      <td>0.005521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928458</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.950886</td>\n",
       "      <td>0.005521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928458</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.950886</td>\n",
       "      <td>0.005521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651779</td>\n",
       "      <td>0.016601</td>\n",
       "      <td>10</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.674107</td>\n",
       "      <td>0.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651779</td>\n",
       "      <td>0.016601</td>\n",
       "      <td>10</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.674107</td>\n",
       "      <td>0.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651779</td>\n",
       "      <td>0.016601</td>\n",
       "      <td>10</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.674107</td>\n",
       "      <td>0.004057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.003858      0.006055         0.001337        0.001796   \n",
       "1        0.002302      0.002501         0.002429        0.003448   \n",
       "2        0.000252      0.000504         0.000000        0.000000   \n",
       "3        0.001415      0.002831         0.003216        0.003939   \n",
       "4        0.001599      0.003199         0.000000        0.000000   \n",
       "5        0.000000      0.000000         0.000000        0.000000   \n",
       "6        0.003143      0.006286         0.000000        0.000000   \n",
       "7        0.003125      0.006250         0.000000        0.000000   \n",
       "8        0.000000      0.000000         0.003124        0.006248   \n",
       "9        0.003123      0.006246         0.000000        0.000000   \n",
       "10       0.000000      0.000000         0.000000        0.000000   \n",
       "11       0.000000      0.000000         0.000000        0.000000   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf  \\\n",
       "0                4                      5   \n",
       "1                4                      3   \n",
       "2                4                      2   \n",
       "3                3                      5   \n",
       "4                3                      3   \n",
       "5                3                      2   \n",
       "6                2                      5   \n",
       "7                2                      3   \n",
       "8                2                      2   \n",
       "9                1                      5   \n",
       "10               1                      3   \n",
       "11               1                      2   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0   {'max_depth': 4, 'min_samples_leaf': 5}           0.913043   \n",
       "1   {'max_depth': 4, 'min_samples_leaf': 3}           0.913043   \n",
       "2   {'max_depth': 4, 'min_samples_leaf': 2}           0.956522   \n",
       "3   {'max_depth': 3, 'min_samples_leaf': 5}           0.913043   \n",
       "4   {'max_depth': 3, 'min_samples_leaf': 3}           0.913043   \n",
       "5   {'max_depth': 3, 'min_samples_leaf': 2}           0.913043   \n",
       "6   {'max_depth': 2, 'min_samples_leaf': 5}           0.913043   \n",
       "7   {'max_depth': 2, 'min_samples_leaf': 3}           0.913043   \n",
       "8   {'max_depth': 2, 'min_samples_leaf': 2}           0.913043   \n",
       "9   {'max_depth': 1, 'min_samples_leaf': 5}           0.652174   \n",
       "10  {'max_depth': 1, 'min_samples_leaf': 3}           0.652174   \n",
       "11  {'max_depth': 1, 'min_samples_leaf': 2}           0.652174   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "0            0.956522           0.954545  ...         0.928458   \n",
       "1            0.956522           0.954545  ...         0.919368   \n",
       "2            0.956522           0.954545  ...         0.937154   \n",
       "3            0.956522           0.954545  ...         0.928458   \n",
       "4            0.956522           0.954545  ...         0.919368   \n",
       "5            0.956522           0.954545  ...         0.919368   \n",
       "6            0.956522           0.954545  ...         0.928458   \n",
       "7            0.956522           0.954545  ...         0.928458   \n",
       "8            0.956522           0.954545  ...         0.928458   \n",
       "9            0.652174           0.681818  ...         0.651779   \n",
       "10           0.652174           0.681818  ...         0.651779   \n",
       "11           0.652174           0.681818  ...         0.651779   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.036299                2            0.955056            0.943820   \n",
       "1         0.034262                7            0.955056            0.977528   \n",
       "2         0.022925                1            0.977528            0.977528   \n",
       "3         0.036299                2            0.955056            0.943820   \n",
       "4         0.034262                7            0.955056            0.955056   \n",
       "5         0.034262                7            0.955056            0.955056   \n",
       "6         0.022163                2            0.955056            0.943820   \n",
       "7         0.022163                2            0.955056            0.943820   \n",
       "8         0.022163                2            0.955056            0.943820   \n",
       "9         0.016601               10            0.674157            0.674157   \n",
       "10        0.016601               10            0.674157            0.674157   \n",
       "11        0.016601               10            0.674157            0.674157   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.966667            0.955556            0.966667   \n",
       "1             0.966667            0.966667            0.977778   \n",
       "2             0.966667            0.977778            0.977778   \n",
       "3             0.944444            0.955556            0.966667   \n",
       "4             0.966667            0.955556            0.977778   \n",
       "5             0.944444            0.955556            0.977778   \n",
       "6             0.944444            0.955556            0.955556   \n",
       "7             0.944444            0.955556            0.955556   \n",
       "8             0.944444            0.955556            0.955556   \n",
       "9             0.666667            0.677778            0.677778   \n",
       "10            0.666667            0.677778            0.677778   \n",
       "11            0.666667            0.677778            0.677778   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.957553         0.008543  \n",
       "1           0.968739         0.008423  \n",
       "2           0.975456         0.004396  \n",
       "3           0.953109         0.008425  \n",
       "4           0.962022         0.009041  \n",
       "5           0.957578         0.010930  \n",
       "6           0.950886         0.005521  \n",
       "7           0.950886         0.005521  \n",
       "8           0.950886         0.005521  \n",
       "9           0.674107         0.004057  \n",
       "10          0.674107         0.004057  \n",
       "11          0.674107         0.004057  \n",
       "\n",
       "[12 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[best_model.max_depth] : 4\n",
      "[best_model.min_samples_leaf] : 2\n"
     ]
    }
   ],
   "source": [
    "# 가장 좋은 모델 \n",
    "best_model = gs_cv.best_estimator_\n",
    "print(f'[best_model.max_depth] : {best_model.max_depth}')\n",
    "print(f'[best_model.min_samples_leaf] : {best_model.min_samples_leaf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.01321873, 0.        , 0.07164651, 0.91513476]), 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피쳐 중요도 및 개수\n",
    "best_model.feature_importances_, best_model.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.barh(range(best_model.n_features_in_), best_model.feature_importances_, align='center')\n",
    "plt.yticks(np.arange(best_model.n_features_in_), best_model.feature_names_in_)\n",
    "plt.xlabel('[Feature Importance]')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [7] DT 그래프 시각화\n",
    "- Graphviz 프로그램(os에 맞는 버전) 설치 + python용 패키지 graphviz 설치\n",
    "- 트리는 dot파일 형태로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] DT 모델을 dot 포맷의 파일로 저장 ==> export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]),\n",
       " array([0, 1, 2]),\n",
       " array(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
       "        'petal width (cm)'], dtype=object))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.classes_, target_sr.unique(), best_model.feature_names_in_\n",
    "# classes_ : 변환된 인코딩의 원본값 보유 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(best_model, out_file='tree.dot', \n",
    "                class_names=['setosa','versicolor','verginica'], feature_names=best_model.feature_names_in_,\n",
    "                impurity=True, filled=True , rounded=True)\n",
    "\n",
    "# filled=True : 색 알록달록 , rounded=True : 테두리 둥글둥글, rotate = True : 옆으로 돌림 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] dot파일 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.1.0 (20240811.2233)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"741pt\" height=\"570pt\"\n",
       " viewBox=\"0.00 0.00 741.38 570.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 566)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-566 737.38,-566 737.38,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#fffdfc\" stroke=\"black\" d=\"M439.5,-562C439.5,-562 308.75,-562 308.75,-562 302.75,-562 296.75,-556 296.75,-550 296.75,-550 296.75,-487.25 296.75,-487.25 296.75,-481.25 302.75,-475.25 308.75,-475.25 308.75,-475.25 439.5,-475.25 439.5,-475.25 445.5,-475.25 451.5,-481.25 451.5,-487.25 451.5,-487.25 451.5,-550 451.5,-550 451.5,-556 445.5,-562 439.5,-562\"/>\n",
       "<text text-anchor=\"middle\" x=\"374.12\" y=\"-544.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) &lt;= 0.8</text>\n",
       "<text text-anchor=\"middle\" x=\"374.12\" y=\"-528.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.667</text>\n",
       "<text text-anchor=\"middle\" x=\"374.12\" y=\"-513.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 112</text>\n",
       "<text text-anchor=\"middle\" x=\"374.12\" y=\"-497.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [38, 37, 37]</text>\n",
       "<text text-anchor=\"middle\" x=\"374.12\" y=\"-481.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M342.38,-431.38C342.38,-431.38 249.88,-431.38 249.88,-431.38 243.88,-431.38 237.88,-425.38 237.88,-419.38 237.88,-419.38 237.88,-372.38 237.88,-372.38 237.88,-366.38 243.88,-360.38 249.88,-360.38 249.88,-360.38 342.38,-360.38 342.38,-360.38 348.38,-360.38 354.38,-366.38 354.38,-372.38 354.38,-372.38 354.38,-419.38 354.38,-419.38 354.38,-425.38 348.38,-431.38 342.38,-431.38\"/>\n",
       "<text text-anchor=\"middle\" x=\"296.12\" y=\"-414.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"296.12\" y=\"-398.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 38</text>\n",
       "<text text-anchor=\"middle\" x=\"296.12\" y=\"-382.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [38, 0, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"296.12\" y=\"-366.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M346.63,-475.05C339.5,-464.02 331.82,-452.13 324.64,-441.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"327.68,-439.28 319.32,-432.77 321.8,-443.07 327.68,-439.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"313.24\" y=\"-450.52\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M522.25,-439.25C522.25,-439.25 384,-439.25 384,-439.25 378,-439.25 372,-433.25 372,-427.25 372,-427.25 372,-364.5 372,-364.5 372,-358.5 378,-352.5 384,-352.5 384,-352.5 522.25,-352.5 522.25,-352.5 528.25,-352.5 534.25,-358.5 534.25,-364.5 534.25,-364.5 534.25,-427.25 534.25,-427.25 534.25,-433.25 528.25,-439.25 522.25,-439.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"453.12\" y=\"-421.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) &lt;= 1.75</text>\n",
       "<text text-anchor=\"middle\" x=\"453.12\" y=\"-406.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"453.12\" y=\"-390.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 74</text>\n",
       "<text text-anchor=\"middle\" x=\"453.12\" y=\"-374.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 37, 37]</text>\n",
       "<text text-anchor=\"middle\" x=\"453.12\" y=\"-358.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M401.98,-475.05C407.52,-466.58 413.41,-457.59 419.13,-448.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"421.88,-451.02 424.43,-440.74 416.03,-447.19 421.88,-451.02\"/>\n",
       "<text text-anchor=\"middle\" x=\"430.37\" y=\"-458.52\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#54e992\" stroke=\"black\" d=\"M431.88,-316.5C431.88,-316.5 288.38,-316.5 288.38,-316.5 282.38,-316.5 276.38,-310.5 276.38,-304.5 276.38,-304.5 276.38,-241.75 276.38,-241.75 276.38,-235.75 282.38,-229.75 288.38,-229.75 288.38,-229.75 431.88,-229.75 431.88,-229.75 437.88,-229.75 443.88,-235.75 443.88,-241.75 443.88,-241.75 443.88,-304.5 443.88,-304.5 443.88,-310.5 437.88,-316.5 431.88,-316.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"360.12\" y=\"-299.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) &lt;= 4.95</text>\n",
       "<text text-anchor=\"middle\" x=\"360.12\" y=\"-283.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.214</text>\n",
       "<text text-anchor=\"middle\" x=\"360.12\" y=\"-267.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 41</text>\n",
       "<text text-anchor=\"middle\" x=\"360.12\" y=\"-251.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 36, 5]</text>\n",
       "<text text-anchor=\"middle\" x=\"360.12\" y=\"-236.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M420.34,-352.3C413.74,-343.74 406.74,-334.64 399.93,-325.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"402.73,-323.71 393.85,-317.92 397.18,-327.98 402.73,-323.71\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#853fe6\" stroke=\"black\" d=\"M617.88,-316.5C617.88,-316.5 474.38,-316.5 474.38,-316.5 468.38,-316.5 462.38,-310.5 462.38,-304.5 462.38,-304.5 462.38,-241.75 462.38,-241.75 462.38,-235.75 468.38,-229.75 474.38,-229.75 474.38,-229.75 617.88,-229.75 617.88,-229.75 623.88,-229.75 629.88,-235.75 629.88,-241.75 629.88,-241.75 629.88,-304.5 629.88,-304.5 629.88,-310.5 623.88,-316.5 617.88,-316.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"546.12\" y=\"-299.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) &lt;= 4.85</text>\n",
       "<text text-anchor=\"middle\" x=\"546.12\" y=\"-283.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.059</text>\n",
       "<text text-anchor=\"middle\" x=\"546.12\" y=\"-267.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n",
       "<text text-anchor=\"middle\" x=\"546.12\" y=\"-251.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 32]</text>\n",
       "<text text-anchor=\"middle\" x=\"546.12\" y=\"-236.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = verginica</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>2&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M485.91,-352.3C492.51,-343.74 499.51,-334.64 506.32,-325.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"509.07,-327.98 512.4,-317.92 503.52,-323.71 509.07,-327.98\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#3fe685\" stroke=\"black\" d=\"M255.62,-193.75C255.62,-193.75 116.62,-193.75 116.62,-193.75 110.62,-193.75 104.62,-187.75 104.62,-181.75 104.62,-181.75 104.62,-119 104.62,-119 104.62,-113 110.62,-107 116.62,-107 116.62,-107 255.62,-107 255.62,-107 261.62,-107 267.62,-113 267.62,-119 267.62,-119 267.62,-181.75 267.62,-181.75 267.62,-187.75 261.62,-193.75 255.62,-193.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"186.12\" y=\"-176.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal length (cm) &lt;= 5.1</text>\n",
       "<text text-anchor=\"middle\" x=\"186.12\" y=\"-160.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.056</text>\n",
       "<text text-anchor=\"middle\" x=\"186.12\" y=\"-144.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\n",
       "<text text-anchor=\"middle\" x=\"186.12\" y=\"-129.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 34, 1]</text>\n",
       "<text text-anchor=\"middle\" x=\"186.12\" y=\"-113.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M298.78,-229.55C285.34,-220.23 271.01,-210.28 257.23,-200.72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"259.25,-197.86 249.04,-195.04 255.26,-203.61 259.25,-197.86\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#c09cf2\" stroke=\"black\" d=\"M436.25,-193.75C436.25,-193.75 298,-193.75 298,-193.75 292,-193.75 286,-187.75 286,-181.75 286,-181.75 286,-119 286,-119 286,-113 292,-107 298,-107 298,-107 436.25,-107 436.25,-107 442.25,-107 448.25,-113 448.25,-119 448.25,-119 448.25,-181.75 448.25,-181.75 448.25,-187.75 442.25,-193.75 436.25,-193.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"367.12\" y=\"-176.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) &lt;= 1.55</text>\n",
       "<text text-anchor=\"middle\" x=\"367.12\" y=\"-160.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n",
       "<text text-anchor=\"middle\" x=\"367.12\" y=\"-144.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n",
       "<text text-anchor=\"middle\" x=\"367.12\" y=\"-129.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 4]</text>\n",
       "<text text-anchor=\"middle\" x=\"367.12\" y=\"-113.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = verginica</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>3&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M362.59,-229.55C363.05,-221.71 363.53,-213.42 364,-205.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"367.48,-205.67 364.57,-195.48 360.5,-205.26 367.48,-205.67\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M108.25,-71C108.25,-71 12,-71 12,-71 6,-71 0,-65 0,-59 0,-59 0,-12 0,-12 0,-6 6,0 12,0 12,0 108.25,0 108.25,0 114.25,0 120.25,-6 120.25,-12 120.25,-12 120.25,-59 120.25,-59 120.25,-65 114.25,-71 108.25,-71\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.12\" y=\"-53.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"60.12\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"60.12\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 1]</text>\n",
       "<text text-anchor=\"middle\" x=\"60.12\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M138.49,-106.7C128.25,-97.53 117.44,-87.85 107.23,-78.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.72,-76.23 99.94,-72.17 105.05,-81.45 109.72,-76.23\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M246.25,-71C246.25,-71 150,-71 150,-71 144,-71 138,-65 138,-59 138,-59 138,-12 138,-12 138,-6 144,0 150,0 150,0 246.25,0 246.25,0 252.25,0 258.25,-6 258.25,-12 258.25,-12 258.25,-59 258.25,-59 258.25,-65 252.25,-71 246.25,-71\"/>\n",
       "<text text-anchor=\"middle\" x=\"198.12\" y=\"-53.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"198.12\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n",
       "<text text-anchor=\"middle\" x=\"198.12\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 33, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"198.12\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M190.66,-106.7C191.5,-98.82 192.38,-90.55 193.23,-82.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"196.7,-82.98 194.28,-72.66 189.74,-82.24 196.7,-82.98\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M402.38,-71C402.38,-71 309.88,-71 309.88,-71 303.88,-71 297.88,-65 297.88,-59 297.88,-59 297.88,-12 297.88,-12 297.88,-6 303.88,0 309.88,0 309.88,0 402.38,0 402.38,0 408.38,0 414.38,-6 414.38,-12 414.38,-12 414.38,-59 414.38,-59 414.38,-65 408.38,-71 402.38,-71\"/>\n",
       "<text text-anchor=\"middle\" x=\"356.12\" y=\"-53.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"356.12\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"middle\" x=\"356.12\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 3]</text>\n",
       "<text text-anchor=\"middle\" x=\"356.12\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = verginica</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M362.97,-106.7C362.2,-98.82 361.39,-90.55 360.61,-82.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"364.1,-82.28 359.65,-72.66 357.14,-82.96 364.1,-82.28\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#9cf2c0\" stroke=\"black\" d=\"M540.25,-71C540.25,-71 444,-71 444,-71 438,-71 432,-65 432,-59 432,-59 432,-12 432,-12 432,-6 438,0 444,0 444,0 540.25,0 540.25,0 546.25,0 552.25,-6 552.25,-12 552.25,-12 552.25,-59 552.25,-59 552.25,-65 546.25,-71 540.25,-71\"/>\n",
       "<text text-anchor=\"middle\" x=\"492.12\" y=\"-53.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n",
       "<text text-anchor=\"middle\" x=\"492.12\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"middle\" x=\"492.12\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 1]</text>\n",
       "<text text-anchor=\"middle\" x=\"492.12\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>7&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M414.38,-106.7C424.54,-97.53 435.26,-87.85 445.4,-78.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"447.55,-81.47 452.62,-72.17 442.85,-76.28 447.55,-81.47\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M587.25,-185.88C587.25,-185.88 491,-185.88 491,-185.88 485,-185.88 479,-179.88 479,-173.88 479,-173.88 479,-126.88 479,-126.88 479,-120.88 485,-114.88 491,-114.88 491,-114.88 587.25,-114.88 587.25,-114.88 593.25,-114.88 599.25,-120.88 599.25,-126.88 599.25,-126.88 599.25,-173.88 599.25,-173.88 599.25,-179.88 593.25,-185.88 587.25,-185.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"539.12\" y=\"-168.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"539.12\" y=\"-152.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"539.12\" y=\"-137.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 1]</text>\n",
       "<text text-anchor=\"middle\" x=\"539.12\" y=\"-121.33\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M543.66,-229.55C543.05,-219.08 542.4,-207.83 541.78,-197.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"545.29,-197.3 541.22,-187.51 538.3,-197.7 545.29,-197.3\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M721.38,-185.88C721.38,-185.88 628.88,-185.88 628.88,-185.88 622.88,-185.88 616.88,-179.88 616.88,-173.88 616.88,-173.88 616.88,-126.88 616.88,-126.88 616.88,-120.88 622.88,-114.88 628.88,-114.88 628.88,-114.88 721.38,-114.88 721.38,-114.88 727.38,-114.88 733.38,-120.88 733.38,-126.88 733.38,-126.88 733.38,-173.88 733.38,-173.88 733.38,-179.88 727.38,-185.88 721.38,-185.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"675.12\" y=\"-168.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"675.12\" y=\"-152.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 31</text>\n",
       "<text text-anchor=\"middle\" x=\"675.12\" y=\"-137.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 31]</text>\n",
       "<text text-anchor=\"middle\" x=\"675.12\" y=\"-121.33\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = verginica</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M591.61,-229.55C603.98,-217.97 617.39,-205.42 629.76,-193.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"632.12,-196.43 637.03,-187.04 627.33,-191.32 632.12,-196.43\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x21c002ac850>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "# 파일에서 데이터 읽어오기\n",
    "with open('tree.dot') as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "# 화면에 출력\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_samples_leaf = 2로 해서 멈춤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [8] 새로운 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data =feature_df[:1]+0.21\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict_proba(new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
