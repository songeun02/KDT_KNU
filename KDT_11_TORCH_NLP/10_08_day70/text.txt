[텍스트 전처리]
- 토큰화                                        -> 최적 토큰화 패키지 
- 정제(불용어, 구두점, 개발자 지정 제거 문자)     -> 불용어, 구두점 
- 단어 사전(정수)
- 문장 ==> 수치화 
- 문장 길이 통일, 패딩
- 정수 수치화 ==> One-Hot Encoding 변환 
    - pytorch는 필요 없음 

[모델] 
- embedding 층 : 차원 축소 (ex, 샘플 5개, 3000개 피쳐 ===> 샘플 5개, 30개 피쳐)
- RNN / LSTM / GRU 층 