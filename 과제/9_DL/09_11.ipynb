{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보스턴 집값 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optimizer\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchmetrics.regression import R2Score\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE => cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'DEVICE => {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FILE = '../DATA/boston.csv'\n",
    "\n",
    "boston_df = pd.read_csv(DATA_FILE)\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boston_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential (nn.Linear(13,40), \n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(40,30),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(30,20),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(20,10),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.weight] Parameter containing:\n",
      "tensor([[ 0.2413,  0.0924, -0.1355,  0.2630, -0.2740,  0.0388, -0.0102, -0.0715,\n",
      "          0.2616,  0.0280, -0.1380,  0.1061, -0.0435],\n",
      "        [ 0.1388, -0.1698, -0.0509, -0.1979, -0.0951,  0.2255,  0.1675, -0.1277,\n",
      "          0.0908,  0.2532,  0.1040, -0.1383,  0.0724],\n",
      "        [-0.1552, -0.0759, -0.0877,  0.1164,  0.1488, -0.2056, -0.1730, -0.1986,\n",
      "          0.0765,  0.2734,  0.1347, -0.1980,  0.1288],\n",
      "        [-0.1774,  0.2523,  0.0550, -0.0588, -0.2230,  0.2490,  0.1588,  0.1408,\n",
      "         -0.1105,  0.2570, -0.1426,  0.0249,  0.2221],\n",
      "        [-0.0318,  0.1929, -0.1307,  0.1747,  0.2623,  0.2266,  0.1333,  0.0957,\n",
      "          0.0341, -0.2206,  0.0323,  0.1329, -0.2313],\n",
      "        [-0.2223,  0.2604, -0.2514, -0.0179, -0.0260,  0.1667, -0.0443,  0.2440,\n",
      "          0.2057,  0.2441, -0.2245,  0.0908,  0.2181],\n",
      "        [ 0.2467,  0.1819, -0.0470, -0.0865,  0.1886, -0.0527, -0.1837, -0.2198,\n",
      "          0.1511, -0.0346, -0.2772, -0.0808,  0.0194],\n",
      "        [-0.1569, -0.0524, -0.2038,  0.2176, -0.0387,  0.2478,  0.0452,  0.0994,\n",
      "         -0.0378,  0.2646, -0.0917, -0.0526, -0.0951],\n",
      "        [-0.0360,  0.1100, -0.0487,  0.0081,  0.2521, -0.1427,  0.2721,  0.1638,\n",
      "         -0.2012,  0.1051,  0.1918,  0.1394, -0.2019],\n",
      "        [ 0.1232,  0.0629,  0.0934, -0.1963,  0.2385,  0.1755,  0.1949,  0.0200,\n",
      "         -0.2254,  0.1740,  0.2760,  0.1814, -0.0129],\n",
      "        [-0.1765,  0.2561, -0.0398, -0.1822,  0.1087, -0.0237,  0.0806,  0.1360,\n",
      "         -0.0653,  0.0437,  0.2365, -0.1027,  0.1407],\n",
      "        [-0.1252, -0.0214,  0.0516,  0.0134, -0.1061,  0.1676,  0.0976, -0.0430,\n",
      "          0.0285, -0.2475,  0.2024, -0.2557, -0.2342],\n",
      "        [ 0.0102,  0.0724,  0.0673,  0.0481,  0.0177,  0.1694,  0.1230, -0.1621,\n",
      "          0.1282,  0.2103,  0.0316,  0.0489, -0.1205],\n",
      "        [-0.2004, -0.1817, -0.1616, -0.1062, -0.1601, -0.2127, -0.0804,  0.2458,\n",
      "         -0.0555, -0.1238,  0.2753, -0.1986,  0.1273],\n",
      "        [-0.0686,  0.2392,  0.1474,  0.0340, -0.1490,  0.2727,  0.1213,  0.1817,\n",
      "         -0.2149,  0.2575, -0.1540,  0.2672, -0.2463],\n",
      "        [-0.1569,  0.2023, -0.2150,  0.0440, -0.0767, -0.0007, -0.1505, -0.2768,\n",
      "         -0.0203, -0.1053,  0.0959, -0.0104,  0.0252],\n",
      "        [ 0.0510, -0.1378, -0.0781, -0.1462, -0.2101,  0.1261, -0.1014,  0.2552,\n",
      "         -0.0179, -0.0933,  0.1812, -0.0792,  0.0227],\n",
      "        [-0.2219,  0.1272,  0.1877, -0.1282, -0.1576, -0.0517,  0.2552, -0.2753,\n",
      "          0.1861,  0.0936, -0.2524, -0.1585,  0.1934],\n",
      "        [ 0.2229,  0.1020,  0.1841, -0.1105, -0.2125,  0.1199, -0.0580,  0.2604,\n",
      "         -0.1422,  0.2492,  0.1352, -0.2472, -0.0048],\n",
      "        [-0.1529,  0.1295,  0.0751,  0.0440, -0.1950, -0.1115, -0.0782, -0.1730,\n",
      "         -0.0271,  0.1767,  0.0779, -0.0298,  0.0012],\n",
      "        [-0.0688,  0.2703, -0.1274,  0.2195,  0.2346, -0.0395,  0.2287, -0.0119,\n",
      "          0.0164, -0.1790,  0.2064,  0.2622,  0.2593],\n",
      "        [-0.1747, -0.1984,  0.2496,  0.0971,  0.2181,  0.0774, -0.0772, -0.2010,\n",
      "          0.2194, -0.2586, -0.0958, -0.0260,  0.0386],\n",
      "        [ 0.2076, -0.1033,  0.1130, -0.1131,  0.1270,  0.2739,  0.0847,  0.1330,\n",
      "         -0.1955,  0.1986, -0.2092, -0.1274, -0.0423],\n",
      "        [-0.0394,  0.0917, -0.2625,  0.1820, -0.0813, -0.2168, -0.1956, -0.0403,\n",
      "          0.0452, -0.0812, -0.1573, -0.0079, -0.1580],\n",
      "        [-0.2208, -0.2273, -0.2231, -0.1227, -0.2309, -0.1944, -0.2549,  0.2382,\n",
      "          0.0755,  0.1115,  0.2184, -0.0984,  0.1663],\n",
      "        [-0.0012,  0.2228,  0.2077,  0.0575, -0.1521, -0.0703, -0.0585, -0.0105,\n",
      "         -0.0450, -0.1535,  0.1450,  0.0990, -0.1198],\n",
      "        [ 0.1853, -0.2087,  0.1622,  0.0344, -0.1910,  0.2186, -0.1397,  0.0029,\n",
      "          0.2361, -0.1767, -0.2467, -0.1230,  0.0906],\n",
      "        [ 0.0785, -0.0379, -0.1434,  0.2461,  0.0634, -0.0253, -0.1274,  0.0376,\n",
      "          0.0021,  0.2715,  0.1305, -0.2321, -0.2181],\n",
      "        [ 0.1935,  0.1201,  0.2533,  0.0498,  0.1381,  0.0490, -0.1907,  0.1323,\n",
      "         -0.2091,  0.1983,  0.0557,  0.1065,  0.0706],\n",
      "        [ 0.0949,  0.1177,  0.1151,  0.2106,  0.0409,  0.0459, -0.0916, -0.2492,\n",
      "          0.1861,  0.2646, -0.0178, -0.1989,  0.0360],\n",
      "        [-0.0981,  0.0996, -0.2027,  0.1809, -0.2646,  0.0412,  0.0680,  0.0307,\n",
      "         -0.2588,  0.0287, -0.1439, -0.0618, -0.0777],\n",
      "        [ 0.0077, -0.2255,  0.1467,  0.2617,  0.1440,  0.2353,  0.2646,  0.1074,\n",
      "         -0.0284,  0.0199,  0.2003,  0.1260,  0.2549],\n",
      "        [-0.1238,  0.1864, -0.2490, -0.0355, -0.2486, -0.1065,  0.0349, -0.1078,\n",
      "          0.0413, -0.1251,  0.0018,  0.1128, -0.0519],\n",
      "        [-0.2229, -0.2247, -0.1370,  0.2534,  0.2001,  0.2339, -0.1134,  0.0888,\n",
      "          0.0453, -0.0332, -0.0150, -0.2670,  0.1066],\n",
      "        [-0.2309,  0.1794, -0.2304,  0.1122,  0.0298,  0.2419, -0.0924,  0.0547,\n",
      "          0.0926,  0.1132, -0.2572,  0.2430,  0.0970],\n",
      "        [-0.1210,  0.2231,  0.0875,  0.2622,  0.1112, -0.2707, -0.2106, -0.1774,\n",
      "         -0.2629,  0.0102,  0.0537,  0.2271,  0.1450],\n",
      "        [ 0.1540,  0.1163,  0.2120,  0.0304,  0.0386,  0.2109, -0.0269, -0.2205,\n",
      "          0.1192,  0.2743,  0.2695, -0.0272,  0.1307],\n",
      "        [ 0.1590, -0.0834, -0.0998,  0.2228,  0.0783, -0.2253, -0.2188,  0.0009,\n",
      "         -0.0496, -0.0926, -0.1871, -0.1069,  0.1640],\n",
      "        [ 0.2692, -0.0406,  0.2286,  0.0414, -0.0765,  0.2406,  0.1361,  0.0020,\n",
      "         -0.0111,  0.2087,  0.0090,  0.1943,  0.1663],\n",
      "        [-0.1775, -0.0882, -0.1621,  0.2487,  0.0126, -0.2061,  0.1514,  0.1971,\n",
      "         -0.1698,  0.2317, -0.1423,  0.0233, -0.2719]], requires_grad=True) \n",
      "\n",
      "[0.bias] Parameter containing:\n",
      "tensor([-0.2060, -0.0470,  0.1228,  0.0759,  0.2328, -0.2065, -0.1601, -0.0985,\n",
      "        -0.1325,  0.0890,  0.1593,  0.1061,  0.2370, -0.1472,  0.1431,  0.2037,\n",
      "         0.0561, -0.1947, -0.1443, -0.1397, -0.1397, -0.0568, -0.1784, -0.0141,\n",
      "        -0.0443,  0.2168,  0.1801,  0.2519,  0.2245, -0.0735, -0.0971, -0.2689,\n",
      "         0.0717,  0.0432, -0.1720,  0.0258, -0.0085, -0.2580,  0.1638,  0.1303],\n",
      "       requires_grad=True) \n",
      "\n",
      "[2.weight] Parameter containing:\n",
      "tensor([[ 0.1237, -0.0163, -0.0577,  ...,  0.0450, -0.1344, -0.1431],\n",
      "        [ 0.0908,  0.0520, -0.0985,  ..., -0.1578, -0.0749,  0.0181],\n",
      "        [-0.1368, -0.0210,  0.0649,  ..., -0.0532,  0.0356, -0.0749],\n",
      "        ...,\n",
      "        [ 0.0441, -0.1444, -0.0460,  ..., -0.1041, -0.0393,  0.0064],\n",
      "        [-0.1315, -0.0890,  0.1164,  ..., -0.0315, -0.1089, -0.0681],\n",
      "        [ 0.0257,  0.1447, -0.1470,  ..., -0.1138,  0.1385, -0.1563]],\n",
      "       requires_grad=True) \n",
      "\n",
      "[2.bias] Parameter containing:\n",
      "tensor([ 0.0112,  0.0697, -0.0495,  0.1565, -0.0979, -0.0477,  0.1330,  0.0609,\n",
      "         0.0250,  0.1315, -0.1482,  0.0530, -0.1074, -0.1199,  0.0963, -0.0999,\n",
      "        -0.0694,  0.1208, -0.0952,  0.1280,  0.0141, -0.0448,  0.1498,  0.1147,\n",
      "        -0.1471,  0.0345,  0.1504, -0.1334, -0.0507,  0.0712],\n",
      "       requires_grad=True) \n",
      "\n",
      "[4.weight] Parameter containing:\n",
      "tensor([[ 7.3825e-02, -8.5708e-02,  1.1769e-01, -7.4928e-02, -3.2165e-03,\n",
      "          1.7437e-01,  1.1171e-01,  8.9533e-02,  2.8532e-03,  3.0955e-02,\n",
      "         -1.2931e-01,  2.1974e-02, -1.6129e-01, -1.4562e-01,  1.6231e-01,\n",
      "          3.2370e-02,  1.0124e-01,  1.6119e-01, -9.9638e-02, -6.0878e-02,\n",
      "          9.3174e-02, -1.7955e-01, -6.2964e-02, -6.4861e-02,  9.5463e-02,\n",
      "          7.3058e-02,  5.6420e-02,  1.5691e-01,  1.1107e-01, -3.6170e-02],\n",
      "        [-8.8173e-02, -5.9151e-03,  1.2461e-01,  6.4156e-02, -2.1248e-02,\n",
      "          1.7553e-01, -1.4365e-01, -1.1386e-01,  1.0341e-01, -8.7700e-02,\n",
      "          1.1957e-01, -1.4498e-01, -8.8149e-02,  8.5132e-02, -9.3130e-02,\n",
      "         -5.9026e-02, -9.9352e-02,  3.9227e-02,  1.5392e-01,  1.8715e-02,\n",
      "         -1.3359e-01, -3.2968e-02,  2.6625e-02, -3.7766e-02,  1.1490e-01,\n",
      "         -6.1692e-02, -1.4761e-01,  3.5516e-02, -1.0744e-02,  2.7752e-02],\n",
      "        [-8.0863e-02, -7.5071e-02, -1.4911e-01, -5.0313e-02, -5.1623e-02,\n",
      "         -1.6460e-01,  1.2867e-01, -1.7404e-01,  1.6554e-01,  9.6047e-02,\n",
      "          1.5704e-01, -6.6020e-02,  1.1588e-01, -1.1819e-01,  1.0494e-01,\n",
      "          1.6791e-01, -9.9069e-03,  5.2019e-02,  9.2673e-03, -1.7599e-01,\n",
      "          1.3072e-01,  8.3979e-02, -1.6875e-01, -1.0049e-01, -4.4907e-02,\n",
      "          7.3639e-02, -7.5043e-02, -1.7871e-02,  1.3292e-01,  7.9786e-02],\n",
      "        [-1.0344e-01, -2.6588e-03, -1.8036e-02,  2.7830e-02,  1.1887e-01,\n",
      "         -1.2050e-01,  1.3976e-02,  1.3223e-01, -1.6063e-01, -1.0541e-01,\n",
      "         -6.3528e-02, -1.7070e-02, -6.4357e-02,  1.5062e-01,  1.7410e-01,\n",
      "         -7.5926e-03,  4.7703e-02,  5.2856e-02, -1.0598e-01, -1.4718e-01,\n",
      "          1.4182e-01, -1.6731e-01, -5.6047e-03,  3.9783e-02, -6.5111e-02,\n",
      "          4.2411e-02, -2.0929e-02, -1.0868e-01,  1.0853e-01,  1.7398e-01],\n",
      "        [-1.7887e-01,  3.7694e-02,  1.7486e-01,  1.4803e-01, -1.5125e-01,\n",
      "          9.4979e-03,  1.5266e-01, -8.0491e-02,  1.6714e-01, -1.5603e-01,\n",
      "         -1.1371e-02, -1.9590e-02, -7.5354e-02, -1.9978e-02,  4.6276e-02,\n",
      "          2.8127e-02,  1.2194e-01,  3.7961e-02, -1.4321e-01, -7.1502e-02,\n",
      "          1.2725e-01, -1.2493e-01,  1.0264e-01,  2.3337e-02, -9.2990e-03,\n",
      "          1.0648e-01,  8.4376e-02,  1.5145e-02, -8.0556e-02,  8.9412e-02],\n",
      "        [-6.3629e-03,  1.0314e-01,  1.0084e-01, -5.8262e-02,  1.0915e-01,\n",
      "          4.4176e-02,  1.1040e-01, -9.6376e-02, -1.5627e-01, -2.9770e-03,\n",
      "         -3.9842e-03,  9.2929e-02,  1.6586e-01,  6.6162e-02,  2.0217e-02,\n",
      "         -1.5161e-01, -1.1235e-01, -1.7405e-01, -1.3252e-01,  8.1734e-02,\n",
      "         -1.7186e-01,  1.2855e-01,  1.0788e-01, -1.3032e-01,  1.0512e-01,\n",
      "          7.7059e-02,  1.1221e-01, -3.2445e-02,  6.8886e-02, -1.6056e-01],\n",
      "        [ 7.1676e-02, -9.4470e-02,  4.2942e-02,  4.8187e-02,  1.3224e-01,\n",
      "         -1.8251e-01, -1.6996e-01, -1.1784e-01,  1.0332e-01,  1.1252e-01,\n",
      "          1.1221e-01, -1.1652e-01, -1.4030e-01, -4.9290e-02, -1.7475e-01,\n",
      "          7.5476e-02, -7.5400e-02, -1.2294e-01,  7.1139e-02,  5.3256e-02,\n",
      "          1.2321e-01,  2.5732e-02, -6.8364e-02,  1.4960e-01,  1.3879e-01,\n",
      "         -1.0755e-01, -2.1152e-02,  3.4041e-02, -3.9562e-02,  1.3067e-01],\n",
      "        [-8.7891e-02,  8.0665e-02, -1.7963e-01,  1.5110e-01,  9.2518e-02,\n",
      "         -5.6896e-02,  6.4954e-02, -2.3898e-03, -4.3091e-02, -1.2244e-01,\n",
      "         -1.3442e-01,  1.7421e-01,  1.9830e-02, -1.3988e-02,  5.3348e-02,\n",
      "         -2.2185e-02, -4.2013e-02, -8.9020e-02, -9.3950e-02, -6.4005e-02,\n",
      "         -1.2790e-01,  9.9067e-02, -1.4702e-01,  1.4581e-03, -9.4408e-02,\n",
      "         -8.8397e-02,  1.5272e-01, -7.1026e-02, -1.6872e-01,  3.0552e-02],\n",
      "        [-6.1079e-02, -3.6756e-03,  1.3917e-01,  3.8791e-02,  1.6834e-01,\n",
      "          3.2582e-02, -1.3715e-01, -8.2870e-02,  7.5759e-03,  1.3601e-01,\n",
      "          4.1506e-02, -1.7344e-01,  7.9727e-02, -9.2519e-02, -8.8946e-03,\n",
      "         -1.6890e-01, -1.7685e-01,  1.3987e-01,  1.0949e-02,  7.2540e-02,\n",
      "         -1.7196e-01, -2.3904e-02, -4.0298e-02,  4.8308e-02,  7.1165e-02,\n",
      "          5.4363e-02, -3.4133e-02,  5.4867e-02,  2.4919e-02, -6.9438e-02],\n",
      "        [-1.8234e-01, -8.3166e-02, -1.0282e-02,  1.2610e-01, -6.7724e-02,\n",
      "          1.3119e-02, -1.3825e-01,  9.9751e-02,  2.0173e-02,  4.6334e-02,\n",
      "          1.7677e-01,  6.2479e-03, -1.3417e-01,  4.0263e-02, -7.5133e-02,\n",
      "          1.7954e-01, -4.2765e-02, -2.3495e-03,  7.5325e-03,  2.0823e-02,\n",
      "         -7.5830e-02, -1.3707e-01, -1.3790e-01, -1.1801e-01,  1.3955e-01,\n",
      "         -1.6190e-01,  2.3079e-02, -1.3410e-01, -3.9284e-02,  1.1246e-01],\n",
      "        [ 1.3931e-01, -1.7453e-01,  5.4205e-02, -1.7601e-01,  8.3490e-02,\n",
      "         -1.3809e-01,  6.0462e-02,  1.1677e-01,  4.6071e-02,  1.7728e-02,\n",
      "          1.7821e-01, -1.3860e-01,  5.3546e-03,  9.8107e-02, -1.1555e-01,\n",
      "          9.3612e-02,  1.4584e-01,  8.0179e-02,  6.0372e-02, -5.6609e-02,\n",
      "         -4.1971e-02, -1.1011e-01, -1.8397e-02, -1.4092e-01, -8.5401e-02,\n",
      "         -5.9334e-02,  1.3473e-01,  1.1405e-01,  1.7087e-01,  1.5753e-02],\n",
      "        [ 5.6869e-02, -1.6725e-01, -1.5868e-01, -1.4509e-01, -7.9542e-05,\n",
      "         -8.8487e-02, -6.2271e-02, -1.7703e-01,  2.4329e-02, -7.8990e-02,\n",
      "          1.4781e-01, -4.6374e-02, -9.6518e-02,  1.7333e-01, -8.4553e-02,\n",
      "          2.8393e-02, -1.3382e-01,  8.9433e-02,  1.1361e-01, -1.0478e-02,\n",
      "          7.3261e-02, -2.3743e-03, -1.1060e-01,  1.5268e-01, -1.0209e-01,\n",
      "          9.0403e-02,  1.7681e-01, -1.6030e-01, -1.4010e-01, -1.2285e-01],\n",
      "        [-1.6094e-01,  1.0222e-01, -1.2498e-02, -1.3295e-01, -5.7662e-02,\n",
      "          7.9474e-02, -7.9688e-02, -1.7680e-01,  5.8928e-02, -6.3573e-02,\n",
      "         -6.3874e-02, -1.6343e-01, -4.3172e-02, -9.3406e-02, -1.7905e-02,\n",
      "         -1.2315e-01, -1.3786e-01, -7.0092e-02, -1.7396e-01, -1.4199e-01,\n",
      "          1.2169e-01, -1.0357e-03,  1.7909e-01, -1.6826e-01,  4.6114e-02,\n",
      "         -5.5512e-02, -5.5739e-04, -1.3146e-01, -1.3247e-01, -9.1802e-02],\n",
      "        [ 1.7949e-01, -9.8414e-03,  4.6161e-02,  4.1313e-02,  9.3704e-02,\n",
      "          5.1049e-02, -3.9753e-02, -1.0659e-01, -1.9080e-02,  1.4809e-01,\n",
      "         -1.3462e-01,  1.1743e-01, -1.5743e-01,  6.5456e-02, -9.1282e-02,\n",
      "          5.2599e-02, -1.4820e-01,  1.1312e-01,  1.0219e-01, -3.3363e-02,\n",
      "          6.6552e-02, -1.0834e-01, -1.6525e-01, -1.4009e-01,  1.2140e-01,\n",
      "         -1.2291e-01, -5.3984e-02, -3.9661e-02, -5.7132e-02,  9.2245e-03],\n",
      "        [-5.9136e-03, -3.4179e-02, -7.6648e-02, -9.8207e-02,  1.1351e-01,\n",
      "          9.0962e-02,  2.7808e-02, -6.1738e-02, -6.8952e-02,  8.7929e-04,\n",
      "          1.1119e-01,  2.3007e-02, -1.2750e-01, -1.3703e-01, -6.7631e-02,\n",
      "          5.6848e-02, -2.2360e-02,  4.9808e-02, -1.6376e-02, -9.5441e-02,\n",
      "          2.9683e-02,  9.0067e-02, -9.6237e-02,  9.7569e-02, -6.3679e-02,\n",
      "         -1.2067e-01,  1.2878e-02, -1.6648e-01,  1.0606e-01, -6.0242e-02],\n",
      "        [-1.3542e-01,  8.1877e-02,  4.6577e-02,  8.6454e-02, -1.3237e-01,\n",
      "         -1.1417e-01, -2.7643e-02,  1.5340e-01,  1.5938e-01, -6.7671e-04,\n",
      "          1.3567e-02, -8.3498e-02, -7.0963e-02,  3.0346e-02, -1.6286e-02,\n",
      "         -5.8704e-02,  6.2235e-02, -1.2564e-01,  1.4170e-01, -4.8183e-02,\n",
      "          9.7431e-03, -1.3669e-01,  1.3849e-01,  6.3480e-02, -4.3758e-02,\n",
      "          3.7160e-02, -1.6615e-01,  1.8156e-01, -1.0590e-01,  1.5134e-01],\n",
      "        [ 9.3073e-03,  1.4232e-01, -4.8765e-02, -1.1022e-01,  1.8193e-01,\n",
      "         -1.6119e-01,  1.3835e-01,  1.7294e-01, -1.6540e-01, -2.7971e-02,\n",
      "          1.7015e-01,  2.6179e-02, -1.4998e-01,  2.4264e-03,  1.7604e-01,\n",
      "          1.5770e-01, -5.5552e-02, -3.7854e-02,  1.2050e-01, -1.5761e-01,\n",
      "          1.1767e-01,  6.2316e-02,  1.7953e-01, -1.6518e-01,  8.5879e-02,\n",
      "         -1.3902e-01, -6.6551e-02, -6.1044e-02,  9.6914e-02, -9.4397e-02],\n",
      "        [ 1.1777e-01,  1.0751e-01, -9.0592e-02, -1.6421e-01, -1.4713e-01,\n",
      "         -1.2133e-03,  3.5156e-02, -2.4138e-02,  4.8040e-02, -3.3411e-02,\n",
      "         -1.1970e-01,  4.2022e-02,  1.2561e-01, -1.1644e-01, -4.3741e-02,\n",
      "          1.6122e-01, -6.8286e-02, -1.2498e-01, -8.0047e-02, -4.3113e-02,\n",
      "         -9.7422e-02,  3.1352e-02,  6.8165e-02,  1.8724e-03, -4.5243e-02,\n",
      "          1.0160e-01, -1.7226e-01,  1.2399e-01, -9.4405e-02, -1.5899e-02],\n",
      "        [-1.4489e-01, -8.0674e-02, -1.1142e-01,  2.7671e-02,  1.6880e-01,\n",
      "          6.8886e-02,  8.9041e-02,  8.7868e-02,  6.0719e-03,  1.6796e-01,\n",
      "         -5.4578e-02, -8.6023e-02, -1.8125e-02, -5.0277e-02,  7.1370e-02,\n",
      "         -1.5264e-01,  1.3626e-01, -7.9443e-02,  4.3044e-02,  4.0606e-05,\n",
      "         -4.8563e-02,  3.8765e-02, -1.6307e-02,  8.3480e-02,  1.8257e-01,\n",
      "         -1.1200e-01,  1.3628e-01,  2.6159e-02,  2.2261e-02,  5.0195e-02],\n",
      "        [-1.4730e-01,  6.9967e-02,  1.4571e-01,  9.7954e-02, -1.6004e-01,\n",
      "         -1.3550e-01,  3.4109e-02, -5.7949e-02,  1.2583e-01, -1.7175e-01,\n",
      "         -1.4261e-01, -1.5024e-01, -1.7704e-01, -1.8366e-02,  7.3153e-02,\n",
      "         -2.6720e-02, -1.6527e-01,  1.6546e-01,  1.3555e-01,  2.6400e-02,\n",
      "         -1.1964e-02,  1.8251e-01,  1.8111e-01, -1.2793e-01,  1.7815e-01,\n",
      "         -1.4712e-01,  3.7910e-02, -1.6506e-01,  6.4917e-02,  5.3394e-02]],\n",
      "       requires_grad=True) \n",
      "\n",
      "[4.bias] Parameter containing:\n",
      "tensor([-0.1413,  0.1757, -0.1040,  0.0145,  0.0054,  0.0850,  0.1307,  0.0943,\n",
      "         0.0547, -0.1159,  0.0927, -0.1132, -0.0865,  0.1193,  0.0909,  0.0221,\n",
      "        -0.0956, -0.0432,  0.0912,  0.0231], requires_grad=True) \n",
      "\n",
      "[6.weight] Parameter containing:\n",
      "tensor([[-0.1108,  0.0648,  0.1739,  0.1614,  0.0873, -0.1560,  0.1205,  0.0933,\n",
      "          0.1902,  0.1128, -0.0017, -0.1630,  0.1052, -0.1182,  0.0136, -0.1782,\n",
      "         -0.1993,  0.1993,  0.0678, -0.1744],\n",
      "        [ 0.0167, -0.0262,  0.1247, -0.1695, -0.0107, -0.0032,  0.1681, -0.1752,\n",
      "         -0.2025, -0.0687, -0.0948, -0.0015, -0.0975,  0.0397,  0.1622,  0.1813,\n",
      "          0.1087, -0.2213, -0.1760, -0.0330],\n",
      "        [ 0.0462, -0.1864,  0.1913, -0.1004, -0.1887,  0.2166, -0.0429,  0.0921,\n",
      "          0.1768, -0.0113, -0.0228, -0.0803,  0.0486, -0.1469, -0.1540, -0.1983,\n",
      "         -0.1048, -0.0391, -0.1080, -0.1649],\n",
      "        [-0.1436,  0.1696,  0.2064, -0.1621,  0.1655, -0.1451,  0.0265, -0.0916,\n",
      "         -0.1747, -0.0809,  0.1090,  0.0083,  0.0314, -0.0750,  0.0382,  0.1469,\n",
      "          0.0713, -0.1029, -0.0110, -0.0944],\n",
      "        [ 0.1350, -0.1342, -0.0407, -0.0425, -0.0469, -0.0814,  0.2171,  0.1078,\n",
      "          0.1990, -0.2131,  0.0889, -0.1826,  0.0185,  0.0281, -0.0596,  0.0378,\n",
      "         -0.1623,  0.0465,  0.0694, -0.0832],\n",
      "        [-0.1394, -0.2054, -0.0354,  0.1078, -0.0228, -0.0564,  0.0749,  0.0076,\n",
      "          0.1162, -0.1837, -0.2153, -0.2003, -0.1763,  0.1160,  0.0264,  0.0180,\n",
      "         -0.0508,  0.1148, -0.2179,  0.1240],\n",
      "        [-0.0373,  0.1011, -0.0666, -0.1628,  0.1412,  0.0227,  0.1635,  0.1762,\n",
      "         -0.1286, -0.1025, -0.1442,  0.1993, -0.0262, -0.1259, -0.2087, -0.0010,\n",
      "         -0.1320,  0.1380, -0.1335,  0.0582],\n",
      "        [ 0.1105,  0.1385, -0.1985,  0.2228, -0.0005,  0.1987, -0.0339,  0.1879,\n",
      "          0.0071,  0.0838,  0.1212, -0.1206,  0.1777,  0.0857,  0.1648, -0.2030,\n",
      "         -0.1309, -0.0481, -0.1981, -0.2165],\n",
      "        [ 0.2149, -0.0456, -0.0134, -0.1722, -0.0198,  0.0063,  0.1848,  0.0828,\n",
      "         -0.1919,  0.2058, -0.1829, -0.0161,  0.0856, -0.1865, -0.1836, -0.0756,\n",
      "         -0.1622, -0.2161,  0.0781, -0.0648],\n",
      "        [-0.1452, -0.1533, -0.1303, -0.0874, -0.0590,  0.0133, -0.1415,  0.0101,\n",
      "          0.1715, -0.0211,  0.0792, -0.0081,  0.0841,  0.0447,  0.0114,  0.1378,\n",
      "         -0.1170, -0.2078, -0.2032,  0.1901]], requires_grad=True) \n",
      "\n",
      "[6.bias] Parameter containing:\n",
      "tensor([ 0.0306,  0.0997,  0.0116,  0.0296, -0.0441, -0.0617,  0.1296, -0.0827,\n",
      "        -0.0271, -0.0876], requires_grad=True) \n",
      "\n",
      "[8.weight] Parameter containing:\n",
      "tensor([[-0.2856, -0.1310,  0.1657,  0.1734,  0.0413,  0.1833,  0.0433,  0.1135,\n",
      "          0.1141, -0.0337]], requires_grad=True) \n",
      "\n",
      "[8.bias] Parameter containing:\n",
      "tensor([0.3133], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'[{name}] {param} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=13, out_features=40, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=40, out_features=30, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=30, out_features=20, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [1]                       --\n",
       "├─Linear: 1-1                            [40]                      560\n",
       "├─ReLU: 1-2                              [40]                      --\n",
       "├─Linear: 1-3                            [30]                      1,230\n",
       "├─ReLU: 1-4                              [30]                      --\n",
       "├─Linear: 1-5                            [20]                      620\n",
       "├─ReLU: 1-6                              [20]                      --\n",
       "├─Linear: 1-7                            [10]                      210\n",
       "├─ReLU: 1-8                              [10]                      --\n",
       "├─Linear: 1-9                            [1]                       11\n",
       "==========================================================================================\n",
       "Total params: 2,631\n",
       "Trainable params: 2,631\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.07\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 0.01\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model)\n",
    "summary(model, input_size=(13,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] 최적화 인스턴스 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optim = optimizer.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4] 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506, 1)\n"
     ]
    }
   ],
   "source": [
    "feature_df = boston_df[boston_df.columns[:-1]]\n",
    "target_df = boston_df[['MEDV']]\n",
    "\n",
    "print(feature_df.shape, target_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature] Train (323, 13), Test (102, 13), Val (81, 13)\n",
      "[Target] Train (323, 1), Test (102, 1), Val (81, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train, test 쪼개기 \n",
    "x_train, x_test, y_train, y_test = train_test_split(feature_df, target_df, test_size=0.2)\n",
    "\n",
    "# train, valid 쪼개기 \n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)\n",
    "\n",
    "print(f'[Feature] Train {x_train.shape}, Test {x_test.shape}, Val {x_val.shape}')\n",
    "print(f'[Target] Train {y_train.shape}, Test {y_test.shape}, Val {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 500, BATCH_SIZE : 17, BATCH_CNT : 19\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 500\n",
    "BATCH_SIZE = 17\n",
    "BATCH_CNT = x_train.shape[0] // BATCH_SIZE\n",
    "\n",
    "print(f'EPOCH : {EPOCH}, BATCH_SIZE : {BATCH_SIZE}, BATCH_CNT : {BATCH_CNT}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(test_df, target_df):\n",
    "    test_ts = torch.FloatTensor(test_df.values).to(DEVICE)\n",
    "    target_ts = torch.FloatTensor(target_df.values).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 학습 진행 \n",
    "        pre_y = model(test_ts)\n",
    "        print(f'{pre_y.shape}')\n",
    "\n",
    "        # 오차 계산 \n",
    "        loss = F.mse_loss(pre_y, target_ts)\n",
    "\n",
    "        # 성능 평가 \n",
    "        r2 = R2Score()(pre_y, target_ts)\n",
    "\n",
    "        print(f'LOSS : {loss}, R2 : {R2Score()(pre_y, target_ts)}')\n",
    "\n",
    "    return loss, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(feature_ts, target_ts, val_ts, val_target_ts):\n",
    "    loss_history = [[],[]]\n",
    "    r2_history = [[],[]]\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "\n",
    "        bs_loss = 0\n",
    "        bs_r2 = 0\n",
    "\n",
    "        for i in range(BATCH_CNT):\n",
    "            start = i * BATCH_SIZE\n",
    "            end = start + BATCH_SIZE\n",
    "\n",
    "            BSX_train = torch.FloatTensor(x_train[start:end].values).to(DEVICE)\n",
    "            BSY_train = torch.FloatTensor(y_train[start:end].values).to(DEVICE)\n",
    "\n",
    "            # 학습 진행 \n",
    "            pre_y = model(BSX_train)\n",
    "\n",
    "            # 오차계산 - 손실함수 \n",
    "            loss = F.mse_loss(pre_y, BSY_train)\n",
    "            bs_loss += loss.item()\n",
    "            bs_r2 += (R2Score()(pre_y, BSY_train)).item()\n",
    "\n",
    "            # 최적화 \n",
    "            adam_optim.zero_grad()\n",
    "            loss.backward()\n",
    "            adam_optim.step()\n",
    "\n",
    "        # 검증 \n",
    "        val_loss, val_r2 = testing(val_ts, val_target_ts)\n",
    "        loss_history[1].append(val_loss)\n",
    "        r2_history[1].append(val_r2)\n",
    "\n",
    "        # 에포크 단위 손실과 성능 지표 \n",
    "        loss_history[0].append(bs_loss/BATCH_CNT)\n",
    "        r2_history[0].append(bs_r2/BATCH_CNT)\n",
    "\n",
    "        print(f'[{epoch}/{EPOCH}] \\n Train_Loss : {loss_history[0][-1]}, R2 : {r2_history[0][-1]}')\n",
    "        print(f'Val_Loss : {loss_history[1][-1]}, R2 : {r2_history[1][-1]}')\n",
    "\n",
    "    return loss_history, r2_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([81, 1])\n",
      "LOSS : 74.6963882446289, R2 : -0.2423645257949829\n",
      "[0/500] \n",
      " Train_Loss : 332.9881760446649, R2 : -3.2895616481178687\n",
      "Val_Loss : 74.6963882446289, R2 : -0.2423645257949829\n",
      "torch.Size([81, 1])\n",
      "LOSS : 56.68684387207031, R2 : 0.05717366933822632\n",
      "[1/500] \n",
      " Train_Loss : 70.54672582525956, R2 : 0.1293219578893561\n",
      "Val_Loss : 56.68684387207031, R2 : 0.05717366933822632\n",
      "torch.Size([81, 1])\n",
      "LOSS : 41.133392333984375, R2 : 0.31586164236068726\n",
      "[2/500] \n",
      " Train_Loss : 99.7174687636526, R2 : -0.41222151643351507\n",
      "Val_Loss : 41.133392333984375, R2 : 0.31586164236068726\n",
      "torch.Size([81, 1])\n",
      "LOSS : 67.66918182373047, R2 : -0.1254866123199463\n",
      "[3/500] \n",
      " Train_Loss : 58.86774083187706, R2 : 0.28677485804808767\n",
      "Val_Loss : 67.66918182373047, R2 : -0.1254866123199463\n",
      "torch.Size([81, 1])\n",
      "LOSS : 40.10142517089844, R2 : 0.3330255150794983\n",
      "[4/500] \n",
      " Train_Loss : 43.10747186761154, R2 : 0.4442305909959893\n",
      "Val_Loss : 40.10142517089844, R2 : 0.3330255150794983\n",
      "torch.Size([81, 1])\n",
      "LOSS : 42.46219253540039, R2 : 0.2937607169151306\n",
      "[5/500] \n",
      " Train_Loss : 41.31720562985069, R2 : 0.4051538517600612\n",
      "Val_Loss : 42.46219253540039, R2 : 0.2937607169151306\n",
      "torch.Size([81, 1])\n",
      "LOSS : 41.211143493652344, R2 : 0.3145684599876404\n",
      "[6/500] \n",
      " Train_Loss : 38.971263684724505, R2 : 0.42382093479758814\n",
      "Val_Loss : 41.211143493652344, R2 : 0.3145684599876404\n",
      "torch.Size([81, 1])\n",
      "LOSS : 32.02119064331055, R2 : 0.4674174189567566\n",
      "[7/500] \n",
      " Train_Loss : 41.768608595195566, R2 : 0.36225784138629313\n",
      "Val_Loss : 32.02119064331055, R2 : 0.4674174189567566\n",
      "torch.Size([81, 1])\n",
      "LOSS : 35.41408157348633, R2 : 0.4109863042831421\n",
      "[8/500] \n",
      " Train_Loss : 33.16008577848736, R2 : 0.5266861790104916\n",
      "Val_Loss : 35.41408157348633, R2 : 0.4109863042831421\n",
      "torch.Size([81, 1])\n",
      "LOSS : 37.46034240722656, R2 : 0.37695246934890747\n",
      "[9/500] \n",
      " Train_Loss : 34.814120393050345, R2 : 0.4828924913155405\n",
      "Val_Loss : 37.46034240722656, R2 : 0.37695246934890747\n",
      "torch.Size([81, 1])\n",
      "LOSS : 36.93848419189453, R2 : 0.38563215732574463\n",
      "[10/500] \n",
      " Train_Loss : 32.097785799126875, R2 : 0.5402074581698367\n",
      "Val_Loss : 36.93848419189453, R2 : 0.38563215732574463\n",
      "torch.Size([81, 1])\n",
      "LOSS : 29.614896774291992, R2 : 0.507439374923706\n",
      "[11/500] \n",
      " Train_Loss : 32.809110942639805, R2 : 0.5088876799533242\n",
      "Val_Loss : 29.614896774291992, R2 : 0.507439374923706\n",
      "torch.Size([81, 1])\n",
      "LOSS : 28.700544357299805, R2 : 0.5226470828056335\n",
      "[12/500] \n",
      " Train_Loss : 31.74386315596731, R2 : 0.5280202689923739\n",
      "Val_Loss : 28.700544357299805, R2 : 0.5226470828056335\n",
      "torch.Size([81, 1])\n",
      "LOSS : 28.843568801879883, R2 : 0.5202682614326477\n",
      "[13/500] \n",
      " Train_Loss : 30.35540691174959, R2 : 0.5631430776495683\n",
      "Val_Loss : 28.843568801879883, R2 : 0.5202682614326477\n",
      "torch.Size([81, 1])\n",
      "LOSS : 27.45101547241211, R2 : 0.5434294939041138\n",
      "[14/500] \n",
      " Train_Loss : 28.669256561680843, R2 : 0.587293593507064\n",
      "Val_Loss : 27.45101547241211, R2 : 0.5434294939041138\n",
      "torch.Size([81, 1])\n",
      "LOSS : 28.53067970275879, R2 : 0.5254722833633423\n",
      "[15/500] \n",
      " Train_Loss : 32.484799435264186, R2 : 0.5263333383359408\n",
      "Val_Loss : 28.53067970275879, R2 : 0.5254722833633423\n",
      "torch.Size([81, 1])\n",
      "LOSS : 29.297260284423828, R2 : 0.512722373008728\n",
      "[16/500] \n",
      " Train_Loss : 33.125684888739336, R2 : 0.5234843461137069\n",
      "Val_Loss : 29.297260284423828, R2 : 0.512722373008728\n",
      "torch.Size([81, 1])\n",
      "LOSS : 31.23246955871582, R2 : 0.480535626411438\n",
      "[17/500] \n",
      " Train_Loss : 31.569021024202044, R2 : 0.5550694434266341\n",
      "Val_Loss : 31.23246955871582, R2 : 0.480535626411438\n",
      "torch.Size([81, 1])\n",
      "LOSS : 25.75564193725586, R2 : 0.5716272592544556\n",
      "[18/500] \n",
      " Train_Loss : 33.722440368250794, R2 : 0.4932004778008712\n",
      "Val_Loss : 25.75564193725586, R2 : 0.5716272592544556\n",
      "torch.Size([81, 1])\n",
      "LOSS : 31.062957763671875, R2 : 0.48335498571395874\n",
      "[19/500] \n",
      " Train_Loss : 38.23337263810007, R2 : 0.4096771008089969\n",
      "Val_Loss : 31.062957763671875, R2 : 0.48335498571395874\n",
      "torch.Size([81, 1])\n",
      "LOSS : 27.96870994567871, R2 : 0.5348191261291504\n",
      "[20/500] \n",
      " Train_Loss : 26.940330304597552, R2 : 0.6467904323025754\n",
      "Val_Loss : 27.96870994567871, R2 : 0.5348191261291504\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.951444625854492, R2 : 0.6182671785354614\n",
      "[21/500] \n",
      " Train_Loss : 24.66924238204956, R2 : 0.6460010597580358\n",
      "Val_Loss : 22.951444625854492, R2 : 0.6182671785354614\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.710538864135742, R2 : 0.6222739815711975\n",
      "[22/500] \n",
      " Train_Loss : 25.913471874437835, R2 : 0.6340800492387069\n",
      "Val_Loss : 22.710538864135742, R2 : 0.6222739815711975\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.401079177856445, R2 : 0.6274210214614868\n",
      "[23/500] \n",
      " Train_Loss : 29.346181969893607, R2 : 0.5577684985963922\n",
      "Val_Loss : 22.401079177856445, R2 : 0.6274210214614868\n",
      "torch.Size([81, 1])\n",
      "LOSS : 23.400148391723633, R2 : 0.6108043193817139\n",
      "[24/500] \n",
      " Train_Loss : 25.413451295149954, R2 : 0.6414462484811482\n",
      "Val_Loss : 23.400148391723633, R2 : 0.6108043193817139\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.893125534057617, R2 : 0.6358693838119507\n",
      "[25/500] \n",
      " Train_Loss : 23.73146451146979, R2 : 0.6561232805252075\n",
      "Val_Loss : 21.893125534057617, R2 : 0.6358693838119507\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.045629501342773, R2 : 0.6333328485488892\n",
      "[26/500] \n",
      " Train_Loss : 23.211331743943063, R2 : 0.6594443980016207\n",
      "Val_Loss : 22.045629501342773, R2 : 0.6333328485488892\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.14544677734375, R2 : 0.631672739982605\n",
      "[27/500] \n",
      " Train_Loss : 22.31837639055754, R2 : 0.6767691907129789\n",
      "Val_Loss : 22.14544677734375, R2 : 0.631672739982605\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.50901222229004, R2 : 0.6256258487701416\n",
      "[28/500] \n",
      " Train_Loss : 23.833249368165667, R2 : 0.6548616792026319\n",
      "Val_Loss : 22.50901222229004, R2 : 0.6256258487701416\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.836076736450195, R2 : 0.6368181705474854\n",
      "[29/500] \n",
      " Train_Loss : 26.02299780594675, R2 : 0.6171107072579233\n",
      "Val_Loss : 21.836076736450195, R2 : 0.6368181705474854\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.432382583618164, R2 : 0.626900315284729\n",
      "[30/500] \n",
      " Train_Loss : 25.166624721727874, R2 : 0.6410403910436129\n",
      "Val_Loss : 22.432382583618164, R2 : 0.626900315284729\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.999570846557617, R2 : 0.634099006652832\n",
      "[31/500] \n",
      " Train_Loss : 23.412124081661826, R2 : 0.6620241121241921\n",
      "Val_Loss : 21.999570846557617, R2 : 0.634099006652832\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.819684982299805, R2 : 0.6370908617973328\n",
      "[32/500] \n",
      " Train_Loss : 21.596903800964355, R2 : 0.6913305928832606\n",
      "Val_Loss : 21.819684982299805, R2 : 0.6370908617973328\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.660661697387695, R2 : 0.6397356986999512\n",
      "[33/500] \n",
      " Train_Loss : 21.496878649059095, R2 : 0.6866939350178367\n",
      "Val_Loss : 21.660661697387695, R2 : 0.6397356986999512\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.786365509033203, R2 : 0.6376450061798096\n",
      "[34/500] \n",
      " Train_Loss : 21.477544357902126, R2 : 0.6839258639436019\n",
      "Val_Loss : 21.786365509033203, R2 : 0.6376450061798096\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.694015502929688, R2 : 0.6391810178756714\n",
      "[35/500] \n",
      " Train_Loss : 21.785948376906546, R2 : 0.6829203712312799\n",
      "Val_Loss : 21.694015502929688, R2 : 0.6391810178756714\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.099531173706055, R2 : 0.6324363946914673\n",
      "[36/500] \n",
      " Train_Loss : 22.6747761023672, R2 : 0.6632529120696219\n",
      "Val_Loss : 22.099531173706055, R2 : 0.6324363946914673\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.600772857666016, R2 : 0.6407318115234375\n",
      "[37/500] \n",
      " Train_Loss : 24.65771770477295, R2 : 0.6393683615483736\n",
      "Val_Loss : 21.600772857666016, R2 : 0.6407318115234375\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.73469352722168, R2 : 0.6385044455528259\n",
      "[38/500] \n",
      " Train_Loss : 25.161332180625514, R2 : 0.6329049687636527\n",
      "Val_Loss : 21.73469352722168, R2 : 0.6385044455528259\n",
      "torch.Size([81, 1])\n",
      "LOSS : 23.04692840576172, R2 : 0.6166791319847107\n",
      "[39/500] \n",
      " Train_Loss : 21.483632363771136, R2 : 0.7006686706292001\n",
      "Val_Loss : 23.04692840576172, R2 : 0.6166791319847107\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.166845321655273, R2 : 0.6313168406486511\n",
      "[40/500] \n",
      " Train_Loss : 21.416627909007826, R2 : 0.6943385789268895\n",
      "Val_Loss : 22.166845321655273, R2 : 0.6313168406486511\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.209518432617188, R2 : 0.630607008934021\n",
      "[41/500] \n",
      " Train_Loss : 21.868589401245117, R2 : 0.6798899173736572\n",
      "Val_Loss : 22.209518432617188, R2 : 0.630607008934021\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.719654083251953, R2 : 0.6387546062469482\n",
      "[42/500] \n",
      " Train_Loss : 22.184242624985544, R2 : 0.6862163041767321\n",
      "Val_Loss : 21.719654083251953, R2 : 0.6387546062469482\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.845081329345703, R2 : 0.6366684436798096\n",
      "[43/500] \n",
      " Train_Loss : 21.815035995684173, R2 : 0.68245488091519\n",
      "Val_Loss : 21.845081329345703, R2 : 0.6366684436798096\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.720993041992188, R2 : 0.6387323141098022\n",
      "[44/500] \n",
      " Train_Loss : 23.288713655973737, R2 : 0.6615994698122928\n",
      "Val_Loss : 21.720993041992188, R2 : 0.6387323141098022\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.85990333557129, R2 : 0.6364219188690186\n",
      "[45/500] \n",
      " Train_Loss : 23.286739650525544, R2 : 0.663796813864457\n",
      "Val_Loss : 21.85990333557129, R2 : 0.6364219188690186\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.294384002685547, R2 : 0.6291955709457397\n",
      "[46/500] \n",
      " Train_Loss : 21.168984362953587, R2 : 0.7047122967870612\n",
      "Val_Loss : 22.294384002685547, R2 : 0.6291955709457397\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.742660522460938, R2 : 0.6383719444274902\n",
      "[47/500] \n",
      " Train_Loss : 25.325542449951172, R2 : 0.6283491253852844\n",
      "Val_Loss : 21.742660522460938, R2 : 0.6383719444274902\n",
      "torch.Size([81, 1])\n",
      "LOSS : 32.755287170410156, R2 : 0.45520782470703125\n",
      "[48/500] \n",
      " Train_Loss : 25.5255991283216, R2 : 0.6398877376004269\n",
      "Val_Loss : 32.755287170410156, R2 : 0.45520782470703125\n",
      "torch.Size([81, 1])\n",
      "LOSS : 23.337692260742188, R2 : 0.6118431091308594\n",
      "[49/500] \n",
      " Train_Loss : 25.310730934143066, R2 : 0.6341010583074469\n",
      "Val_Loss : 23.337692260742188, R2 : 0.6118431091308594\n",
      "torch.Size([81, 1])\n",
      "LOSS : 33.43751907348633, R2 : 0.44386082887649536\n",
      "[50/500] \n",
      " Train_Loss : 26.89912469763505, R2 : 0.6099416550837065\n",
      "Val_Loss : 33.43751907348633, R2 : 0.44386082887649536\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.76760482788086, R2 : 0.621324896812439\n",
      "[51/500] \n",
      " Train_Loss : 28.230942726135254, R2 : 0.5878104253819114\n",
      "Val_Loss : 22.76760482788086, R2 : 0.621324896812439\n",
      "torch.Size([81, 1])\n",
      "LOSS : 29.158279418945312, R2 : 0.5150339603424072\n",
      "[52/500] \n",
      " Train_Loss : 23.500815266057064, R2 : 0.6949033705811751\n",
      "Val_Loss : 29.158279418945312, R2 : 0.5150339603424072\n",
      "torch.Size([81, 1])\n",
      "LOSS : 23.117961883544922, R2 : 0.6154976487159729\n",
      "[53/500] \n",
      " Train_Loss : 23.018077950728568, R2 : 0.674527789417066\n",
      "Val_Loss : 23.117961883544922, R2 : 0.6154976487159729\n",
      "torch.Size([81, 1])\n",
      "LOSS : 29.119375228881836, R2 : 0.5156810283660889\n",
      "[54/500] \n",
      " Train_Loss : 25.441760866265547, R2 : 0.6347117267156902\n",
      "Val_Loss : 29.119375228881836, R2 : 0.5156810283660889\n",
      "torch.Size([81, 1])\n",
      "LOSS : 23.29449462890625, R2 : 0.6125615835189819\n",
      "[55/500] \n",
      " Train_Loss : 22.869384564851458, R2 : 0.6949694093904997\n",
      "Val_Loss : 23.29449462890625, R2 : 0.6125615835189819\n",
      "torch.Size([81, 1])\n",
      "LOSS : 32.369075775146484, R2 : 0.4616314172744751\n",
      "[56/500] \n",
      " Train_Loss : 23.45793202048854, R2 : 0.6610913966831408\n",
      "Val_Loss : 32.369075775146484, R2 : 0.4616314172744751\n",
      "torch.Size([81, 1])\n",
      "LOSS : 25.395051956176758, R2 : 0.5776246786117554\n",
      "[57/500] \n",
      " Train_Loss : 24.598035235154, R2 : 0.6537058322053206\n",
      "Val_Loss : 25.395051956176758, R2 : 0.5776246786117554\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.939132690429688, R2 : 0.6351041793823242\n",
      "[58/500] \n",
      " Train_Loss : 25.523053520604183, R2 : 0.6271794218766061\n",
      "Val_Loss : 21.939132690429688, R2 : 0.6351041793823242\n",
      "torch.Size([81, 1])\n",
      "LOSS : 38.14606857299805, R2 : 0.3655473589897156\n",
      "[59/500] \n",
      " Train_Loss : 25.18555309897975, R2 : 0.6423541464303669\n",
      "Val_Loss : 38.14606857299805, R2 : 0.3655473589897156\n",
      "torch.Size([81, 1])\n",
      "LOSS : 23.995485305786133, R2 : 0.6009025573730469\n",
      "[60/500] \n",
      " Train_Loss : 22.716659445511667, R2 : 0.6895426041201541\n",
      "Val_Loss : 23.995485305786133, R2 : 0.6009025573730469\n",
      "torch.Size([81, 1])\n",
      "LOSS : 32.308990478515625, R2 : 0.4626306891441345\n",
      "[61/500] \n",
      " Train_Loss : 24.108301062332956, R2 : 0.6553373023083335\n",
      "Val_Loss : 32.308990478515625, R2 : 0.4626306891441345\n",
      "torch.Size([81, 1])\n",
      "LOSS : 24.082246780395508, R2 : 0.5994595289230347\n",
      "[62/500] \n",
      " Train_Loss : 23.022318840026855, R2 : 0.6890896872470254\n",
      "Val_Loss : 24.082246780395508, R2 : 0.5994595289230347\n",
      "torch.Size([81, 1])\n",
      "LOSS : 26.87895393371582, R2 : 0.5529441237449646\n",
      "[63/500] \n",
      " Train_Loss : 24.389390995627956, R2 : 0.6554247987897772\n",
      "Val_Loss : 26.87895393371582, R2 : 0.5529441237449646\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.436189651489258, R2 : 0.6268370151519775\n",
      "[64/500] \n",
      " Train_Loss : 22.617785052249307, R2 : 0.6965204540051912\n",
      "Val_Loss : 22.436189651489258, R2 : 0.6268370151519775\n",
      "torch.Size([81, 1])\n",
      "LOSS : 30.174299240112305, R2 : 0.4981353282928467\n",
      "[65/500] \n",
      " Train_Loss : 21.024203727119847, R2 : 0.7032691616761056\n",
      "Val_Loss : 30.174299240112305, R2 : 0.4981353282928467\n",
      "torch.Size([81, 1])\n",
      "LOSS : 21.676647186279297, R2 : 0.6394698619842529\n",
      "[66/500] \n",
      " Train_Loss : 27.096521879497327, R2 : 0.6153321611253839\n",
      "Val_Loss : 21.676647186279297, R2 : 0.6394698619842529\n",
      "torch.Size([81, 1])\n",
      "LOSS : 45.09424591064453, R2 : 0.24998396635055542\n",
      "[67/500] \n",
      " Train_Loss : 24.34364898581254, R2 : 0.6507495045661926\n",
      "Val_Loss : 45.09424591064453, R2 : 0.24998396635055542\n",
      "torch.Size([81, 1])\n",
      "LOSS : 23.287429809570312, R2 : 0.6126790046691895\n",
      "[68/500] \n",
      " Train_Loss : 27.59646561271266, R2 : 0.6228640393206948\n",
      "Val_Loss : 23.287429809570312, R2 : 0.6126790046691895\n",
      "torch.Size([81, 1])\n",
      "LOSS : 33.366058349609375, R2 : 0.4450494050979614\n",
      "[69/500] \n",
      " Train_Loss : 24.16278492776971, R2 : 0.6652799468291434\n",
      "Val_Loss : 33.366058349609375, R2 : 0.4450494050979614\n",
      "torch.Size([81, 1])\n",
      "LOSS : 29.210289001464844, R2 : 0.514168918132782\n",
      "[70/500] \n",
      " Train_Loss : 24.834034869545384, R2 : 0.6723808395235162\n",
      "Val_Loss : 29.210289001464844, R2 : 0.514168918132782\n",
      "torch.Size([81, 1])\n",
      "LOSS : 27.91410255432129, R2 : 0.5357273817062378\n",
      "[71/500] \n",
      " Train_Loss : 34.70552143297697, R2 : 0.4700787475234584\n",
      "Val_Loss : 27.91410255432129, R2 : 0.5357273817062378\n",
      "torch.Size([81, 1])\n",
      "LOSS : 51.3289794921875, R2 : 0.14628660678863525\n",
      "[72/500] \n",
      " Train_Loss : 33.96246438277395, R2 : 0.5244037257997614\n",
      "Val_Loss : 51.3289794921875, R2 : 0.14628660678863525\n",
      "torch.Size([81, 1])\n",
      "LOSS : 27.310047149658203, R2 : 0.5457741022109985\n",
      "[73/500] \n",
      " Train_Loss : 30.959688939546282, R2 : 0.5782484286709836\n",
      "Val_Loss : 27.310047149658203, R2 : 0.5457741022109985\n",
      "torch.Size([81, 1])\n",
      "LOSS : 32.6385383605957, R2 : 0.4571496248245239\n",
      "[74/500] \n",
      " Train_Loss : 22.7099760708056, R2 : 0.6859989636822751\n",
      "Val_Loss : 32.6385383605957, R2 : 0.4571496248245239\n",
      "torch.Size([81, 1])\n",
      "LOSS : 22.496606826782227, R2 : 0.6258321404457092\n",
      "[75/500] \n",
      " Train_Loss : 24.199416562130576, R2 : 0.6614973356849269\n",
      "Val_Loss : 22.496606826782227, R2 : 0.6258321404457092\n",
      "torch.Size([81, 1])\n",
      "LOSS : 39.49741744995117, R2 : 0.34307146072387695\n",
      "[76/500] \n",
      " Train_Loss : 23.160925413432874, R2 : 0.6642059495574549\n",
      "Val_Loss : 39.49741744995117, R2 : 0.34307146072387695\n",
      "torch.Size([81, 1])\n",
      "LOSS : 52.842952728271484, R2 : 0.12110596895217896\n",
      "[77/500] \n",
      " Train_Loss : 32.85156546140972, R2 : 0.5424215260304903\n",
      "Val_Loss : 52.842952728271484, R2 : 0.12110596895217896\n",
      "torch.Size([81, 1])\n",
      "LOSS : 55.60279083251953, R2 : 0.0752037763595581\n",
      "[78/500] \n",
      " Train_Loss : 31.33158927214773, R2 : 0.5828008777216861\n",
      "Val_Loss : 55.60279083251953, R2 : 0.0752037763595581\n",
      "torch.Size([81, 1])\n",
      "LOSS : 36.53651809692383, R2 : 0.39231765270233154\n",
      "[79/500] \n",
      " Train_Loss : 38.07113245913857, R2 : 0.4869665785839683\n",
      "Val_Loss : 36.53651809692383, R2 : 0.39231765270233154\n",
      "torch.Size([81, 1])\n",
      "LOSS : 73.73580169677734, R2 : -0.2263878583908081\n",
      "[80/500] \n",
      " Train_Loss : 39.57868114270662, R2 : 0.43681805384786504\n",
      "Val_Loss : 73.73580169677734, R2 : -0.2263878583908081\n",
      "torch.Size([81, 1])\n",
      "LOSS : 59.36324691772461, R2 : 0.012659251689910889\n",
      "[81/500] \n",
      " Train_Loss : 63.08729482951917, R2 : 0.1423571643076445\n",
      "Val_Loss : 59.36324691772461, R2 : 0.012659251689910889\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.635833740234375, R2 : -0.0085066556930542\n",
      "[82/500] \n",
      " Train_Loss : 88.20007846229954, R2 : -0.08168704886185496\n",
      "Val_Loss : 60.635833740234375, R2 : -0.0085066556930542\n",
      "torch.Size([81, 1])\n",
      "LOSS : 62.16166305541992, R2 : -0.033884644508361816\n",
      "[83/500] \n",
      " Train_Loss : 86.49801364697908, R2 : -0.08718539539136384\n",
      "Val_Loss : 62.16166305541992, R2 : -0.033884644508361816\n",
      "torch.Size([81, 1])\n",
      "LOSS : 61.87723159790039, R2 : -0.029153823852539062\n",
      "[84/500] \n",
      " Train_Loss : 89.32617267809417, R2 : -0.1383443317915264\n",
      "Val_Loss : 61.87723159790039, R2 : -0.029153823852539062\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.14474105834961, R2 : -0.0003387928009033203\n",
      "[85/500] \n",
      " Train_Loss : 88.37966718171772, R2 : -0.11084976949189838\n",
      "Val_Loss : 60.14474105834961, R2 : -0.0003387928009033203\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.21884536743164, R2 : -0.0015712976455688477\n",
      "[86/500] \n",
      " Train_Loss : 86.66832331607216, R2 : -0.08549237878699052\n",
      "Val_Loss : 60.21884536743164, R2 : -0.0015712976455688477\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.19873809814453, R2 : -0.0012367963790893555\n",
      "[87/500] \n",
      " Train_Loss : 86.82656187760203, R2 : -0.08908546598334062\n",
      "Val_Loss : 60.19873809814453, R2 : -0.0012367963790893555\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.17957305908203, R2 : -0.0009181499481201172\n",
      "[88/500] \n",
      " Train_Loss : 86.75333525005139, R2 : -0.08706336899807579\n",
      "Val_Loss : 60.17957305908203, R2 : -0.0009181499481201172\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.18507766723633, R2 : -0.0010095834732055664\n",
      "[89/500] \n",
      " Train_Loss : 86.71379741869475, R2 : -0.08675422793940495\n",
      "Val_Loss : 60.18507766723633, R2 : -0.0010095834732055664\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1821403503418, R2 : -0.0009608268737792969\n",
      "[90/500] \n",
      " Train_Loss : 86.72346044841565, R2 : -0.0868287211970279\n",
      "Val_Loss : 60.1821403503418, R2 : -0.0009608268737792969\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.184173583984375, R2 : -0.000994563102722168\n",
      "[91/500] \n",
      " Train_Loss : 86.7195802989759, R2 : -0.08680179872010883\n",
      "Val_Loss : 60.184173583984375, R2 : -0.000994563102722168\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.18547439575195, R2 : -0.0010162591934204102\n",
      "[92/500] \n",
      " Train_Loss : 86.72742452119526, R2 : -0.08695392859609503\n",
      "Val_Loss : 60.18547439575195, R2 : -0.0010162591934204102\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.187095642089844, R2 : -0.0010432004928588867\n",
      "[93/500] \n",
      " Train_Loss : 86.7339096069336, R2 : -0.08707739804920397\n",
      "Val_Loss : 60.187095642089844, R2 : -0.0010432004928588867\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.188812255859375, R2 : -0.0010718107223510742\n",
      "[94/500] \n",
      " Train_Loss : 86.74128211172004, R2 : -0.08722163501538728\n",
      "Val_Loss : 60.188812255859375, R2 : -0.0010718107223510742\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.190521240234375, R2 : -0.0011001825332641602\n",
      "[95/500] \n",
      " Train_Loss : 86.74884806181255, R2 : -0.08736590335243627\n",
      "Val_Loss : 60.190521240234375, R2 : -0.0011001825332641602\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.19227600097656, R2 : -0.0011293888092041016\n",
      "[96/500] \n",
      " Train_Loss : 86.75632416574578, R2 : -0.08750967602980764\n",
      "Val_Loss : 60.19227600097656, R2 : -0.0011293888092041016\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.194026947021484, R2 : -0.0011584758758544922\n",
      "[97/500] \n",
      " Train_Loss : 86.76384584527267, R2 : -0.08765391299599096\n",
      "Val_Loss : 60.194026947021484, R2 : -0.0011584758758544922\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.19580078125, R2 : -0.001188039779663086\n",
      "[98/500] \n",
      " Train_Loss : 86.77131241246273, R2 : -0.08779693277258623\n",
      "Val_Loss : 60.19580078125, R2 : -0.001188039779663086\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.19759750366211, R2 : -0.0012178421020507812\n",
      "[99/500] \n",
      " Train_Loss : 86.7787497671027, R2 : -0.08793952590540836\n",
      "Val_Loss : 60.19759750366211, R2 : -0.0012178421020507812\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.19938659667969, R2 : -0.0012476444244384766\n",
      "[100/500] \n",
      " Train_Loss : 86.78614636471397, R2 : -0.08808115908974096\n",
      "Val_Loss : 60.19938659667969, R2 : -0.0012476444244384766\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2011833190918, R2 : -0.0012775659561157227\n",
      "[101/500] \n",
      " Train_Loss : 86.7934953789962, R2 : -0.08822186997062281\n",
      "Val_Loss : 60.2011833190918, R2 : -0.0012775659561157227\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2030029296875, R2 : -0.001307845115661621\n",
      "[102/500] \n",
      " Train_Loss : 86.8007862693385, R2 : -0.08836145777451365\n",
      "Val_Loss : 60.2030029296875, R2 : -0.001307845115661621\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.20481872558594, R2 : -0.0013380050659179688\n",
      "[103/500] \n",
      " Train_Loss : 86.80802546049419, R2 : -0.08849997269479852\n",
      "Val_Loss : 60.20481872558594, R2 : -0.0013380050659179688\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.20663833618164, R2 : -0.0013682842254638672\n",
      "[104/500] \n",
      " Train_Loss : 86.81519779406096, R2 : -0.08863721395793714\n",
      "Val_Loss : 60.20663833618164, R2 : -0.0013682842254638672\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.208465576171875, R2 : -0.0013986825942993164\n",
      "[105/500] \n",
      " Train_Loss : 86.82231340910259, R2 : -0.0887733258699116\n",
      "Val_Loss : 60.208465576171875, R2 : -0.0013986825942993164\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.21029281616211, R2 : -0.0014290809631347656\n",
      "[106/500] \n",
      " Train_Loss : 86.82936025920667, R2 : -0.08890798844789204\n",
      "Val_Loss : 60.21029281616211, R2 : -0.0014290809631347656\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.21211242675781, R2 : -0.001459360122680664\n",
      "[107/500] \n",
      " Train_Loss : 86.83633513199656, R2 : -0.08904129580447548\n",
      "Val_Loss : 60.21211242675781, R2 : -0.001459360122680664\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.21394729614258, R2 : -0.0014897584915161133\n",
      "[108/500] \n",
      " Train_Loss : 86.84323792708547, R2 : -0.08917321029462312\n",
      "Val_Loss : 60.21394729614258, R2 : -0.0014897584915161133\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.21575927734375, R2 : -0.001519918441772461\n",
      "[109/500] \n",
      " Train_Loss : 86.85006021198474, R2 : -0.08930354996731407\n",
      "Val_Loss : 60.21575927734375, R2 : -0.001519918441772461\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.21757888793945, R2 : -0.0015501976013183594\n",
      "[110/500] \n",
      " Train_Loss : 86.85679907547801, R2 : -0.08943219561325877\n",
      "Val_Loss : 60.21757888793945, R2 : -0.0015501976013183594\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.219390869140625, R2 : -0.001580357551574707\n",
      "[111/500] \n",
      " Train_Loss : 86.86345532065944, R2 : -0.08955931663513184\n",
      "Val_Loss : 60.219390869140625, R2 : -0.001580357551574707\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.22119903564453, R2 : -0.001610398292541504\n",
      "[112/500] \n",
      " Train_Loss : 86.87002623708625, R2 : -0.08968472480773926\n",
      "Val_Loss : 60.22119903564453, R2 : -0.001610398292541504\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.222991943359375, R2 : -0.00164031982421875\n",
      "[113/500] \n",
      " Train_Loss : 86.87650469729775, R2 : -0.08980831347013775\n",
      "Val_Loss : 60.222991943359375, R2 : -0.00164031982421875\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.22477722167969, R2 : -0.0016700029373168945\n",
      "[114/500] \n",
      " Train_Loss : 86.88289501792507, R2 : -0.08993023320248253\n",
      "Val_Loss : 60.22477722167969, R2 : -0.0016700029373168945\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2265510559082, R2 : -0.0016994476318359375\n",
      "[115/500] \n",
      " Train_Loss : 86.88919017189427, R2 : -0.09005028323123329\n",
      "Val_Loss : 60.2265510559082, R2 : -0.0016994476318359375\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.228309631347656, R2 : -0.001728653907775879\n",
      "[116/500] \n",
      " Train_Loss : 86.89538724798905, R2 : -0.09016838826631245\n",
      "Val_Loss : 60.228309631347656, R2 : -0.001728653907775879\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.230064392089844, R2 : -0.0017578601837158203\n",
      "[117/500] \n",
      " Train_Loss : 86.90149006090667, R2 : -0.0902846612428364\n",
      "Val_Loss : 60.230064392089844, R2 : -0.0017578601837158203\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.231788635253906, R2 : -0.0017865896224975586\n",
      "[118/500] \n",
      " Train_Loss : 86.90749098125256, R2 : -0.0903989641289962\n",
      "Val_Loss : 60.231788635253906, R2 : -0.0017865896224975586\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.23350524902344, R2 : -0.0018150806427001953\n",
      "[119/500] \n",
      " Train_Loss : 86.91338639510305, R2 : -0.09051124673140676\n",
      "Val_Loss : 60.23350524902344, R2 : -0.0018150806427001953\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.23521423339844, R2 : -0.0018434524536132812\n",
      "[120/500] \n",
      " Train_Loss : 86.91918132179661, R2 : -0.09062154669510691\n",
      "Val_Loss : 60.23521423339844, R2 : -0.0018434524536132812\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.236881256103516, R2 : -0.0018712282180786133\n",
      "[121/500] \n",
      " Train_Loss : 86.92486813193874, R2 : -0.09072978873001902\n",
      "Val_Loss : 60.236881256103516, R2 : -0.0018712282180786133\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.23854064941406, R2 : -0.0018988847732543945\n",
      "[122/500] \n",
      " Train_Loss : 86.9304441150866, R2 : -0.09083589754606548\n",
      "Val_Loss : 60.23854064941406, R2 : -0.0018988847732543945\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.24018478393555, R2 : -0.0019261837005615234\n",
      "[123/500] \n",
      " Train_Loss : 86.93591870759663, R2 : -0.09093999235253585\n",
      "Val_Loss : 60.24018478393555, R2 : -0.0019261837005615234\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.24179458618164, R2 : -0.0019530057907104492\n",
      "[124/500] \n",
      " Train_Loss : 86.94127695184005, R2 : -0.0910418849242361\n",
      "Val_Loss : 60.24179458618164, R2 : -0.0019530057907104492\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.24340057373047, R2 : -0.0019797086715698242\n",
      "[125/500] \n",
      " Train_Loss : 86.94652898688065, R2 : -0.09114167564793636\n",
      "Val_Loss : 60.24340057373047, R2 : -0.0019797086715698242\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.24496078491211, R2 : -0.0020055770874023438\n",
      "[126/500] \n",
      " Train_Loss : 86.9516671833239, R2 : -0.09123928295938592\n",
      "Val_Loss : 60.24496078491211, R2 : -0.0020055770874023438\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.24650955200195, R2 : -0.0020314455032348633\n",
      "[127/500] \n",
      " Train_Loss : 86.9566899349815, R2 : -0.09133465666519969\n",
      "Val_Loss : 60.24650955200195, R2 : -0.0020314455032348633\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.248023986816406, R2 : -0.002056598663330078\n",
      "[128/500] \n",
      " Train_Loss : 86.96160175925807, R2 : -0.09142790342632093\n",
      "Val_Loss : 60.248023986816406, R2 : -0.002056598663330078\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.24951171875, R2 : -0.00208127498626709\n",
      "[129/500] \n",
      " Train_Loss : 86.96639713488128, R2 : -0.09151890403346012\n",
      "Val_Loss : 60.24951171875, R2 : -0.00208127498626709\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.25098419189453, R2 : -0.0021058320999145508\n",
      "[130/500] \n",
      " Train_Loss : 86.97107345179508, R2 : -0.09160763966409784\n",
      "Val_Loss : 60.25098419189453, R2 : -0.0021058320999145508\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.25242233276367, R2 : -0.002129793167114258\n",
      "[131/500] \n",
      " Train_Loss : 86.97564255563836, R2 : -0.09169422952752364\n",
      "Val_Loss : 60.25242233276367, R2 : -0.002129793167114258\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.25383377075195, R2 : -0.002153158187866211\n",
      "[132/500] \n",
      " Train_Loss : 86.98008748104698, R2 : -0.09177847285019725\n",
      "Val_Loss : 60.25383377075195, R2 : -0.002153158187866211\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.25520324707031, R2 : -0.00217592716217041\n",
      "[133/500] \n",
      " Train_Loss : 86.98441445200066, R2 : -0.09186050138975445\n",
      "Val_Loss : 60.25520324707031, R2 : -0.00217592716217041\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.256553649902344, R2 : -0.002198457717895508\n",
      "[134/500] \n",
      " Train_Loss : 86.98862668087608, R2 : -0.09194027122698332\n",
      "Val_Loss : 60.256553649902344, R2 : -0.002198457717895508\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.25787353515625, R2 : -0.0022203922271728516\n",
      "[135/500] \n",
      " Train_Loss : 86.99272547270122, R2 : -0.09201783882944208\n",
      "Val_Loss : 60.25787353515625, R2 : -0.0022203922271728516\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2591552734375, R2 : -0.0022417306900024414\n",
      "[136/500] \n",
      " Train_Loss : 86.99670550697728, R2 : -0.09209316027791876\n",
      "Val_Loss : 60.2591552734375, R2 : -0.0022417306900024414\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.26041030883789, R2 : -0.002262592315673828\n",
      "[137/500] \n",
      " Train_Loss : 87.00056316978053, R2 : -0.09216617283068206\n",
      "Val_Loss : 60.26041030883789, R2 : -0.002262592315673828\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.261627197265625, R2 : -0.002282857894897461\n",
      "[138/500] \n",
      " Train_Loss : 87.00431000558953, R2 : -0.09223696432615582\n",
      "Val_Loss : 60.261627197265625, R2 : -0.002282857894897461\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.262821197509766, R2 : -0.0023027658462524414\n",
      "[139/500] \n",
      " Train_Loss : 87.0079355741802, R2 : -0.09230539673253109\n",
      "Val_Loss : 60.262821197509766, R2 : -0.0023027658462524414\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.26396560668945, R2 : -0.0023217201232910156\n",
      "[140/500] \n",
      " Train_Loss : 87.01144619991905, R2 : -0.09237172101673327\n",
      "Val_Loss : 60.26396560668945, R2 : -0.0023217201232910156\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.26510238647461, R2 : -0.002340555191040039\n",
      "[141/500] \n",
      " Train_Loss : 87.01483435379832, R2 : -0.0924357113085295\n",
      "Val_Loss : 60.26510238647461, R2 : -0.002340555191040039\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.26618576049805, R2 : -0.002358675003051758\n",
      "[142/500] \n",
      " Train_Loss : 87.01811378880551, R2 : -0.09249752446224815\n",
      "Val_Loss : 60.26618576049805, R2 : -0.002358675003051758\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.267242431640625, R2 : -0.0023761987686157227\n",
      "[143/500] \n",
      " Train_Loss : 87.02127637361225, R2 : -0.09255716675206234\n",
      "Val_Loss : 60.267242431640625, R2 : -0.0023761987686157227\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.26826095581055, R2 : -0.0023931264877319336\n",
      "[144/500] \n",
      " Train_Loss : 87.02432722794383, R2 : -0.09261460053293329\n",
      "Val_Loss : 60.26826095581055, R2 : -0.0023931264877319336\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.269248962402344, R2 : -0.0024095773696899414\n",
      "[145/500] \n",
      " Train_Loss : 87.02725470693488, R2 : -0.09266973796643709\n",
      "Val_Loss : 60.269248962402344, R2 : -0.0024095773696899414\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27019500732422, R2 : -0.0024253129959106445\n",
      "[146/500] \n",
      " Train_Loss : 87.03007356744064, R2 : -0.09272277355194092\n",
      "Val_Loss : 60.27019500732422, R2 : -0.0024253129959106445\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2711181640625, R2 : -0.0024406909942626953\n",
      "[147/500] \n",
      " Train_Loss : 87.03278330752724, R2 : -0.09277370728944477\n",
      "Val_Loss : 60.2711181640625, R2 : -0.0024406909942626953\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.272003173828125, R2 : -0.0024553537368774414\n",
      "[148/500] \n",
      " Train_Loss : 87.03537178039551, R2 : -0.09282231330871582\n",
      "Val_Loss : 60.272003173828125, R2 : -0.0024553537368774414\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27284622192383, R2 : -0.0024694204330444336\n",
      "[149/500] \n",
      " Train_Loss : 87.03785193593879, R2 : -0.09286882375416003\n",
      "Val_Loss : 60.27284622192383, R2 : -0.0024694204330444336\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27366638183594, R2 : -0.0024831295013427734\n",
      "[150/500] \n",
      " Train_Loss : 87.04022748846756, R2 : -0.09291337665758635\n",
      "Val_Loss : 60.27366638183594, R2 : -0.0024831295013427734\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.274444580078125, R2 : -0.002496004104614258\n",
      "[151/500] \n",
      " Train_Loss : 87.0424959283126, R2 : -0.09295583398718583\n",
      "Val_Loss : 60.274444580078125, R2 : -0.002496004104614258\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.275184631347656, R2 : -0.002508401870727539\n",
      "[152/500] \n",
      " Train_Loss : 87.044651533428, R2 : -0.09299615182374653\n",
      "Val_Loss : 60.275184631347656, R2 : -0.002508401870727539\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27589797973633, R2 : -0.0025202035903930664\n",
      "[153/500] \n",
      " Train_Loss : 87.0466961107756, R2 : -0.09303435526396099\n",
      "Val_Loss : 60.27589797973633, R2 : -0.0025202035903930664\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27656555175781, R2 : -0.002531290054321289\n",
      "[154/500] \n",
      " Train_Loss : 87.04863528201454, R2 : -0.09307055724294562\n",
      "Val_Loss : 60.27656555175781, R2 : -0.002531290054321289\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2772102355957, R2 : -0.0025420188903808594\n",
      "[155/500] \n",
      " Train_Loss : 87.05047246029503, R2 : -0.09310479540573924\n",
      "Val_Loss : 60.2772102355957, R2 : -0.0025420188903808594\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2778205871582, R2 : -0.0025521516799926758\n",
      "[156/500] \n",
      " Train_Loss : 87.05220152202405, R2 : -0.09313698191391795\n",
      "Val_Loss : 60.2778205871582, R2 : -0.0025521516799926758\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27839279174805, R2 : -0.0025616884231567383\n",
      "[157/500] \n",
      " Train_Loss : 87.05383381090667, R2 : -0.09316730499267578\n",
      "Val_Loss : 60.27839279174805, R2 : -0.0025616884231567383\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.278934478759766, R2 : -0.0025707483291625977\n",
      "[158/500] \n",
      " Train_Loss : 87.05536340412341, R2 : -0.09319563915855006\n",
      "Val_Loss : 60.278934478759766, R2 : -0.0025707483291625977\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.279441833496094, R2 : -0.0025790929794311523\n",
      "[159/500] \n",
      " Train_Loss : 87.05679251018323, R2 : -0.09322207224996466\n",
      "Val_Loss : 60.279441833496094, R2 : -0.0025790929794311523\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2799186706543, R2 : -0.0025870800018310547\n",
      "[160/500] \n",
      " Train_Loss : 87.0581266503585, R2 : -0.09324668583117034\n",
      "Val_Loss : 60.2799186706543, R2 : -0.0025870800018310547\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.280364990234375, R2 : -0.002594470977783203\n",
      "[161/500] \n",
      " Train_Loss : 87.05935538442512, R2 : -0.09326927285445363\n",
      "Val_Loss : 60.280364990234375, R2 : -0.002594470977783203\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28076934814453, R2 : -0.002601146697998047\n",
      "[162/500] \n",
      " Train_Loss : 87.06049688238846, R2 : -0.0932902034960295\n",
      "Val_Loss : 60.28076934814453, R2 : -0.002601146697998047\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28114700317383, R2 : -0.0026074647903442383\n",
      "[163/500] \n",
      " Train_Loss : 87.06153518275211, R2 : -0.09330918286976062\n",
      "Val_Loss : 60.28114700317383, R2 : -0.0026074647903442383\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28150177001953, R2 : -0.0026134252548217773\n",
      "[164/500] \n",
      " Train_Loss : 87.0624835365697, R2 : -0.09332643057170667\n",
      "Val_Loss : 60.28150177001953, R2 : -0.0026134252548217773\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28181838989258, R2 : -0.0026186704635620117\n",
      "[165/500] \n",
      " Train_Loss : 87.06334164268092, R2 : -0.09334194032769454\n",
      "Val_Loss : 60.28181838989258, R2 : -0.0026186704635620117\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2821044921875, R2 : -0.002623438835144043\n",
      "[166/500] \n",
      " Train_Loss : 87.0641118099815, R2 : -0.09335585644370631\n",
      "Val_Loss : 60.2821044921875, R2 : -0.002623438835144043\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28236389160156, R2 : -0.002627730369567871\n",
      "[167/500] \n",
      " Train_Loss : 87.06479152880217, R2 : -0.0933679279528166\n",
      "Val_Loss : 60.28236389160156, R2 : -0.002627730369567871\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.282588958740234, R2 : -0.0026314258575439453\n",
      "[168/500] \n",
      " Train_Loss : 87.06537838986046, R2 : -0.0933782928868344\n",
      "Val_Loss : 60.282588958740234, R2 : -0.0026314258575439453\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.282779693603516, R2 : -0.0026346445083618164\n",
      "[169/500] \n",
      " Train_Loss : 87.06588574459678, R2 : -0.09338715829347309\n",
      "Val_Loss : 60.282779693603516, R2 : -0.0026346445083618164\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28295135498047, R2 : -0.002637505531311035\n",
      "[170/500] \n",
      " Train_Loss : 87.0663090756065, R2 : -0.09339431085084614\n",
      "Val_Loss : 60.28295135498047, R2 : -0.002637505531311035\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28308868408203, R2 : -0.0026397705078125\n",
      "[171/500] \n",
      " Train_Loss : 87.06664496973941, R2 : -0.09339988231658936\n",
      "Val_Loss : 60.28308868408203, R2 : -0.0026397705078125\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.283203125, R2 : -0.0026416778564453125\n",
      "[172/500] \n",
      " Train_Loss : 87.06689914904143, R2 : -0.09340393543243408\n",
      "Val_Loss : 60.283203125, R2 : -0.0026416778564453125\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.283294677734375, R2 : -0.0026432275772094727\n",
      "[173/500] \n",
      " Train_Loss : 87.06707783749229, R2 : -0.09340644510168779\n",
      "Val_Loss : 60.283294677734375, R2 : -0.0026432275772094727\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.283348083496094, R2 : -0.002644062042236328\n",
      "[174/500] \n",
      " Train_Loss : 87.06717290376362, R2 : -0.09340742387269672\n",
      "Val_Loss : 60.283348083496094, R2 : -0.002644062042236328\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28337860107422, R2 : -0.002644658088684082\n",
      "[175/500] \n",
      " Train_Loss : 87.06719217802349, R2 : -0.09340695330971166\n",
      "Val_Loss : 60.28337860107422, R2 : -0.002644658088684082\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28337860107422, R2 : -0.002644658088684082\n",
      "[176/500] \n",
      " Train_Loss : 87.0671359614322, R2 : -0.09340507105777138\n",
      "Val_Loss : 60.28337860107422, R2 : -0.002644658088684082\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28336715698242, R2 : -0.0026444196701049805\n",
      "[177/500] \n",
      " Train_Loss : 87.06701067874306, R2 : -0.09340182731026098\n",
      "Val_Loss : 60.28336715698242, R2 : -0.0026444196701049805\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2833251953125, R2 : -0.0026437044143676758\n",
      "[178/500] \n",
      " Train_Loss : 87.06681562724866, R2 : -0.09339727853473864\n",
      "Val_Loss : 60.2833251953125, R2 : -0.0026437044143676758\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28327560424805, R2 : -0.0026428699493408203\n",
      "[179/500] \n",
      " Train_Loss : 87.06656445954975, R2 : -0.09339172589151483\n",
      "Val_Loss : 60.28327560424805, R2 : -0.0026428699493408203\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.283172607421875, R2 : -0.0026412010192871094\n",
      "[180/500] \n",
      " Train_Loss : 87.0662565733257, R2 : -0.09338491213949103\n",
      "Val_Loss : 60.283172607421875, R2 : -0.0026412010192871094\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.283050537109375, R2 : -0.002639174461364746\n",
      "[181/500] \n",
      " Train_Loss : 87.06582792181717, R2 : -0.09337585223348517\n",
      "Val_Loss : 60.283050537109375, R2 : -0.002639174461364746\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.282920837402344, R2 : -0.002637028694152832\n",
      "[182/500] \n",
      " Train_Loss : 87.06535008079128, R2 : -0.09336591394324052\n",
      "Val_Loss : 60.282920837402344, R2 : -0.002637028694152832\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28274917602539, R2 : -0.0026341676712036133\n",
      "[183/500] \n",
      " Train_Loss : 87.06480467946906, R2 : -0.09335467062498394\n",
      "Val_Loss : 60.28274917602539, R2 : -0.0026341676712036133\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28257751464844, R2 : -0.0026313066482543945\n",
      "[184/500] \n",
      " Train_Loss : 87.06419021204898, R2 : -0.09334212855288856\n",
      "Val_Loss : 60.28257751464844, R2 : -0.0026313066482543945\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2823600769043, R2 : -0.0026276111602783203\n",
      "[185/500] \n",
      " Train_Loss : 87.06352284080104, R2 : -0.09332853241970665\n",
      "Val_Loss : 60.2823600769043, R2 : -0.0026276111602783203\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28213119506836, R2 : -0.0026237964630126953\n",
      "[186/500] \n",
      " Train_Loss : 87.06278941505833, R2 : -0.0933137065485904\n",
      "Val_Loss : 60.28213119506836, R2 : -0.0026237964630126953\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.281883239746094, R2 : -0.0026197433471679688\n",
      "[187/500] \n",
      " Train_Loss : 87.06198963366057, R2 : -0.09329764466536672\n",
      "Val_Loss : 60.281883239746094, R2 : -0.0026197433471679688\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2816162109375, R2 : -0.00261533260345459\n",
      "[188/500] \n",
      " Train_Loss : 87.06114056235866, R2 : -0.09328056636609529\n",
      "Val_Loss : 60.2816162109375, R2 : -0.00261533260345459\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.281333923339844, R2 : -0.0026105642318725586\n",
      "[189/500] \n",
      " Train_Loss : 87.06022533617522, R2 : -0.09326228342558208\n",
      "Val_Loss : 60.281333923339844, R2 : -0.0026105642318725586\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28102111816406, R2 : -0.002605438232421875\n",
      "[190/500] \n",
      " Train_Loss : 87.05926011738025, R2 : -0.093243071907445\n",
      "Val_Loss : 60.28102111816406, R2 : -0.002605438232421875\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.280696868896484, R2 : -0.002599954605102539\n",
      "[191/500] \n",
      " Train_Loss : 87.05824580945466, R2 : -0.0932228502474333\n",
      "Val_Loss : 60.280696868896484, R2 : -0.002599954605102539\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.280357360839844, R2 : -0.0025943517684936523\n",
      "[192/500] \n",
      " Train_Loss : 87.05716464394017, R2 : -0.09320141767200671\n",
      "Val_Loss : 60.280357360839844, R2 : -0.0025943517684936523\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.28000259399414, R2 : -0.002588510513305664\n",
      "[193/500] \n",
      " Train_Loss : 87.05603408813477, R2 : -0.09317906279312937\n",
      "Val_Loss : 60.28000259399414, R2 : -0.002588510513305664\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27962112426758, R2 : -0.0025821924209594727\n",
      "[194/500] \n",
      " Train_Loss : 87.05485614977385, R2 : -0.09315572286906995\n",
      "Val_Loss : 60.27962112426758, R2 : -0.0025821924209594727\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.279232025146484, R2 : -0.0025756359100341797\n",
      "[195/500] \n",
      " Train_Loss : 87.05362540797184, R2 : -0.09313140417400159\n",
      "Val_Loss : 60.279232025146484, R2 : -0.0025756359100341797\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2788200378418, R2 : -0.002568840980529785\n",
      "[196/500] \n",
      " Train_Loss : 87.05234748438785, R2 : -0.09310618827217504\n",
      "Val_Loss : 60.2788200378418, R2 : -0.002568840980529785\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27839279174805, R2 : -0.0025616884231567383\n",
      "[197/500] \n",
      " Train_Loss : 87.0510246879176, R2 : -0.09308015672784102\n",
      "Val_Loss : 60.27839279174805, R2 : -0.0025616884231567383\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2779655456543, R2 : -0.0025545358657836914\n",
      "[198/500] \n",
      " Train_Loss : 87.0496469798841, R2 : -0.09305304602572792\n",
      "Val_Loss : 60.2779655456543, R2 : -0.0025545358657836914\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.277496337890625, R2 : -0.0025467872619628906\n",
      "[199/500] \n",
      " Train_Loss : 87.04823564228259, R2 : -0.09302529535795513\n",
      "Val_Loss : 60.277496337890625, R2 : -0.0025467872619628906\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27703094482422, R2 : -0.00253903865814209\n",
      "[200/500] \n",
      " Train_Loss : 87.04676989505165, R2 : -0.09299648435492265\n",
      "Val_Loss : 60.27703094482422, R2 : -0.00253903865814209\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.276546478271484, R2 : -0.0025310516357421875\n",
      "[201/500] \n",
      " Train_Loss : 87.04526007802863, R2 : -0.09296693299946032\n",
      "Val_Loss : 60.276546478271484, R2 : -0.0025310516357421875\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27604675292969, R2 : -0.002522706985473633\n",
      "[202/500] \n",
      " Train_Loss : 87.04371171248586, R2 : -0.09293656600149054\n",
      "Val_Loss : 60.27604675292969, R2 : -0.002522706985473633\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27554702758789, R2 : -0.002514362335205078\n",
      "[203/500] \n",
      " Train_Loss : 87.0421249991969, R2 : -0.09290544610274465\n",
      "Val_Loss : 60.27554702758789, R2 : -0.002514362335205078\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27500915527344, R2 : -0.0025054216384887695\n",
      "[204/500] \n",
      " Train_Loss : 87.04049010025828, R2 : -0.0928734352714137\n",
      "Val_Loss : 60.27500915527344, R2 : -0.0025054216384887695\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.274478912353516, R2 : -0.0024966001510620117\n",
      "[205/500] \n",
      " Train_Loss : 87.03881444429096, R2 : -0.09284071545851857\n",
      "Val_Loss : 60.274478912353516, R2 : -0.0024966001510620117\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27393341064453, R2 : -0.0024875402450561523\n",
      "[206/500] \n",
      " Train_Loss : 87.03710776881168, R2 : -0.09280737450248316\n",
      "Val_Loss : 60.27393341064453, R2 : -0.0024875402450561523\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27336502075195, R2 : -0.0024781227111816406\n",
      "[207/500] \n",
      " Train_Loss : 87.03536485370837, R2 : -0.09277325554897911\n",
      "Val_Loss : 60.27336502075195, R2 : -0.0024781227111816406\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.272796630859375, R2 : -0.002468585968017578\n",
      "[208/500] \n",
      " Train_Loss : 87.03357666417172, R2 : -0.09273832722714073\n",
      "Val_Loss : 60.272796630859375, R2 : -0.002468585968017578\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.272220611572266, R2 : -0.0024590492248535156\n",
      "[209/500] \n",
      " Train_Loss : 87.03175785667018, R2 : -0.0927028405038934\n",
      "Val_Loss : 60.272220611572266, R2 : -0.0024590492248535156\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.271629333496094, R2 : -0.0024491548538208008\n",
      "[210/500] \n",
      " Train_Loss : 87.02989789059288, R2 : -0.09266653813813862\n",
      "Val_Loss : 60.271629333496094, R2 : -0.0024491548538208008\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.271026611328125, R2 : -0.002439141273498535\n",
      "[211/500] \n",
      " Train_Loss : 87.02801282782303, R2 : -0.09262979030609131\n",
      "Val_Loss : 60.271026611328125, R2 : -0.002439141273498535\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.27041244506836, R2 : -0.002428889274597168\n",
      "[212/500] \n",
      " Train_Loss : 87.02608600415681, R2 : -0.09259217663815147\n",
      "Val_Loss : 60.27041244506836, R2 : -0.002428889274597168\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.269798278808594, R2 : -0.0024187564849853516\n",
      "[213/500] \n",
      " Train_Loss : 87.02413318031712, R2 : -0.09255416142313104\n",
      "Val_Loss : 60.269798278808594, R2 : -0.0024187564849853516\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.26915740966797, R2 : -0.0024080276489257812\n",
      "[214/500] \n",
      " Train_Loss : 87.02214351453279, R2 : -0.09251536193646882\n",
      "Val_Loss : 60.26915740966797, R2 : -0.0024080276489257812\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.268524169921875, R2 : -0.0023975372314453125\n",
      "[215/500] \n",
      " Train_Loss : 87.02012001840691, R2 : -0.09247601659674394\n",
      "Val_Loss : 60.268524169921875, R2 : -0.0023975372314453125\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.26786804199219, R2 : -0.0023865699768066406\n",
      "[216/500] \n",
      " Train_Loss : 87.01807754918148, R2 : -0.09243621324238024\n",
      "Val_Loss : 60.26786804199219, R2 : -0.0023865699768066406\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2672119140625, R2 : -0.0023757219314575195\n",
      "[217/500] \n",
      " Train_Loss : 87.015996230276, R2 : -0.09239568208393298\n",
      "Val_Loss : 60.2672119140625, R2 : -0.0023757219314575195\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.26654052734375, R2 : -0.002364516258239746\n",
      "[218/500] \n",
      " Train_Loss : 87.0138853976601, R2 : -0.0923546552658081\n",
      "Val_Loss : 60.26654052734375, R2 : -0.002364516258239746\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.265865325927734, R2 : -0.0023533105850219727\n",
      "[219/500] \n",
      " Train_Loss : 87.01174876564427, R2 : -0.09231307632044743\n",
      "Val_Loss : 60.265865325927734, R2 : -0.0023533105850219727\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.26518630981445, R2 : -0.0023419857025146484\n",
      "[220/500] \n",
      " Train_Loss : 87.00958131489001, R2 : -0.09227092015115838\n",
      "Val_Loss : 60.26518630981445, R2 : -0.0023419857025146484\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.264503479003906, R2 : -0.0023306608200073242\n",
      "[221/500] \n",
      " Train_Loss : 87.00738525390625, R2 : -0.09222826204801861\n",
      "Val_Loss : 60.264503479003906, R2 : -0.0023306608200073242\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.263797760009766, R2 : -0.0023189783096313477\n",
      "[222/500] \n",
      " Train_Loss : 87.00516771015369, R2 : -0.09218511455937435\n",
      "Val_Loss : 60.263797760009766, R2 : -0.0023189783096313477\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.263092041015625, R2 : -0.0023071765899658203\n",
      "[223/500] \n",
      " Train_Loss : 87.0029219577187, R2 : -0.09214150905609131\n",
      "Val_Loss : 60.263092041015625, R2 : -0.0023071765899658203\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.262386322021484, R2 : -0.0022954940795898438\n",
      "[224/500] \n",
      " Train_Loss : 87.0006486993087, R2 : -0.0920973263288799\n",
      "Val_Loss : 60.262386322021484, R2 : -0.0022954940795898438\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.26166915893555, R2 : -0.0022835731506347656\n",
      "[225/500] \n",
      " Train_Loss : 86.99835456045051, R2 : -0.09205271695789538\n",
      "Val_Loss : 60.26166915893555, R2 : -0.0022835731506347656\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.26094055175781, R2 : -0.002271413803100586\n",
      "[226/500] \n",
      " Train_Loss : 86.99602910092003, R2 : -0.09200757428219444\n",
      "Val_Loss : 60.26094055175781, R2 : -0.002271413803100586\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.26021957397461, R2 : -0.002259373664855957\n",
      "[227/500] \n",
      " Train_Loss : 86.9936822590075, R2 : -0.09196200496272038\n",
      "Val_Loss : 60.26021957397461, R2 : -0.002259373664855957\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.25948715209961, R2 : -0.0022472143173217773\n",
      "[228/500] \n",
      " Train_Loss : 86.99131222775108, R2 : -0.09191600272530004\n",
      "Val_Loss : 60.25948715209961, R2 : -0.0022472143173217773\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.25873947143555, R2 : -0.002234816551208496\n",
      "[229/500] \n",
      " Train_Loss : 86.98892061333908, R2 : -0.09186958011827971\n",
      "Val_Loss : 60.25873947143555, R2 : -0.002234816551208496\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.257991790771484, R2 : -0.002222418785095215\n",
      "[230/500] \n",
      " Train_Loss : 86.98650912234658, R2 : -0.09182275596417878\n",
      "Val_Loss : 60.257991790771484, R2 : -0.002222418785095215\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.25724411010742, R2 : -0.0022100210189819336\n",
      "[231/500] \n",
      " Train_Loss : 86.9840656079744, R2 : -0.09177536713449579\n",
      "Val_Loss : 60.25724411010742, R2 : -0.0022100210189819336\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.25648498535156, R2 : -0.0021973848342895508\n",
      "[232/500] \n",
      " Train_Loss : 86.9816020162482, R2 : -0.09172755166103966\n",
      "Val_Loss : 60.25648498535156, R2 : -0.0021973848342895508\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2557258605957, R2 : -0.002184748649597168\n",
      "[233/500] \n",
      " Train_Loss : 86.97911804600766, R2 : -0.09167935346302233\n",
      "Val_Loss : 60.2557258605957, R2 : -0.002184748649597168\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.25496292114258, R2 : -0.0021719932556152344\n",
      "[234/500] \n",
      " Train_Loss : 86.97661409879986, R2 : -0.0916308039113095\n",
      "Val_Loss : 60.25496292114258, R2 : -0.0021719932556152344\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.254188537597656, R2 : -0.00215911865234375\n",
      "[235/500] \n",
      " Train_Loss : 86.97409007423802, R2 : -0.09158188418338173\n",
      "Val_Loss : 60.254188537597656, R2 : -0.00215911865234375\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.25341033935547, R2 : -0.0021462440490722656\n",
      "[236/500] \n",
      " Train_Loss : 86.97153984872918, R2 : -0.09153241232821815\n",
      "Val_Loss : 60.25341033935547, R2 : -0.0021462440490722656\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.252628326416016, R2 : -0.0021331310272216797\n",
      "[237/500] \n",
      " Train_Loss : 86.96897326017681, R2 : -0.09148260794187847\n",
      "Val_Loss : 60.252628326416016, R2 : -0.0021331310272216797\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.25185012817383, R2 : -0.0021202564239501953\n",
      "[238/500] \n",
      " Train_Loss : 86.96638629311009, R2 : -0.09143247102436267\n",
      "Val_Loss : 60.25185012817383, R2 : -0.0021202564239501953\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.251060485839844, R2 : -0.0021071434020996094\n",
      "[239/500] \n",
      " Train_Loss : 86.96377824482165, R2 : -0.09138193255976627\n",
      "Val_Loss : 60.251060485839844, R2 : -0.0021071434020996094\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.250267028808594, R2 : -0.0020939111709594727\n",
      "[240/500] \n",
      " Train_Loss : 86.96114981801887, R2 : -0.09133099882226241\n",
      "Val_Loss : 60.250267028808594, R2 : -0.0020939111709594727\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.24947738647461, R2 : -0.002080678939819336\n",
      "[241/500] \n",
      " Train_Loss : 86.95850392391807, R2 : -0.09127972000523617\n",
      "Val_Loss : 60.24947738647461, R2 : -0.002080678939819336\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.24867248535156, R2 : -0.0020674467086791992\n",
      "[242/500] \n",
      " Train_Loss : 86.95584507992393, R2 : -0.0912281776729383\n",
      "Val_Loss : 60.24867248535156, R2 : -0.0020674467086791992\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.24787139892578, R2 : -0.0020540952682495117\n",
      "[243/500] \n",
      " Train_Loss : 86.95315993459602, R2 : -0.09117612713261654\n",
      "Val_Loss : 60.24787139892578, R2 : -0.0020540952682495117\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2470703125, R2 : -0.0020407438278198242\n",
      "[244/500] \n",
      " Train_Loss : 86.95045190108449, R2 : -0.09112370641607988\n",
      "Val_Loss : 60.2470703125, R2 : -0.0020407438278198242\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.24625778198242, R2 : -0.002027153968811035\n",
      "[245/500] \n",
      " Train_Loss : 86.94773443121659, R2 : -0.09107103473261784\n",
      "Val_Loss : 60.24625778198242, R2 : -0.002027153968811035\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.24544143676758, R2 : -0.002013683319091797\n",
      "[246/500] \n",
      " Train_Loss : 86.94499427393863, R2 : -0.09101799287294086\n",
      "Val_Loss : 60.24544143676758, R2 : -0.002013683319091797\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2446174621582, R2 : -0.001999974250793457\n",
      "[247/500] \n",
      " Train_Loss : 86.94223534433465, R2 : -0.0909645306436639\n",
      "Val_Loss : 60.2446174621582, R2 : -0.001999974250793457\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.24380874633789, R2 : -0.0019865036010742188\n",
      "[248/500] \n",
      " Train_Loss : 86.93945503234863, R2 : -0.0909106919639989\n",
      "Val_Loss : 60.24380874633789, R2 : -0.0019865036010742188\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.242977142333984, R2 : -0.001972675323486328\n",
      "[249/500] \n",
      " Train_Loss : 86.93666187085603, R2 : -0.09085663368827418\n",
      "Val_Loss : 60.242977142333984, R2 : -0.001972675323486328\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.242156982421875, R2 : -0.0019589662551879883\n",
      "[250/500] \n",
      " Train_Loss : 86.93385314941406, R2 : -0.09080224288137335\n",
      "Val_Loss : 60.242156982421875, R2 : -0.0019589662551879883\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2413330078125, R2 : -0.0019452571868896484\n",
      "[251/500] \n",
      " Train_Loss : 86.9310238486842, R2 : -0.09074739405983373\n",
      "Val_Loss : 60.2413330078125, R2 : -0.0019452571868896484\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.240501403808594, R2 : -0.0019314289093017578\n",
      "[252/500] \n",
      " Train_Loss : 86.92817316557232, R2 : -0.0906922879971956\n",
      "Val_Loss : 60.240501403808594, R2 : -0.0019314289093017578\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.23966598510742, R2 : -0.0019176006317138672\n",
      "[253/500] \n",
      " Train_Loss : 86.92531003450092, R2 : -0.09063683058086194\n",
      "Val_Loss : 60.23966598510742, R2 : -0.0019176006317138672\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.23883056640625, R2 : -0.0019036531448364258\n",
      "[254/500] \n",
      " Train_Loss : 86.92242873342414, R2 : -0.09058102181083277\n",
      "Val_Loss : 60.23883056640625, R2 : -0.0019036531448364258\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.23799133300781, R2 : -0.0018897056579589844\n",
      "[255/500] \n",
      " Train_Loss : 86.91952835886102, R2 : -0.0905248993321469\n",
      "Val_Loss : 60.23799133300781, R2 : -0.0018897056579589844\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.23714828491211, R2 : -0.0018756389617919922\n",
      "[256/500] \n",
      " Train_Loss : 86.91661232396176, R2 : -0.09046851333818938\n",
      "Val_Loss : 60.23714828491211, R2 : -0.0018756389617919922\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.236305236816406, R2 : -0.0018616914749145508\n",
      "[257/500] \n",
      " Train_Loss : 86.91368203414113, R2 : -0.09041178226470947\n",
      "Val_Loss : 60.236305236816406, R2 : -0.0018616914749145508\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.23546600341797, R2 : -0.0018477439880371094\n",
      "[258/500] \n",
      " Train_Loss : 86.91073066309879, R2 : -0.09035463709580271\n",
      "Val_Loss : 60.23546600341797, R2 : -0.0018477439880371094\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.234622955322266, R2 : -0.0018336772918701172\n",
      "[259/500] \n",
      " Train_Loss : 86.90775991740979, R2 : -0.0902971907665855\n",
      "Val_Loss : 60.234622955322266, R2 : -0.0018336772918701172\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2337646484375, R2 : -0.0018194913864135742\n",
      "[260/500] \n",
      " Train_Loss : 86.90477782801578, R2 : -0.09023950601878919\n",
      "Val_Loss : 60.2337646484375, R2 : -0.0018194913864135742\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.23291778564453, R2 : -0.0018053054809570312\n",
      "[261/500] \n",
      " Train_Loss : 86.90177455701325, R2 : -0.09018140090139289\n",
      "Val_Loss : 60.23291778564453, R2 : -0.0018053054809570312\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2320671081543, R2 : -0.0017911195755004883\n",
      "[262/500] \n",
      " Train_Loss : 86.89875672992908, R2 : -0.09012297580116674\n",
      "Val_Loss : 60.2320671081543, R2 : -0.0017911195755004883\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.23120880126953, R2 : -0.0017769336700439453\n",
      "[263/500] \n",
      " Train_Loss : 86.89571822317023, R2 : -0.0900642056214182\n",
      "Val_Loss : 60.23120880126953, R2 : -0.0017769336700439453\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.23035430908203, R2 : -0.0017627477645874023\n",
      "[264/500] \n",
      " Train_Loss : 86.89266857347991, R2 : -0.0900052409423025\n",
      "Val_Loss : 60.23035430908203, R2 : -0.0017627477645874023\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2294921875, R2 : -0.0017483234405517578\n",
      "[265/500] \n",
      " Train_Loss : 86.88959834450169, R2 : -0.08994586844193309\n",
      "Val_Loss : 60.2294921875, R2 : -0.0017483234405517578\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.22863006591797, R2 : -0.001734018325805664\n",
      "[266/500] \n",
      " Train_Loss : 86.88651345905505, R2 : -0.08988615086204127\n",
      "Val_Loss : 60.22863006591797, R2 : -0.001734018325805664\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.22777557373047, R2 : -0.001719832420349121\n",
      "[267/500] \n",
      " Train_Loss : 86.88340709083958, R2 : -0.08982610075097335\n",
      "Val_Loss : 60.22777557373047, R2 : -0.001719832420349121\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.226905822753906, R2 : -0.0017054080963134766\n",
      "[268/500] \n",
      " Train_Loss : 86.88028857582493, R2 : -0.08976576202794125\n",
      "Val_Loss : 60.226905822753906, R2 : -0.0017054080963134766\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.226043701171875, R2 : -0.001690983772277832\n",
      "[269/500] \n",
      " Train_Loss : 86.87714787533409, R2 : -0.08970504058034796\n",
      "Val_Loss : 60.226043701171875, R2 : -0.001690983772277832\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.22517776489258, R2 : -0.0016765594482421875\n",
      "[270/500] \n",
      " Train_Loss : 86.8739945261102, R2 : -0.08964407444000244\n",
      "Val_Loss : 60.22517776489258, R2 : -0.0016765594482421875\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.22431564331055, R2 : -0.0016622543334960938\n",
      "[271/500] \n",
      " Train_Loss : 86.870824713456, R2 : -0.08958270675257633\n",
      "Val_Loss : 60.22431564331055, R2 : -0.0016622543334960938\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.22343826293945, R2 : -0.0016477108001708984\n",
      "[272/500] \n",
      " Train_Loss : 86.8676317114579, R2 : -0.08952102535649349\n",
      "Val_Loss : 60.22343826293945, R2 : -0.0016477108001708984\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.222572326660156, R2 : -0.001633286476135254\n",
      "[273/500] \n",
      " Train_Loss : 86.86442646227385, R2 : -0.08945903652592709\n",
      "Val_Loss : 60.222572326660156, R2 : -0.001633286476135254\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.22169876098633, R2 : -0.0016187429428100586\n",
      "[274/500] \n",
      " Train_Loss : 86.86120294269763, R2 : -0.08939676535756964\n",
      "Val_Loss : 60.22169876098633, R2 : -0.0016187429428100586\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.22081756591797, R2 : -0.0016040802001953125\n",
      "[275/500] \n",
      " Train_Loss : 86.85795974731445, R2 : -0.08933402990040026\n",
      "Val_Loss : 60.22081756591797, R2 : -0.0016040802001953125\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.21994400024414, R2 : -0.0015895366668701172\n",
      "[276/500] \n",
      " Train_Loss : 86.85469436645508, R2 : -0.08927092426701595\n",
      "Val_Loss : 60.21994400024414, R2 : -0.0015895366668701172\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.21906280517578, R2 : -0.001574873924255371\n",
      "[277/500] \n",
      " Train_Loss : 86.85141985039962, R2 : -0.08920767432764957\n",
      "Val_Loss : 60.21906280517578, R2 : -0.001574873924255371\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.218196868896484, R2 : -0.0015604496002197266\n",
      "[278/500] \n",
      " Train_Loss : 86.84812555815044, R2 : -0.0891439161802593\n",
      "Val_Loss : 60.218196868896484, R2 : -0.0015604496002197266\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.217308044433594, R2 : -0.0015457868576049805\n",
      "[279/500] \n",
      " Train_Loss : 86.8448102850663, R2 : -0.0890799133401168\n",
      "Val_Loss : 60.217308044433594, R2 : -0.0015457868576049805\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2164306640625, R2 : -0.0015311241149902344\n",
      "[280/500] \n",
      " Train_Loss : 86.84148266440944, R2 : -0.08901557796879818\n",
      "Val_Loss : 60.2164306640625, R2 : -0.0015311241149902344\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.215553283691406, R2 : -0.001516580581665039\n",
      "[281/500] \n",
      " Train_Loss : 86.83813386214406, R2 : -0.08895085987291838\n",
      "Val_Loss : 60.215553283691406, R2 : -0.001516580581665039\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.21466827392578, R2 : -0.0015017986297607422\n",
      "[282/500] \n",
      " Train_Loss : 86.83476427981728, R2 : -0.08888575277830425\n",
      "Val_Loss : 60.21466827392578, R2 : -0.0015017986297607422\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.21379470825195, R2 : -0.0014872550964355469\n",
      "[283/500] \n",
      " Train_Loss : 86.83138074372944, R2 : -0.08882035079755281\n",
      "Val_Loss : 60.21379470825195, R2 : -0.0014872550964355469\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2129020690918, R2 : -0.00147247314453125\n",
      "[284/500] \n",
      " Train_Loss : 86.82797853570236, R2 : -0.0887546225597984\n",
      "Val_Loss : 60.2129020690918, R2 : -0.00147247314453125\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.21202087402344, R2 : -0.001457810401916504\n",
      "[285/500] \n",
      " Train_Loss : 86.82456086811267, R2 : -0.08868858061338726\n",
      "Val_Loss : 60.21202087402344, R2 : -0.001457810401916504\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.21113586425781, R2 : -0.001443028450012207\n",
      "[286/500] \n",
      " Train_Loss : 86.82112071388646, R2 : -0.08862204928147166\n",
      "Val_Loss : 60.21113586425781, R2 : -0.001443028450012207\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.210243225097656, R2 : -0.0014282464981079102\n",
      "[287/500] \n",
      " Train_Loss : 86.81765987998561, R2 : -0.08855527325680382\n",
      "Val_Loss : 60.210243225097656, R2 : -0.0014282464981079102\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.20935821533203, R2 : -0.0014134645462036133\n",
      "[288/500] \n",
      " Train_Loss : 86.81418428922954, R2 : -0.08848810823340165\n",
      "Val_Loss : 60.20935821533203, R2 : -0.0014134645462036133\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.208465576171875, R2 : -0.0013986825942993164\n",
      "[289/500] \n",
      " Train_Loss : 86.81068641261051, R2 : -0.08842053538874577\n",
      "Val_Loss : 60.208465576171875, R2 : -0.0013986825942993164\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.207584381103516, R2 : -0.0013840198516845703\n",
      "[290/500] \n",
      " Train_Loss : 86.80717096830669, R2 : -0.08835266138377942\n",
      "Val_Loss : 60.207584381103516, R2 : -0.0013840198516845703\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.206695556640625, R2 : -0.0013691186904907227\n",
      "[291/500] \n",
      " Train_Loss : 86.80363665129009, R2 : -0.08828435446086683\n",
      "Val_Loss : 60.206695556640625, R2 : -0.0013691186904907227\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.205806732177734, R2 : -0.0013544559478759766\n",
      "[292/500] \n",
      " Train_Loss : 86.80008476658871, R2 : -0.08821579657102886\n",
      "Val_Loss : 60.205806732177734, R2 : -0.0013544559478759766\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.20491409301758, R2 : -0.001339554786682129\n",
      "[293/500] \n",
      " Train_Loss : 86.7965097929302, R2 : -0.08814668027978194\n",
      "Val_Loss : 60.20491409301758, R2 : -0.001339554786682129\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.20402145385742, R2 : -0.001324772834777832\n",
      "[294/500] \n",
      " Train_Loss : 86.79291654887952, R2 : -0.08807738203751414\n",
      "Val_Loss : 60.20402145385742, R2 : -0.001324772834777832\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.2031364440918, R2 : -0.0013099908828735352\n",
      "[295/500] \n",
      " Train_Loss : 86.78930694178531, R2 : -0.08800764460312693\n",
      "Val_Loss : 60.2031364440918, R2 : -0.0013099908828735352\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.202239990234375, R2 : -0.0012950897216796875\n",
      "[296/500] \n",
      " Train_Loss : 86.78567555076198, R2 : -0.08793751817000539\n",
      "Val_Loss : 60.202239990234375, R2 : -0.0012950897216796875\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.201351165771484, R2 : -0.0012803077697753906\n",
      "[297/500] \n",
      " Train_Loss : 86.78203000520405, R2 : -0.08786710312491969\n",
      "Val_Loss : 60.201351165771484, R2 : -0.0012803077697753906\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.200462341308594, R2 : -0.0012655258178710938\n",
      "[298/500] \n",
      " Train_Loss : 86.77835775676526, R2 : -0.08779619242015638\n",
      "Val_Loss : 60.200462341308594, R2 : -0.0012655258178710938\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.19956970214844, R2 : -0.001250624656677246\n",
      "[299/500] \n",
      " Train_Loss : 86.77466733832108, R2 : -0.08772494918421696\n",
      "Val_Loss : 60.19956970214844, R2 : -0.001250624656677246\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.19866943359375, R2 : -0.0012357234954833984\n",
      "[300/500] \n",
      " Train_Loss : 86.77095533672131, R2 : -0.0876532793045044\n",
      "Val_Loss : 60.19866943359375, R2 : -0.0012357234954833984\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.197784423828125, R2 : -0.0012209415435791016\n",
      "[301/500] \n",
      " Train_Loss : 86.76722345854107, R2 : -0.08758123924857691\n",
      "Val_Loss : 60.197784423828125, R2 : -0.0012209415435791016\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.19688415527344, R2 : -0.001206040382385254\n",
      "[302/500] \n",
      " Train_Loss : 86.76347431383635, R2 : -0.08750885411312706\n",
      "Val_Loss : 60.19688415527344, R2 : -0.001206040382385254\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.19599914550781, R2 : -0.001191258430480957\n",
      "[303/500] \n",
      " Train_Loss : 86.75970117669357, R2 : -0.0874360486080772\n",
      "Val_Loss : 60.19599914550781, R2 : -0.001191258430480957\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.195106506347656, R2 : -0.0011764764785766602\n",
      "[304/500] \n",
      " Train_Loss : 86.75591739855315, R2 : -0.08736301723279451\n",
      "Val_Loss : 60.195106506347656, R2 : -0.0011764764785766602\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.194210052490234, R2 : -0.0011615753173828125\n",
      "[305/500] \n",
      " Train_Loss : 86.75209989045796, R2 : -0.08728929569846705\n",
      "Val_Loss : 60.194210052490234, R2 : -0.0011615753173828125\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.19332504272461, R2 : -0.0011467933654785156\n",
      "[306/500] \n",
      " Train_Loss : 86.74826762550755, R2 : -0.08721534829390676\n",
      "Val_Loss : 60.19332504272461, R2 : -0.0011467933654785156\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.19243240356445, R2 : -0.0011320114135742188\n",
      "[307/500] \n",
      " Train_Loss : 86.74441478126927, R2 : -0.08714099934226588\n",
      "Val_Loss : 60.19243240356445, R2 : -0.0011320114135742188\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1915397644043, R2 : -0.001117110252380371\n",
      "[308/500] \n",
      " Train_Loss : 86.74054366663883, R2 : -0.08706630531110261\n",
      "Val_Loss : 60.1915397644043, R2 : -0.001117110252380371\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.190650939941406, R2 : -0.0011023283004760742\n",
      "[309/500] \n",
      " Train_Loss : 86.73664936266448, R2 : -0.08699116581364681\n",
      "Val_Loss : 60.190650939941406, R2 : -0.0011023283004760742\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.18976593017578, R2 : -0.0010876655578613281\n",
      "[310/500] \n",
      " Train_Loss : 86.73273357592132, R2 : -0.08691555575320595\n",
      "Val_Loss : 60.18976593017578, R2 : -0.0010876655578613281\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.18886947631836, R2 : -0.0010726451873779297\n",
      "[311/500] \n",
      " Train_Loss : 86.7287936963533, R2 : -0.08683959433906957\n",
      "Val_Loss : 60.18886947631836, R2 : -0.0010726451873779297\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.18798828125, R2 : -0.0010581016540527344\n",
      "[312/500] \n",
      " Train_Loss : 86.72483745374177, R2 : -0.08676321882950633\n",
      "Val_Loss : 60.18798828125, R2 : -0.0010581016540527344\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.187103271484375, R2 : -0.0010433197021484375\n",
      "[313/500] \n",
      " Train_Loss : 86.72086745814273, R2 : -0.08668664882057592\n",
      "Val_Loss : 60.187103271484375, R2 : -0.0010433197021484375\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.18621063232422, R2 : -0.0010285377502441406\n",
      "[314/500] \n",
      " Train_Loss : 86.71686493723016, R2 : -0.08660938865260075\n",
      "Val_Loss : 60.18621063232422, R2 : -0.0010285377502441406\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.18533706665039, R2 : -0.0010139942169189453\n",
      "[315/500] \n",
      " Train_Loss : 86.71284264012387, R2 : -0.08653190261439274\n",
      "Val_Loss : 60.18533706665039, R2 : -0.0010139942169189453\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.18445587158203, R2 : -0.0009993314743041992\n",
      "[316/500] \n",
      " Train_Loss : 86.708807493511, R2 : -0.08645399620658473\n",
      "Val_Loss : 60.18445587158203, R2 : -0.0009993314743041992\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.183570861816406, R2 : -0.0009845495223999023\n",
      "[317/500] \n",
      " Train_Loss : 86.70474564401727, R2 : -0.08637568825169613\n",
      "Val_Loss : 60.183570861816406, R2 : -0.0009845495223999023\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.182682037353516, R2 : -0.0009698867797851562\n",
      "[318/500] \n",
      " Train_Loss : 86.7006681341874, R2 : -0.08629701012059261\n",
      "Val_Loss : 60.182682037353516, R2 : -0.0009698867797851562\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.18180465698242, R2 : -0.0009552240371704102\n",
      "[319/500] \n",
      " Train_Loss : 86.69656362031635, R2 : -0.08621786770067717\n",
      "Val_Loss : 60.18180465698242, R2 : -0.0009552240371704102\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.180931091308594, R2 : -0.0009406805038452148\n",
      "[320/500] \n",
      " Train_Loss : 86.69244264301501, R2 : -0.08613839274958561\n",
      "Val_Loss : 60.180931091308594, R2 : -0.0009406805038452148\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1800537109375, R2 : -0.0009261369705200195\n",
      "[321/500] \n",
      " Train_Loss : 86.6883006848787, R2 : -0.08605851625141345\n",
      "Val_Loss : 60.1800537109375, R2 : -0.0009261369705200195\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.179176330566406, R2 : -0.0009114742279052734\n",
      "[322/500] \n",
      " Train_Loss : 86.68413834822805, R2 : -0.08597826957702637\n",
      "Val_Loss : 60.179176330566406, R2 : -0.0009114742279052734\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.178306579589844, R2 : -0.0008970499038696289\n",
      "[323/500] \n",
      " Train_Loss : 86.67995422764828, R2 : -0.08589757116217363\n",
      "Val_Loss : 60.178306579589844, R2 : -0.0008970499038696289\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.17744064331055, R2 : -0.0008826255798339844\n",
      "[324/500] \n",
      " Train_Loss : 86.67574972855418, R2 : -0.08581655276449103\n",
      "Val_Loss : 60.17744064331055, R2 : -0.0008826255798339844\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.176578521728516, R2 : -0.0008683204650878906\n",
      "[325/500] \n",
      " Train_Loss : 86.67152535287957, R2 : -0.08573508890051591\n",
      "Val_Loss : 60.176578521728516, R2 : -0.0008683204650878906\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.17570877075195, R2 : -0.0008537769317626953\n",
      "[326/500] \n",
      " Train_Loss : 86.66728160255833, R2 : -0.0856532799570184\n",
      "Val_Loss : 60.17570877075195, R2 : -0.0008537769317626953\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.17484664916992, R2 : -0.0008394718170166016\n",
      "[327/500] \n",
      " Train_Loss : 86.66302289460835, R2 : -0.08557118867572985\n",
      "Val_Loss : 60.17484664916992, R2 : -0.0008394718170166016\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.17399215698242, R2 : -0.0008252859115600586\n",
      "[328/500] \n",
      " Train_Loss : 86.65873517488178, R2 : -0.08548851389633982\n",
      "Val_Loss : 60.17399215698242, R2 : -0.0008252859115600586\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.173133850097656, R2 : -0.0008109807968139648\n",
      "[329/500] \n",
      " Train_Loss : 86.65443661338405, R2 : -0.08540570108514083\n",
      "Val_Loss : 60.173133850097656, R2 : -0.0008109807968139648\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.172279357910156, R2 : -0.0007967948913574219\n",
      "[330/500] \n",
      " Train_Loss : 86.65011295519378, R2 : -0.08532238006591797\n",
      "Val_Loss : 60.172279357910156, R2 : -0.0007967948913574219\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.17142868041992, R2 : -0.0007826089859008789\n",
      "[331/500] \n",
      " Train_Loss : 86.64577644749691, R2 : -0.08523877670890406\n",
      "Val_Loss : 60.17142868041992, R2 : -0.0007826089859008789\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.170589447021484, R2 : -0.0007686614990234375\n",
      "[332/500] \n",
      " Train_Loss : 86.64141584697522, R2 : -0.08515476553063643\n",
      "Val_Loss : 60.170589447021484, R2 : -0.0007686614990234375\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.16974639892578, R2 : -0.0007547140121459961\n",
      "[333/500] \n",
      " Train_Loss : 86.63703496832596, R2 : -0.08507038417615388\n",
      "Val_Loss : 60.16974639892578, R2 : -0.0007547140121459961\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.16890335083008, R2 : -0.0007406473159790039\n",
      "[334/500] \n",
      " Train_Loss : 86.63264204326428, R2 : -0.0849857393063997\n",
      "Val_Loss : 60.16890335083008, R2 : -0.0007406473159790039\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.16807556152344, R2 : -0.0007269382476806641\n",
      "[335/500] \n",
      " Train_Loss : 86.62823195206492, R2 : -0.08490078700216193\n",
      "Val_Loss : 60.16807556152344, R2 : -0.0007269382476806641\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.16724395751953, R2 : -0.0007131099700927734\n",
      "[336/500] \n",
      " Train_Loss : 86.6238014823512, R2 : -0.08481535786076595\n",
      "Val_Loss : 60.16724395751953, R2 : -0.0007131099700927734\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.166412353515625, R2 : -0.0006992816925048828\n",
      "[337/500] \n",
      " Train_Loss : 86.61935404727333, R2 : -0.08472977186504163\n",
      "Val_Loss : 60.166412353515625, R2 : -0.0006992816925048828\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.165592193603516, R2 : -0.000685572624206543\n",
      "[338/500] \n",
      " Train_Loss : 86.61488874335038, R2 : -0.08464372785467851\n",
      "Val_Loss : 60.165592193603516, R2 : -0.000685572624206543\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.16477966308594, R2 : -0.0006721019744873047\n",
      "[339/500] \n",
      " Train_Loss : 86.61041299920333, R2 : -0.08455754581250642\n",
      "Val_Loss : 60.16477966308594, R2 : -0.0006721019744873047\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.16396713256836, R2 : -0.0006585121154785156\n",
      "[340/500] \n",
      " Train_Loss : 86.60591767963611, R2 : -0.08447099986829255\n",
      "Val_Loss : 60.16396713256836, R2 : -0.0006585121154785156\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.16315841674805, R2 : -0.0006450414657592773\n",
      "[341/500] \n",
      " Train_Loss : 86.60140288503547, R2 : -0.08438410257038317\n",
      "Val_Loss : 60.16315841674805, R2 : -0.0006450414657592773\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.16236114501953, R2 : -0.0006318092346191406\n",
      "[342/500] \n",
      " Train_Loss : 86.59688447651111, R2 : -0.08429705469231856\n",
      "Val_Loss : 60.16236114501953, R2 : -0.0006318092346191406\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.16156005859375, R2 : -0.0006184577941894531\n",
      "[343/500] \n",
      " Train_Loss : 86.5923446856047, R2 : -0.08420964918638531\n",
      "Val_Loss : 60.16156005859375, R2 : -0.0006184577941894531\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.160770416259766, R2 : -0.0006053447723388672\n",
      "[344/500] \n",
      " Train_Loss : 86.58778863204152, R2 : -0.084121961342661\n",
      "Val_Loss : 60.160770416259766, R2 : -0.0006053447723388672\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.15998840332031, R2 : -0.000592350959777832\n",
      "[345/500] \n",
      " Train_Loss : 86.58322595295154, R2 : -0.08403416056382029\n",
      "Val_Loss : 60.15998840332031, R2 : -0.000592350959777832\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.159210205078125, R2 : -0.0005793571472167969\n",
      "[346/500] \n",
      " Train_Loss : 86.57865494175961, R2 : -0.08394617783395868\n",
      "Val_Loss : 60.159210205078125, R2 : -0.0005793571472167969\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.15843963623047, R2 : -0.0005666017532348633\n",
      "[347/500] \n",
      " Train_Loss : 86.57406706559031, R2 : -0.08385784375040155\n",
      "Val_Loss : 60.15843963623047, R2 : -0.0005666017532348633\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.15767288208008, R2 : -0.0005538463592529297\n",
      "[348/500] \n",
      " Train_Loss : 86.5694714596397, R2 : -0.08376942182842054\n",
      "Val_Loss : 60.15767288208008, R2 : -0.0005538463592529297\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.15690612792969, R2 : -0.0005410909652709961\n",
      "[349/500] \n",
      " Train_Loss : 86.56486450998406, R2 : -0.08368076776203356\n",
      "Val_Loss : 60.15690612792969, R2 : -0.0005410909652709961\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.15615463256836, R2 : -0.0005285739898681641\n",
      "[350/500] \n",
      " Train_Loss : 86.56024701971756, R2 : -0.08359193174462569\n",
      "Val_Loss : 60.15615463256836, R2 : -0.0005285739898681641\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.15541076660156, R2 : -0.0005162954330444336\n",
      "[351/500] \n",
      " Train_Loss : 86.55562400817871, R2 : -0.08350299534044768\n",
      "Val_Loss : 60.15541076660156, R2 : -0.0005162954330444336\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1546630859375, R2 : -0.0005037784576416016\n",
      "[352/500] \n",
      " Train_Loss : 86.55099045602898, R2 : -0.08341385816272937\n",
      "Val_Loss : 60.1546630859375, R2 : -0.0005037784576416016\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1539421081543, R2 : -0.0004917383193969727\n",
      "[353/500] \n",
      " Train_Loss : 86.5463533903423, R2 : -0.08332470843666478\n",
      "Val_Loss : 60.1539421081543, R2 : -0.0004917383193969727\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.15321731567383, R2 : -0.00047969818115234375\n",
      "[354/500] \n",
      " Train_Loss : 86.541714417307, R2 : -0.08323542695296438\n",
      "Val_Loss : 60.15321731567383, R2 : -0.00047969818115234375\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.15250015258789, R2 : -0.0004677772521972656\n",
      "[355/500] \n",
      " Train_Loss : 86.53706711216977, R2 : -0.08314612664674458\n",
      "Val_Loss : 60.15250015258789, R2 : -0.0004677772521972656\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.15179443359375, R2 : -0.00045609474182128906\n",
      "[356/500] \n",
      " Train_Loss : 86.53241749813682, R2 : -0.08305663184115761\n",
      "Val_Loss : 60.15179443359375, R2 : -0.00045609474182128906\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.15109634399414, R2 : -0.0004444122314453125\n",
      "[357/500] \n",
      " Train_Loss : 86.52776698062294, R2 : -0.08296728761572587\n",
      "Val_Loss : 60.15109634399414, R2 : -0.0004444122314453125\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1504020690918, R2 : -0.0004329681396484375\n",
      "[358/500] \n",
      " Train_Loss : 86.52310803062038, R2 : -0.08287771124588816\n",
      "Val_Loss : 60.1504020690918, R2 : -0.0004329681396484375\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.149723052978516, R2 : -0.0004216432571411133\n",
      "[359/500] \n",
      " Train_Loss : 86.51846213089793, R2 : -0.08278840466549522\n",
      "Val_Loss : 60.149723052978516, R2 : -0.0004216432571411133\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.149051666259766, R2 : -0.00041043758392333984\n",
      "[360/500] \n",
      " Train_Loss : 86.51381372150622, R2 : -0.08269908553675602\n",
      "Val_Loss : 60.149051666259766, R2 : -0.00041043758392333984\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.14838409423828, R2 : -0.0003993511199951172\n",
      "[361/500] \n",
      " Train_Loss : 86.50916280244526, R2 : -0.08260970366628546\n",
      "Val_Loss : 60.14838409423828, R2 : -0.0003993511199951172\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.14773941040039, R2 : -0.0003886222839355469\n",
      "[362/500] \n",
      " Train_Loss : 86.50451810736405, R2 : -0.08252042218258507\n",
      "Val_Loss : 60.14773941040039, R2 : -0.0003886222839355469\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.14707946777344, R2 : -0.000377655029296875\n",
      "[363/500] \n",
      " Train_Loss : 86.49988204554508, R2 : -0.08243136029494436\n",
      "Val_Loss : 60.14707946777344, R2 : -0.000377655029296875\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.146453857421875, R2 : -0.00036728382110595703\n",
      "[364/500] \n",
      " Train_Loss : 86.495244277151, R2 : -0.08234224821391858\n",
      "Val_Loss : 60.146453857421875, R2 : -0.00036728382110595703\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.145816802978516, R2 : -0.0003566741943359375\n",
      "[365/500] \n",
      " Train_Loss : 86.49062216909309, R2 : -0.08225350630910773\n",
      "Val_Loss : 60.145816802978516, R2 : -0.0003566741943359375\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.145198822021484, R2 : -0.0003464221954345703\n",
      "[366/500] \n",
      " Train_Loss : 86.48601080241956, R2 : -0.08216487106524016\n",
      "Val_Loss : 60.145198822021484, R2 : -0.0003464221954345703\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.14460372924805, R2 : -0.00033652782440185547\n",
      "[367/500] \n",
      " Train_Loss : 86.4814039531507, R2 : -0.08207644914325915\n",
      "Val_Loss : 60.14460372924805, R2 : -0.00033652782440185547\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.14400100708008, R2 : -0.00032639503479003906\n",
      "[368/500] \n",
      " Train_Loss : 86.47681406924599, R2 : -0.08198830328489605\n",
      "Val_Loss : 60.14400100708008, R2 : -0.00032639503479003906\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1434211730957, R2 : -0.00031685829162597656\n",
      "[369/500] \n",
      " Train_Loss : 86.4722382394891, R2 : -0.08190045231267025\n",
      "Val_Loss : 60.1434211730957, R2 : -0.00031685829162597656\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.14285659790039, R2 : -0.00030744075775146484\n",
      "[370/500] \n",
      " Train_Loss : 86.46767666465358, R2 : -0.08181287112988923\n",
      "Val_Loss : 60.14285659790039, R2 : -0.00030744075775146484\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.142276763916016, R2 : -0.00029778480529785156\n",
      "[371/500] \n",
      " Train_Loss : 86.46313014783357, R2 : -0.0817256162041112\n",
      "Val_Loss : 60.142276763916016, R2 : -0.00029778480529785156\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1417350769043, R2 : -0.0002887248992919922\n",
      "[372/500] \n",
      " Train_Loss : 86.45861123737537, R2 : -0.08163888830887644\n",
      "Val_Loss : 60.1417350769043, R2 : -0.0002887248992919922\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.14119338989258, R2 : -0.0002797842025756836\n",
      "[373/500] \n",
      " Train_Loss : 86.45410587913112, R2 : -0.08155245529977899\n",
      "Val_Loss : 60.14119338989258, R2 : -0.0002797842025756836\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.140655517578125, R2 : -0.000270843505859375\n",
      "[374/500] \n",
      " Train_Loss : 86.44962310791016, R2 : -0.08146646775697407\n",
      "Val_Loss : 60.140655517578125, R2 : -0.000270843505859375\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.14013671875, R2 : -0.00026214122772216797\n",
      "[375/500] \n",
      " Train_Loss : 86.44516563415527, R2 : -0.08138090058376915\n",
      "Val_Loss : 60.14013671875, R2 : -0.00026214122772216797\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.139617919921875, R2 : -0.0002535581588745117\n",
      "[376/500] \n",
      " Train_Loss : 86.44073375902678, R2 : -0.0812958604411075\n",
      "Val_Loss : 60.139617919921875, R2 : -0.0002535581588745117\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.139129638671875, R2 : -0.0002454519271850586\n",
      "[377/500] \n",
      " Train_Loss : 86.43632567556281, R2 : -0.08121134105481599\n",
      "Val_Loss : 60.139129638671875, R2 : -0.0002454519271850586\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13863754272461, R2 : -0.0002372264862060547\n",
      "[378/500] \n",
      " Train_Loss : 86.4319480092902, R2 : -0.08112739889245284\n",
      "Val_Loss : 60.13863754272461, R2 : -0.0002372264862060547\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.138160705566406, R2 : -0.00022923946380615234\n",
      "[379/500] \n",
      " Train_Loss : 86.4276025671708, R2 : -0.08104409669574938\n",
      "Val_Loss : 60.138160705566406, R2 : -0.00022923946380615234\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13770294189453, R2 : -0.00022172927856445312\n",
      "[380/500] \n",
      " Train_Loss : 86.42329336467542, R2 : -0.08096144701305188\n",
      "Val_Loss : 60.13770294189453, R2 : -0.00022172927856445312\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13724136352539, R2 : -0.00021409988403320312\n",
      "[381/500] \n",
      " Train_Loss : 86.41900694997688, R2 : -0.08087924279664692\n",
      "Val_Loss : 60.13724136352539, R2 : -0.00021409988403320312\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.136802673339844, R2 : -0.0002067089080810547\n",
      "[382/500] \n",
      " Train_Loss : 86.41476651241905, R2 : -0.08079805499628971\n",
      "Val_Loss : 60.136802673339844, R2 : -0.0002067089080810547\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.136375427246094, R2 : -0.0001996755599975586\n",
      "[383/500] \n",
      " Train_Loss : 86.41055699398643, R2 : -0.08071729383970562\n",
      "Val_Loss : 60.136375427246094, R2 : -0.0001996755599975586\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13595962524414, R2 : -0.00019276142120361328\n",
      "[384/500] \n",
      " Train_Loss : 86.40639465733578, R2 : -0.08063756164751555\n",
      "Val_Loss : 60.13595962524414, R2 : -0.00019276142120361328\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13554763793945, R2 : -0.00018584728240966797\n",
      "[385/500] \n",
      " Train_Loss : 86.40226685373406, R2 : -0.08055844432429264\n",
      "Val_Loss : 60.13554763793945, R2 : -0.00018584728240966797\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13515853881836, R2 : -0.00017940998077392578\n",
      "[386/500] \n",
      " Train_Loss : 86.3981826179906, R2 : -0.0804802555786936\n",
      "Val_Loss : 60.13515853881836, R2 : -0.00017940998077392578\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13477325439453, R2 : -0.0001729726791381836\n",
      "[387/500] \n",
      " Train_Loss : 86.39414937872635, R2 : -0.0804029012981214\n",
      "Val_Loss : 60.13477325439453, R2 : -0.0001729726791381836\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13439178466797, R2 : -0.0001666545867919922\n",
      "[388/500] \n",
      " Train_Loss : 86.39015057212428, R2 : -0.08032632501501787\n",
      "Val_Loss : 60.13439178466797, R2 : -0.0001666545867919922\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.134037017822266, R2 : -0.00016069412231445312\n",
      "[389/500] \n",
      " Train_Loss : 86.3862062755384, R2 : -0.08025078397048147\n",
      "Val_Loss : 60.134037017822266, R2 : -0.00016069412231445312\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13368225097656, R2 : -0.00015485286712646484\n",
      "[390/500] \n",
      " Train_Loss : 86.3823087591874, R2 : -0.08017609621349134\n",
      "Val_Loss : 60.13368225097656, R2 : -0.00015485286712646484\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13334274291992, R2 : -0.00014913082122802734\n",
      "[391/500] \n",
      " Train_Loss : 86.3784576215242, R2 : -0.08010232448577881\n",
      "Val_Loss : 60.13334274291992, R2 : -0.00014913082122802734\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.132999420166016, R2 : -0.00014352798461914062\n",
      "[392/500] \n",
      " Train_Loss : 86.37465928730212, R2 : -0.08002961309332597\n",
      "Val_Loss : 60.132999420166016, R2 : -0.00014352798461914062\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1326904296875, R2 : -0.00013840198516845703\n",
      "[393/500] \n",
      " Train_Loss : 86.37091827392578, R2 : -0.07995793693944027\n",
      "Val_Loss : 60.1326904296875, R2 : -0.00013840198516845703\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13237762451172, R2 : -0.00013315677642822266\n",
      "[394/500] \n",
      " Train_Loss : 86.36722062763415, R2 : -0.07988719563735158\n",
      "Val_Loss : 60.13237762451172, R2 : -0.00013315677642822266\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.132083892822266, R2 : -0.00012826919555664062\n",
      "[395/500] \n",
      " Train_Loss : 86.36358662655479, R2 : -0.07981756486390766\n",
      "Val_Loss : 60.132083892822266, R2 : -0.00012826919555664062\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13178634643555, R2 : -0.0001232624053955078\n",
      "[396/500] \n",
      " Train_Loss : 86.36000362195466, R2 : -0.07974894423233836\n",
      "Val_Loss : 60.13178634643555, R2 : -0.0001232624053955078\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13151168823242, R2 : -0.00011873245239257812\n",
      "[397/500] \n",
      " Train_Loss : 86.35648054825633, R2 : -0.07968149059697201\n",
      "Val_Loss : 60.13151168823242, R2 : -0.00011873245239257812\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13124465942383, R2 : -0.00011432170867919922\n",
      "[398/500] \n",
      " Train_Loss : 86.35301369114926, R2 : -0.07961515376442357\n",
      "Val_Loss : 60.13124465942383, R2 : -0.00011432170867919922\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1309928894043, R2 : -0.0001100301742553711\n",
      "[399/500] \n",
      " Train_Loss : 86.34960315102025, R2 : -0.07954978942871094\n",
      "Val_Loss : 60.1309928894043, R2 : -0.0001100301742553711\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.130733489990234, R2 : -0.00010573863983154297\n",
      "[400/500] \n",
      " Train_Loss : 86.34624561510589, R2 : -0.0794855042507774\n",
      "Val_Loss : 60.130733489990234, R2 : -0.00010573863983154297\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.130496978759766, R2 : -0.00010192394256591797\n",
      "[401/500] \n",
      " Train_Loss : 86.34295865109092, R2 : -0.07942254292337518\n",
      "Val_Loss : 60.130496978759766, R2 : -0.00010192394256591797\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13026428222656, R2 : -9.799003601074219e-05\n",
      "[402/500] \n",
      " Train_Loss : 86.33972218162135, R2 : -0.07936058546367444\n",
      "Val_Loss : 60.13026428222656, R2 : -9.799003601074219e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.13003921508789, R2 : -9.429454803466797e-05\n",
      "[403/500] \n",
      " Train_Loss : 86.33655026084499, R2 : -0.07929982009686921\n",
      "Val_Loss : 60.13003921508789, R2 : -9.429454803466797e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12982940673828, R2 : -9.071826934814453e-05\n",
      "[404/500] \n",
      " Train_Loss : 86.33343515898052, R2 : -0.07924012761366994\n",
      "Val_Loss : 60.12982940673828, R2 : -9.071826934814453e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12962341308594, R2 : -8.738040924072266e-05\n",
      "[405/500] \n",
      " Train_Loss : 86.33038119265908, R2 : -0.07918162094919305\n",
      "Val_Loss : 60.12962341308594, R2 : -8.738040924072266e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.129417419433594, R2 : -8.392333984375e-05\n",
      "[406/500] \n",
      " Train_Loss : 86.32738565143787, R2 : -0.07912420599084151\n",
      "Val_Loss : 60.129417419433594, R2 : -8.392333984375e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12923049926758, R2 : -8.082389831542969e-05\n",
      "[407/500] \n",
      " Train_Loss : 86.32444833454333, R2 : -0.07906792665782728\n",
      "Val_Loss : 60.12923049926758, R2 : -8.082389831542969e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.129051208496094, R2 : -7.784366607666016e-05\n",
      "[408/500] \n",
      " Train_Loss : 86.32157044661672, R2 : -0.07901275785345781\n",
      "Val_Loss : 60.129051208496094, R2 : -7.784366607666016e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12887191772461, R2 : -7.474422454833984e-05\n",
      "[409/500] \n",
      " Train_Loss : 86.31874907644172, R2 : -0.07895864938434802\n",
      "Val_Loss : 60.12887191772461, R2 : -7.474422454833984e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12870788574219, R2 : -7.212162017822266e-05\n",
      "[410/500] \n",
      " Train_Loss : 86.31598552904632, R2 : -0.07890566399222926\n",
      "Val_Loss : 60.12870788574219, R2 : -7.212162017822266e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.128543853759766, R2 : -6.937980651855469e-05\n",
      "[411/500] \n",
      " Train_Loss : 86.31328131023206, R2 : -0.078853776580409\n",
      "Val_Loss : 60.128543853759766, R2 : -6.937980651855469e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.128387451171875, R2 : -6.67572021484375e-05\n",
      "[412/500] \n",
      " Train_Loss : 86.31062778673675, R2 : -0.07880286166542455\n",
      "Val_Loss : 60.128387451171875, R2 : -6.67572021484375e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12824249267578, R2 : -6.437301635742188e-05\n",
      "[413/500] \n",
      " Train_Loss : 86.30803198563426, R2 : -0.07875300081152665\n",
      "Val_Loss : 60.12824249267578, R2 : -6.437301635742188e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12809753417969, R2 : -6.198883056640625e-05\n",
      "[414/500] \n",
      " Train_Loss : 86.30548698023746, R2 : -0.0787041187286377\n",
      "Val_Loss : 60.12809753417969, R2 : -6.198883056640625e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.127960205078125, R2 : -5.9604644775390625e-05\n",
      "[415/500] \n",
      " Train_Loss : 86.30299708717747, R2 : -0.07865633462604724\n",
      "Val_Loss : 60.127960205078125, R2 : -5.9604644775390625e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12782669067383, R2 : -5.745887756347656e-05\n",
      "[416/500] \n",
      " Train_Loss : 86.30055738750256, R2 : -0.0786094163593493\n",
      "Val_Loss : 60.12782669067383, R2 : -5.745887756347656e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12770080566406, R2 : -5.53131103515625e-05\n",
      "[417/500] \n",
      " Train_Loss : 86.29816507038318, R2 : -0.07856344549279463\n",
      "Val_Loss : 60.12770080566406, R2 : -5.53131103515625e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.127567291259766, R2 : -5.316734313964844e-05\n",
      "[418/500] \n",
      " Train_Loss : 86.29582455283717, R2 : -0.07851838438134444\n",
      "Val_Loss : 60.127567291259766, R2 : -5.316734313964844e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.127464294433594, R2 : -5.137920379638672e-05\n",
      "[419/500] \n",
      " Train_Loss : 86.29352639850818, R2 : -0.07847419537995991\n",
      "Val_Loss : 60.127464294433594, R2 : -5.137920379638672e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.127349853515625, R2 : -4.947185516357422e-05\n",
      "[420/500] \n",
      " Train_Loss : 86.2912782367907, R2 : -0.0784308722144679\n",
      "Val_Loss : 60.127349853515625, R2 : -4.947185516357422e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12724304199219, R2 : -4.76837158203125e-05\n",
      "[421/500] \n",
      " Train_Loss : 86.2890689247533, R2 : -0.07838833959479082\n",
      "Val_Loss : 60.12724304199219, R2 : -4.76837158203125e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.127132415771484, R2 : -4.589557647705078e-05\n",
      "[422/500] \n",
      " Train_Loss : 86.28690177515934, R2 : -0.07834656615006297\n",
      "Val_Loss : 60.127132415771484, R2 : -4.589557647705078e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12703323364258, R2 : -4.4226646423339844e-05\n",
      "[423/500] \n",
      " Train_Loss : 86.28476925900108, R2 : -0.07830547031603362\n",
      "Val_Loss : 60.12703323364258, R2 : -4.4226646423339844e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12693405151367, R2 : -4.2557716369628906e-05\n",
      "[424/500] \n",
      " Train_Loss : 86.28268131456878, R2 : -0.07826510228608784\n",
      "Val_Loss : 60.12693405151367, R2 : -4.2557716369628906e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12684631347656, R2 : -4.112720489501953e-05\n",
      "[425/500] \n",
      " Train_Loss : 86.28062579506322, R2 : -0.0782254746085719\n",
      "Val_Loss : 60.12684631347656, R2 : -4.112720489501953e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.126747131347656, R2 : -3.9458274841308594e-05\n",
      "[426/500] \n",
      " Train_Loss : 86.27860330280505, R2 : -0.07818639278411865\n",
      "Val_Loss : 60.126747131347656, R2 : -3.9458274841308594e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.126670837402344, R2 : -3.814697265625e-05\n",
      "[427/500] \n",
      " Train_Loss : 86.2766160463032, R2 : -0.0781479885703639\n",
      "Val_Loss : 60.126670837402344, R2 : -3.814697265625e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12657928466797, R2 : -3.6716461181640625e-05\n",
      "[428/500] \n",
      " Train_Loss : 86.27465589422928, R2 : -0.07811008001628675\n",
      "Val_Loss : 60.12657928466797, R2 : -3.6716461181640625e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12650680541992, R2 : -3.552436828613281e-05\n",
      "[429/500] \n",
      " Train_Loss : 86.27272987365723, R2 : -0.07807278633117676\n",
      "Val_Loss : 60.12650680541992, R2 : -3.552436828613281e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12642288208008, R2 : -3.409385681152344e-05\n",
      "[430/500] \n",
      " Train_Loss : 86.27082242463764, R2 : -0.07803586909645482\n",
      "Val_Loss : 60.12642288208008, R2 : -3.409385681152344e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1263427734375, R2 : -3.2782554626464844e-05\n",
      "[431/500] \n",
      " Train_Loss : 86.26894388700786, R2 : -0.07799945379558362\n",
      "Val_Loss : 60.1263427734375, R2 : -3.2782554626464844e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.126277923583984, R2 : -3.170967102050781e-05\n",
      "[432/500] \n",
      " Train_Loss : 86.26708522595857, R2 : -0.07796342749344676\n",
      "Val_Loss : 60.126277923583984, R2 : -3.170967102050781e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.126197814941406, R2 : -3.039836883544922e-05\n",
      "[433/500] \n",
      " Train_Loss : 86.26525115966797, R2 : -0.07792784665760241\n",
      "Val_Loss : 60.126197814941406, R2 : -3.039836883544922e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12613296508789, R2 : -2.9325485229492188e-05\n",
      "[434/500] \n",
      " Train_Loss : 86.26343897769326, R2 : -0.0778927112880506\n",
      "Val_Loss : 60.12613296508789, R2 : -2.9325485229492188e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.126060485839844, R2 : -2.8014183044433594e-05\n",
      "[435/500] \n",
      " Train_Loss : 86.26164145218699, R2 : -0.07785782061125103\n",
      "Val_Loss : 60.126060485839844, R2 : -2.8014183044433594e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.125999450683594, R2 : -2.7060508728027344e-05\n",
      "[436/500] \n",
      " Train_Loss : 86.25986039011102, R2 : -0.07782326246562757\n",
      "Val_Loss : 60.125999450683594, R2 : -2.7060508728027344e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12593460083008, R2 : -2.5987625122070312e-05\n",
      "[437/500] \n",
      " Train_Loss : 86.2580962933992, R2 : -0.07778894901275635\n",
      "Val_Loss : 60.12593460083008, R2 : -2.5987625122070312e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12588119506836, R2 : -2.5033950805664062e-05\n",
      "[438/500] \n",
      " Train_Loss : 86.25634645160876, R2 : -0.07775495554271497\n",
      "Val_Loss : 60.12588119506836, R2 : -2.5033950805664062e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12582015991211, R2 : -2.4080276489257812e-05\n",
      "[439/500] \n",
      " Train_Loss : 86.25460885700427, R2 : -0.07772112520117509\n",
      "Val_Loss : 60.12582015991211, R2 : -2.4080276489257812e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.125755310058594, R2 : -2.300739288330078e-05\n",
      "[440/500] \n",
      " Train_Loss : 86.25288330881219, R2 : -0.07768756464907997\n",
      "Val_Loss : 60.125755310058594, R2 : -2.300739288330078e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12569808959961, R2 : -2.205371856689453e-05\n",
      "[441/500] \n",
      " Train_Loss : 86.25116659465588, R2 : -0.07765417349965949\n",
      "Val_Loss : 60.12569808959961, R2 : -2.205371856689453e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12565231323242, R2 : -2.1219253540039062e-05\n",
      "[442/500] \n",
      " Train_Loss : 86.24946162575169, R2 : -0.07762093920456736\n",
      "Val_Loss : 60.12565231323242, R2 : -2.1219253540039062e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12559509277344, R2 : -2.0384788513183594e-05\n",
      "[443/500] \n",
      " Train_Loss : 86.24775996961091, R2 : -0.07758783666711104\n",
      "Val_Loss : 60.12559509277344, R2 : -2.0384788513183594e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12554168701172, R2 : -1.9431114196777344e-05\n",
      "[444/500] \n",
      " Train_Loss : 86.2460705606561, R2 : -0.07755487216146369\n",
      "Val_Loss : 60.12554168701172, R2 : -1.9431114196777344e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12549591064453, R2 : -1.8596649169921875e-05\n",
      "[445/500] \n",
      " Train_Loss : 86.24438888148258, R2 : -0.07752210215518349\n",
      "Val_Loss : 60.12549591064453, R2 : -1.8596649169921875e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12544631958008, R2 : -1.7881393432617188e-05\n",
      "[446/500] \n",
      " Train_Loss : 86.2427046926398, R2 : -0.0774893133263839\n",
      "Val_Loss : 60.12544631958008, R2 : -1.7881393432617188e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12539291381836, R2 : -1.6927719116210938e-05\n",
      "[447/500] \n",
      " Train_Loss : 86.24103315253006, R2 : -0.07745676919033653\n",
      "Val_Loss : 60.12539291381836, R2 : -1.6927719116210938e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.125343322753906, R2 : -1.609325408935547e-05\n",
      "[448/500] \n",
      " Train_Loss : 86.23936753523977, R2 : -0.0774242313284623\n",
      "Val_Loss : 60.125343322753906, R2 : -1.609325408935547e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.125301361083984, R2 : -1.5497207641601562e-05\n",
      "[449/500] \n",
      " Train_Loss : 86.23769760131836, R2 : -0.0773916809182418\n",
      "Val_Loss : 60.125301361083984, R2 : -1.5497207641601562e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12525177001953, R2 : -1.4662742614746094e-05\n",
      "[450/500] \n",
      " Train_Loss : 86.23603519640471, R2 : -0.07735923716896459\n",
      "Val_Loss : 60.12525177001953, R2 : -1.4662742614746094e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12521743774414, R2 : -1.4066696166992188e-05\n",
      "[451/500] \n",
      " Train_Loss : 86.23438082243267, R2 : -0.07732693145149633\n",
      "Val_Loss : 60.12521743774414, R2 : -1.4066696166992188e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12516784667969, R2 : -1.3232231140136719e-05\n",
      "[452/500] \n",
      " Train_Loss : 86.23272273415013, R2 : -0.0772945943631624\n",
      "Val_Loss : 60.12516784667969, R2 : -1.3232231140136719e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1251335144043, R2 : -1.2636184692382812e-05\n",
      "[453/500] \n",
      " Train_Loss : 86.23107117100766, R2 : -0.07726237020994488\n",
      "Val_Loss : 60.1251335144043, R2 : -1.2636184692382812e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.125091552734375, R2 : -1.1920928955078125e-05\n",
      "[454/500] \n",
      " Train_Loss : 86.22941629510177, R2 : -0.07723004566995721\n",
      "Val_Loss : 60.125091552734375, R2 : -1.1920928955078125e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12506103515625, R2 : -1.1444091796875e-05\n",
      "[455/500] \n",
      " Train_Loss : 86.22776352731805, R2 : -0.07719778387170088\n",
      "Val_Loss : 60.12506103515625, R2 : -1.1444091796875e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1250114440918, R2 : -1.0609626770019531e-05\n",
      "[456/500] \n",
      " Train_Loss : 86.22611487539191, R2 : -0.07716560991186845\n",
      "Val_Loss : 60.1250114440918, R2 : -1.0609626770019531e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.124977111816406, R2 : -1.0013580322265625e-05\n",
      "[457/500] \n",
      " Train_Loss : 86.22446361340974, R2 : -0.07713335438778526\n",
      "Val_Loss : 60.124977111816406, R2 : -1.0013580322265625e-05\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12493896484375, R2 : -9.417533874511719e-06\n",
      "[458/500] \n",
      " Train_Loss : 86.22281275297466, R2 : -0.0771011051378752\n",
      "Val_Loss : 60.12493896484375, R2 : -9.417533874511719e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12490463256836, R2 : -8.821487426757812e-06\n",
      "[459/500] \n",
      " Train_Loss : 86.22116610878392, R2 : -0.07706898764560097\n",
      "Val_Loss : 60.12490463256836, R2 : -8.821487426757812e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.124874114990234, R2 : -8.344650268554688e-06\n",
      "[460/500] \n",
      " Train_Loss : 86.21952137194182, R2 : -0.07703679486324913\n",
      "Val_Loss : 60.124874114990234, R2 : -8.344650268554688e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12483596801758, R2 : -7.748603820800781e-06\n",
      "[461/500] \n",
      " Train_Loss : 86.21787241885536, R2 : -0.07700460835507042\n",
      "Val_Loss : 60.12483596801758, R2 : -7.748603820800781e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12480545043945, R2 : -7.271766662597656e-06\n",
      "[462/500] \n",
      " Train_Loss : 86.21622507195724, R2 : -0.07697241557271857\n",
      "Val_Loss : 60.12480545043945, R2 : -7.271766662597656e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12478256225586, R2 : -6.794929504394531e-06\n",
      "[463/500] \n",
      " Train_Loss : 86.21457330804122, R2 : -0.07694015377446224\n",
      "Val_Loss : 60.12478256225586, R2 : -6.794929504394531e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12474822998047, R2 : -6.198883056640625e-06\n",
      "[464/500] \n",
      " Train_Loss : 86.21292837042557, R2 : -0.07690802373384174\n",
      "Val_Loss : 60.12474822998047, R2 : -6.198883056640625e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12472915649414, R2 : -5.9604644775390625e-06\n",
      "[465/500] \n",
      " Train_Loss : 86.21127650612279, R2 : -0.07687576193558543\n",
      "Val_Loss : 60.12472915649414, R2 : -5.9604644775390625e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.124698638916016, R2 : -5.364418029785156e-06\n",
      "[466/500] \n",
      " Train_Loss : 86.20962966115852, R2 : -0.07684353150819477\n",
      "Val_Loss : 60.124698638916016, R2 : -5.364418029785156e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12466812133789, R2 : -4.887580871582031e-06\n",
      "[467/500] \n",
      " Train_Loss : 86.20797739530865, R2 : -0.07681127598411158\n",
      "Val_Loss : 60.12466812133789, R2 : -4.887580871582031e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1246452331543, R2 : -4.5299530029296875e-06\n",
      "[468/500] \n",
      " Train_Loss : 86.20633085150467, R2 : -0.07677912712097168\n",
      "Val_Loss : 60.1246452331543, R2 : -4.5299530029296875e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12461853027344, R2 : -4.0531158447265625e-06\n",
      "[469/500] \n",
      " Train_Loss : 86.2046782844945, R2 : -0.07674677121011834\n",
      "Val_Loss : 60.12461853027344, R2 : -4.0531158447265625e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.124603271484375, R2 : -3.814697265625e-06\n",
      "[470/500] \n",
      " Train_Loss : 86.20301969427811, R2 : -0.07671442157343815\n",
      "Val_Loss : 60.124603271484375, R2 : -3.814697265625e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.124576568603516, R2 : -3.4570693969726562e-06\n",
      "[471/500] \n",
      " Train_Loss : 86.20137345163445, R2 : -0.07668221624274003\n",
      "Val_Loss : 60.124576568603516, R2 : -3.4570693969726562e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12455368041992, R2 : -2.9802322387695312e-06\n",
      "[472/500] \n",
      " Train_Loss : 86.19971706992702, R2 : -0.07664983523519416\n",
      "Val_Loss : 60.12455368041992, R2 : -2.9802322387695312e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.124534606933594, R2 : -2.7418136596679688e-06\n",
      "[473/500] \n",
      " Train_Loss : 86.1980683176141, R2 : -0.07661759853363037\n",
      "Val_Loss : 60.124534606933594, R2 : -2.7418136596679688e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12451934814453, R2 : -2.384185791015625e-06\n",
      "[474/500] \n",
      " Train_Loss : 86.19640982778449, R2 : -0.0765851987035651\n",
      "Val_Loss : 60.12451934814453, R2 : -2.384185791015625e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12450408935547, R2 : -2.2649765014648438e-06\n",
      "[475/500] \n",
      " Train_Loss : 86.19475444994475, R2 : -0.07655279259932668\n",
      "Val_Loss : 60.12450408935547, R2 : -2.2649765014648438e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.124488830566406, R2 : -1.9073486328125e-06\n",
      "[476/500] \n",
      " Train_Loss : 86.19310087906688, R2 : -0.07652043668847335\n",
      "Val_Loss : 60.124488830566406, R2 : -1.9073486328125e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12446212768555, R2 : -1.5497207641601562e-06\n",
      "[477/500] \n",
      " Train_Loss : 86.19143977918122, R2 : -0.07648800548754241\n",
      "Val_Loss : 60.12446212768555, R2 : -1.5497207641601562e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12446212768555, R2 : -1.5497207641601562e-06\n",
      "[478/500] \n",
      " Train_Loss : 86.18978138973839, R2 : -0.07645553036739952\n",
      "Val_Loss : 60.12446212768555, R2 : -1.5497207641601562e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12445068359375, R2 : -1.3113021850585938e-06\n",
      "[479/500] \n",
      " Train_Loss : 86.18812028985275, R2 : -0.07642308034394917\n",
      "Val_Loss : 60.12445068359375, R2 : -1.3113021850585938e-06\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12443161010742, R2 : -9.5367431640625e-07\n",
      "[480/500] \n",
      " Train_Loss : 86.18645738300525, R2 : -0.07639054875624807\n",
      "Val_Loss : 60.12443161010742, R2 : -9.5367431640625e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.124420166015625, R2 : -8.344650268554688e-07\n",
      "[481/500] \n",
      " Train_Loss : 86.18479548002544, R2 : -0.07635807363610518\n",
      "Val_Loss : 60.124420166015625, R2 : -8.344650268554688e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12441635131836, R2 : -7.152557373046875e-07\n",
      "[482/500] \n",
      " Train_Loss : 86.18313177008378, R2 : -0.07632549812919215\n",
      "Val_Loss : 60.12441635131836, R2 : -7.152557373046875e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12440490722656, R2 : -4.76837158203125e-07\n",
      "[483/500] \n",
      " Train_Loss : 86.181463743511, R2 : -0.07629292262227912\n",
      "Val_Loss : 60.12440490722656, R2 : -4.76837158203125e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12439727783203, R2 : -3.5762786865234375e-07\n",
      "[484/500] \n",
      " Train_Loss : 86.17979943124871, R2 : -0.07626035338953922\n",
      "Val_Loss : 60.12439727783203, R2 : -3.5762786865234375e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.124385833740234, R2 : -2.384185791015625e-07\n",
      "[485/500] \n",
      " Train_Loss : 86.17812889500668, R2 : -0.0762276523991635\n",
      "Val_Loss : 60.124385833740234, R2 : -2.384185791015625e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.124385833740234, R2 : -2.384185791015625e-07\n",
      "[486/500] \n",
      " Train_Loss : 86.17646046688682, R2 : -0.0761950831664236\n",
      "Val_Loss : 60.124385833740234, R2 : -2.384185791015625e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.124385833740234, R2 : -2.384185791015625e-07\n",
      "[487/500] \n",
      " Train_Loss : 86.17478762174908, R2 : -0.07616228806345086\n",
      "Val_Loss : 60.124385833740234, R2 : -2.384185791015625e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12437438964844, R2 : 0.0\n",
      "[488/500] \n",
      " Train_Loss : 86.17311005843312, R2 : -0.07612956197638261\n",
      "Val_Loss : 60.12437438964844, R2 : 0.0\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12437438964844, R2 : 0.0\n",
      "[489/500] \n",
      " Train_Loss : 86.17143831754986, R2 : -0.07609681079262182\n",
      "Val_Loss : 60.12437438964844, R2 : 0.0\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12437438964844, R2 : 0.0\n",
      "[490/500] \n",
      " Train_Loss : 86.16976296274285, R2 : -0.07606405333468788\n",
      "Val_Loss : 60.12437438964844, R2 : 0.0\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12437438964844, R2 : 0.0\n",
      "[491/500] \n",
      " Train_Loss : 86.16808740716232, R2 : -0.07603123313502262\n",
      "Val_Loss : 60.12437438964844, R2 : 0.0\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12437438964844, R2 : 0.0\n",
      "[492/500] \n",
      " Train_Loss : 86.16640121058414, R2 : -0.07599828117772152\n",
      "Val_Loss : 60.12437438964844, R2 : 0.0\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1243782043457, R2 : -1.1920928955078125e-07\n",
      "[493/500] \n",
      " Train_Loss : 86.16472073605186, R2 : -0.07596537313963238\n",
      "Val_Loss : 60.1243782043457, R2 : -1.1920928955078125e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1243896484375, R2 : -3.5762786865234375e-07\n",
      "[494/500] \n",
      " Train_Loss : 86.16304327312268, R2 : -0.0759325341174477\n",
      "Val_Loss : 60.1243896484375, R2 : -3.5762786865234375e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.1243896484375, R2 : -3.5762786865234375e-07\n",
      "[495/500] \n",
      " Train_Loss : 86.16135798002544, R2 : -0.07589953824093468\n",
      "Val_Loss : 60.1243896484375, R2 : -3.5762786865234375e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12440490722656, R2 : -4.76837158203125e-07\n",
      "[496/500] \n",
      " Train_Loss : 86.1596649571469, R2 : -0.0758664796226903\n",
      "Val_Loss : 60.12440490722656, R2 : -4.76837158203125e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12440490722656, R2 : -4.76837158203125e-07\n",
      "[497/500] \n",
      " Train_Loss : 86.15798207333214, R2 : -0.075833471197831\n",
      "Val_Loss : 60.12440490722656, R2 : -4.76837158203125e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12441635131836, R2 : -7.152557373046875e-07\n",
      "[498/500] \n",
      " Train_Loss : 86.15628734387849, R2 : -0.07580032474116276\n",
      "Val_Loss : 60.12441635131836, R2 : -7.152557373046875e-07\n",
      "torch.Size([81, 1])\n",
      "LOSS : 60.12441635131836, R2 : -7.152557373046875e-07\n",
      "[499/500] \n",
      " Train_Loss : 86.15459532486766, R2 : -0.07576725984874524\n",
      "Val_Loss : 60.12441635131836, R2 : -7.152557373046875e-07\n"
     ]
    }
   ],
   "source": [
    "loss, r2 = training(x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'R2')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 후 loss 시각화 \n",
    "\n",
    "THRESHOLD = 50\n",
    "fg, axes = plt.subplots(1,2, figsize = (10,5))\n",
    "axes[0].plot(range(1,THRESHOLD+1) ,loss[0][:THRESHOLD], label = 'Train')\n",
    "axes[0].plot(range(1,THRESHOLD+1), loss[1][:THRESHOLD], label = 'Val')\n",
    "axes[0].grid()\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('LOSS')\n",
    "\n",
    "axes[1].plot(range(1,THRESHOLD+1) ,r2[0][:THRESHOLD], label = 'Train')\n",
    "axes[1].plot(range(1,THRESHOLD+1), r2[1][:THRESHOLD], label = 'Val')\n",
    "axes[1].grid()\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('r2')\n",
    "axes[1].set_title('R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.168984362953587\n",
      "0.7047122967870612\n"
     ]
    }
   ],
   "source": [
    "print(min(loss[0][:THRESHOLD]))\n",
    "print(max(r2[0][:THRESHOLD]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
