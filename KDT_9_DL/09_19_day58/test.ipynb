{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 퍼셉트론(Perceptron) 개념에 대해 설명하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사람의 뉴런을 공학적으로 나타낸 것   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 퍼셉트론(Perceptron) 기본 동작 원리 및 수식을 도식화와 함께 작성해주세요\n",
    " - 조건 : 피쳐 4개 퍼셉트론 1개\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피쳐와 가중치(w)를 곱하여 더하고 절편(b)도 더한 식을 활성함수에 적용시킨다. \n",
    "# f11w11 + f21w21 + f31w31 + f41w41 + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 활성화함수(Activation Function)의 역할을 설명하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퍼셉트론의 값(들어오는 값)이 0 ~ 1 범위에 속하도록 바꿔준다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 대표적인 활성화함수 에 대해 설명하세요\n",
    " - 최소 4개 이상 값의 범위\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Relu \n",
    "#   - x < 0 -> 0\n",
    "#   --> 0 <= x \n",
    "\n",
    "# - LeakyRelu\n",
    "#   - 기존 Relu가 죽은 Relu가 돼서 사용 \n",
    "#   - x < 0 -> 0.00001 (0 아닌 매우 작은 값)\n",
    "\n",
    "# - step\n",
    "#   - x < 0 -> 0\n",
    "#   - 0 <= x <= 1 -> x \n",
    "#   - x > 1 -> 1\n",
    "\n",
    "# - sigmoid\n",
    "#   - 이진 분류에서 주로 사용된다 \n",
    "#   - 0 <= x <= 1\n",
    "\n",
    "# - softmax \n",
    "#   - 다중 분류에서 주로 사용된다\n",
    "#   - 0 <= x <= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 경사하강법의 개념 및 대표적인 경사하강법 알고리즘에 대해 간략히 설명하세요\n",
    " - 최소 3개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate를 제공하여 순차적으로 학습하며 기울기가 가장 작은 지점을 찾는다.\n",
    "\n",
    "# 확률적 경사 하강법 : 데이터 전체 말고 랜덤하게 추출하여 경사 하강법 진행\n",
    "# \n",
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. . 회귀 모델 구현을 간략하게 코드 작성하세요\n",
    " - 피쳐 3개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = nn.Sequential(nn.Linear(3,5),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3, out_features=5, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. . 이진분류 모델 구현을 간략하게 코드 작성하세요\n",
    " - 피처 5개     \n",
    " - 클래스 2개    \n",
    " - 층 : 4개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "class b_model(nn.Module):\n",
    "    def __init__(self, in_out, out_out = 2, h_cnt=4):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(5,in_out)\n",
    "        self.hidden_layer = nn.ModuleList()\n",
    "        \n",
    "        n = 5\n",
    "        for i in range(h_cnt):\n",
    "        \n",
    "            self.hidden_layer.append(nn.Linear(in_out - (i-1) * n, in_out - i*n))\n",
    "\n",
    "        self.output_layer = nn.Linear(in_out - i * n, out_out)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = self.input_layer(x)\n",
    "        y = F.relu(y)\n",
    "\n",
    "        for hidden in self.hidden_layer:\n",
    "            y = hidden(y)\n",
    "            y = F.relu(y)\n",
    "\n",
    "        y = self.output_layer(y)\n",
    "        y = F.sigmoid(y)\n",
    "    \n",
    "        return y \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b_model(\n",
       "  (input_layer): Linear(in_features=5, out_features=40, bias=True)\n",
       "  (hidden_layer): ModuleList(\n",
       "    (0): Linear(in_features=45, out_features=40, bias=True)\n",
       "    (1): Linear(in_features=40, out_features=35, bias=True)\n",
       "    (2): Linear(in_features=35, out_features=30, bias=True)\n",
       "    (3): Linear(in_features=30, out_features=25, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=25, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_m = b_model(40)\n",
    "b_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. . 다중분류 모델 구현을 간략하게 코드 작성하세요\n",
    " - 피처 5개 \n",
    " - 클래스 8개 \n",
    " - 층 3 ~ 5개 \n",
    " - 퍼셉트론 : 동적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "class m_model(nn.Module):\n",
    "    def __init__(self, in_out, h_cnt, out_out= 8):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(5,in_out)\n",
    "        self.hidden_layer = nn.ModuleList()\n",
    "        \n",
    "        n = 5\n",
    "        for i in range(h_cnt):\n",
    "        \n",
    "            self.hidden_layer.append(nn.Linear(in_out - (i-1) * n, in_out - i*n))\n",
    "\n",
    "        self.output_layer = nn.Linear(in_out - i * n, out_out)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = self.input_layer(x)\n",
    "        y = F.relu(y)\n",
    "\n",
    "        for hidden in self.hidden_layer:\n",
    "            y = hidden(y)\n",
    "            y = F.relu(y)\n",
    "\n",
    "        y = self.output_layer(y)\n",
    "        y = F.softmax(y)\n",
    "    \n",
    "        return y \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "class m_model_p(nn.Module):\n",
    "    def __init__(self, h_io = [], out_out= 8):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(5,h_io[0])\n",
    "        self.hidden_layer = nn.ModuleList()\n",
    "        \n",
    "        \n",
    "        for i in range(len(h_io)-1):\n",
    "        \n",
    "            self.hidden_layer.append(nn.Linear(h_io[i], h_io[i+1]))\n",
    "\n",
    "        self.output_layer = nn.Linear(h_io[-1], out_out)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = self.input_layer(x)\n",
    "        y = F.relu(y)\n",
    "\n",
    "        for hidden in self.hidden_layer:\n",
    "            y = hidden(y)\n",
    "            y = F.relu(y)\n",
    "\n",
    "        y = self.output_layer(y)\n",
    "        y = F.softmax(y)\n",
    "    \n",
    "        return y \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m_model(\n",
       "  (input_layer): Linear(in_features=5, out_features=40, bias=True)\n",
       "  (hidden_layer): ModuleList(\n",
       "    (0): Linear(in_features=45, out_features=40, bias=True)\n",
       "    (1): Linear(in_features=40, out_features=35, bias=True)\n",
       "    (2): Linear(in_features=35, out_features=30, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=30, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_m = m_model(40,3)\n",
    "m_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m_model_p(\n",
       "  (input_layer): Linear(in_features=5, out_features=40, bias=True)\n",
       "  (hidden_layer): ModuleList(\n",
       "    (0): Linear(in_features=40, out_features=30, bias=True)\n",
       "    (1): Linear(in_features=30, out_features=25, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=25, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_m_p = m_model_p([40,30,25])\n",
    "m_m_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 기울기 소실 개념 및 해결 방법을 설명하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해결방법 : Relu 함수 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. 파이토치의 모델 동작 모드에 대해 관련 함수도 함께 설명하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 \n",
    "# - 모델을 train만 시키는 모드 \n",
    "# - model.train()\n",
    "\n",
    "\n",
    "# 검증 \n",
    "# 모델을 검증하는 모드\n",
    "# w, b를 업데이트 하지 않음 \n",
    "# - model.eval() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
